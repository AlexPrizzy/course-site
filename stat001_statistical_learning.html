<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Statistical learning: the basics</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/readable.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-45631879-2', 'auto');
  ga('send', 'pageview');

</script>




<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 66px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 71px;
  margin-top: -71px;
}

.section h2 {
  padding-top: 71px;
  margin-top: -71px;
}
.section h3 {
  padding-top: 71px;
  margin-top: -71px;
}
.section h4 {
  padding-top: 71px;
  margin-top: -71px;
}
.section h5 {
  padding-top: 71px;
  margin-top: -71px;
}
.section h6 {
  padding-top: 71px;
  margin-top: -71px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Computing for the Social Sciences</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="faq.html">FAQ</a>
</li>
<li>
  <a href="syllabus.html">Syllabus</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Statistical learning: the basics</h1>

</div>


<div id="what-is-statistical-learning" class="section level1">
<h1>What is statistical learning?</h1>
<p><strong>Statistical models</strong> attempt to summarize relationships between variables by reducing the dimensionality of the data. For example, here we have some simulated data on sales of <a href="https://www.shamwow.com/">Shamwow</a> in 200 different markets.</p>
<div class="figure">
<img src="images/shamwow.jpg" />

</div>
<p>Our goal is to improve sales of the Shamwow. Since we cannot directly increase sales of the product (unless we go out and buy it ourselves), our only option is to increase advertising across three potential mediums: newspaper, radio, and TV.</p>
<p>In this example, the advertising budgets are our <strong>input variables</strong>, also called <strong>independent variables</strong>, <strong>features</strong>, or <strong>predictors</strong>. The sales of Shamwows is the <strong>output</strong>, also called the <strong>dependent variable</strong> or <strong>response</strong>.</p>
<p>By plotting the variables against one another using a scatterplot, we can see there is some sort of relationship between each medium’s advertising spending and Shamwow sales:</p>
<p><img src="stat001_statistical_learning_files/figure-html/plot_ad-1.png" width="672" /></p>
<p>But there seems to be a lot of noise in the data. How can we summarize this? We can do so by estimating a mathematical equation following the general form:</p>
<p><span class="math display">\[Y = f(X) + \epsilon\]</span></p>
<p>where <span class="math inline">\(f\)</span> is some fixed, unknown function of the relationship between the independent variable(s) <span class="math inline">\(X\)</span> and the dependent variable <span class="math inline">\(Y\)</span>, with some random error <span class="math inline">\(\epsilon\)</span>.</p>
<p>Statistical learning refers to the set of approaches for estimating <span class="math inline">\(f\)</span>. There are many potential approaches to defining the functional form of <span class="math inline">\(f\)</span>. One approach widely used is called <strong>least squares</strong> - it means that the overall solution minimizes the sum of the squares of the errors made in the results of the equation. The errors are simply the vertical difference between the actual values for <span class="math inline">\(y\)</span> and the predicted values for <span class="math inline">\(y\)</span>. Applied here, the results would look like:</p>
<p><img src="stat001_statistical_learning_files/figure-html/plot_ad_fit-1.png" width="672" /></p>
<p>However statistical learning (and machine learning) allows us to use a wide range of functional forms beyond a simple linear model.</p>
</div>
<div id="why-estimate-f" class="section level1">
<h1>Why estimate <span class="math inline">\(f\)</span>?</h1>
<p>There are two major goals of statistical modeling:</p>
<div id="prediction" class="section level2">
<h2>Prediction</h2>
<p>Under a system of <strong>prediction</strong>, we use our knowledge of the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> to predict <span class="math inline">\(Y\)</span> for given values of <span class="math inline">\(X\)</span>. Often the function <span class="math inline">\(f\)</span> is treated as a <strong>black box</strong> - we don’t care what the function is, as long as it makes accurate predictions. If we are trying to boost sales of Shamwow, we may not care why specific factors drive an increase in sales - we just want to know how to adjust our advertising budgets to maximize sales.</p>
</div>
<div id="inference" class="section level2">
<h2>Inference</h2>
<p>Under a system of <strong>inference</strong>, we use our knowledge of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> to understand the relationship between the variables. Here we are most interested in the explanation, not the prediction. So in the Shamwow example, we may not care about actual sales of the product - instead, we may be economists who wish to understand how advertising spending influences product sales. We don’t care about the actual product, we simply want to learn more about the process and <strong>generalize</strong> it to a wider range of settings.</p>
</div>
</div>
<div id="how-do-we-estimate-f" class="section level1">
<h1>How do we estimate <span class="math inline">\(f\)</span>?</h1>
<p>There are two major approaches to estimating <span class="math inline">\(f\)</span>: parametric and non-parametric methods.</p>
<div id="parametric-methods" class="section level2">
<h2>Parametric methods</h2>
<p>Parametric methods involve a two-stage process:</p>
<ol style="list-style-type: decimal">
<li>First make an assumption about the functional form of <span class="math inline">\(f\)</span>. For instance, OLS assumes that the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is <strong>linear</strong>. This greatly simplifies the problem of estimating the model because we know a great deal about the properties of linear models.</li>
<li>After a model has been selected, we need to <strong>fit</strong> or <strong>train</strong> the model using the actual data. We demonstrated this previously with ordinary least squares. The estimation procedure minimizes the sum of the squares of the differences between the observed responses <span class="math inline">\(Y\)</span> and those predicted by a linear function <span class="math inline">\(\hat{Y}\)</span>.</li>
</ol>
<p><img src="stat001_statistical_learning_files/figure-html/plot_parametric-1.png" width="672" /></p>
<p>This is only one possible estimation procedure, but is popular because it is relatively intuitive. This model-based approach is referred to as <strong>parametric</strong>, because it simplifies the problem of estimating <span class="math inline">\(f\)</span> to estimating a set of parameters in the function:</p>
<p><span class="math display">\[Y = \beta_0 + \beta_{1}X_1\]</span></p>
<p>where <span class="math inline">\(Y\)</span> is the sales, <span class="math inline">\(X_1\)</span> is the advertising spending in a given medium (newspaper, radio, or TV), and <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are parameters defining the intercept and slope of the line.</p>
<p>The downside to parametric methods is that they assume a specific functional form of the relationship between the variables. Sometimes relationships really are linear - often however they are not. They could be curvilinear, parbolic, interactive, etc. Unless we know this <em>a priori</em> or test for all of these potential functional forms, it is possible our parametric method will not accurately summarize the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.</p>
</div>
<div id="non-parametric-methods" class="section level2">
<h2>Non-parametric methods</h2>
<p>Non-parametric methods do not make any assumptions about the functional form of <span class="math inline">\(f\)</span>. Instead, they use the data itself to estimate <span class="math inline">\(f\)</span> so that it gets as close as possible to the data points without becoming overly complex. By avoiding any assumptions about the functional form, non-parametric methods avoid the issues caused by parametic models. However, by doing so non-parametric methods require a large set of observations to avoid <strong>overfitting</strong> the data and obtain an accurate estimate of <span class="math inline">\(f\)</span>.</p>
<p>One non-parametric method is called <strong><span class="math inline">\(K\)</span>-nearest neighbors regression</strong> (KNN regression). Rather than binning the data into discrete and fixed intervals, KNN regression uses a moving average to generate the regression line. Given a value for <span class="math inline">\(K\)</span> and a prediction point <span class="math inline">\(x_0\)</span>, KNN regression identifies the <span class="math inline">\(K\)</span> observations closest to the prediction point <span class="math inline">\(X_0\)</span>, and estimates a local regression line that is the average of these observations values for the outcome <span class="math inline">\(Y\)</span>.</p>
<p>With <span class="math inline">\(K=1\)</span>, the resulting KNN regression line will fit the training observations extraordinarily well.</p>
<p><img src="stat001_statistical_learning_files/figure-html/knn-1-1.png" width="672" /></p>
<p>Perhaps a bit too well. Compare this to <span class="math inline">\(K=9\)</span>:</p>
<p><img src="stat001_statistical_learning_files/figure-html/knn-9-1.png" width="672" /></p>
<p>This smoothing line averages over the nine nearest observations; while still a step function, it is smoother than <span class="math inline">\(K=1\)</span>.</p>
</div>
</div>
<div id="classification-vs.regression" class="section level1">
<h1>Classification vs. regression</h1>
<p>Variables can be classified as <strong>quantitative</strong> or <strong>qualitative</strong>. Quantitative variables take on numeric values. In contrast, qualitative variables take on different <strong>classes</strong>, or discrete categories. Qualitative variables can have any number of classes, though binary categories are frequent:</p>
<ul>
<li>Yes/no</li>
<li>Male/female</li>
</ul>
<p>Problems with a quantitative dependent variable are typically called <strong>regression</strong> problems, whereas qualitative dependent variables are called <strong>classification</strong> problems. Part of this distinction is merely semantic, but different methods may be employed depending on the type of response variable. For instance, you would not use linear regression on a qualitative response variable. Conceptually, how would you define a linear function for a response variable that takes on the values “male” or “female”? It doesn’t make any conceptual sense. Instead, you can employ classification methods such as <strong>logistic regression</strong> to estimate the probability that based on a set of predictors a specific observation is part of a response class.</p>
<p>That said, whether <strong>predictors</strong> are qualitative or quantitative is not important in determining whether the problem is one of regression or classification. As long as qualitative predictors are properly coded before the analysis is conducted, they can be used for either type of problem.</p>
</div>
<div id="session-info" class="section level1 toc-ignore">
<h1>Session Info</h1>
<pre><code>##  setting  value                       
##  version  R version 3.4.3 (2017-11-30)
##  system   x86_64, darwin15.6.0        
##  ui       X11                         
##  language (EN)                        
##  collate  en_US.UTF-8                 
##  tz       America/Chicago             
##  date     2018-04-24                  
## 
##  package    * version    date       source                             
##  assertthat   0.2.0      2017-04-11 CRAN (R 3.4.0)                     
##  backports    1.1.2      2017-12-13 CRAN (R 3.4.3)                     
##  base       * 3.4.3      2017-12-07 local                              
##  bindr        0.1.1      2018-03-13 CRAN (R 3.4.3)                     
##  bindrcpp     0.2.2.9000 2018-04-08 Github (krlmlr/bindrcpp@bd5ae73)   
##  broom        0.4.4      2018-03-29 CRAN (R 3.4.3)                     
##  cellranger   1.1.0      2016-07-27 CRAN (R 3.4.0)                     
##  cli          1.0.0      2017-11-05 CRAN (R 3.4.2)                     
##  colorspace   1.3-2      2016-12-14 CRAN (R 3.4.0)                     
##  compiler     3.4.3      2017-12-07 local                              
##  crayon       1.3.4      2017-10-03 Github (gaborcsardi/crayon@b5221ab)
##  datasets   * 3.4.3      2017-12-07 local                              
##  devtools     1.13.5     2018-02-18 CRAN (R 3.4.3)                     
##  digest       0.6.15     2018-01-28 CRAN (R 3.4.3)                     
##  dplyr      * 0.7.4.9003 2018-04-08 Github (tidyverse/dplyr@b7aaa95)   
##  evaluate     0.10.1     2017-06-24 CRAN (R 3.4.1)                     
##  FNN        * 1.1        2013-07-31 CRAN (R 3.4.0)                     
##  forcats    * 0.3.0      2018-02-19 CRAN (R 3.4.3)                     
##  foreign      0.8-69     2017-06-22 CRAN (R 3.4.3)                     
##  ggplot2    * 2.2.1.9000 2018-04-24 Github (tidyverse/ggplot2@3c9c504) 
##  glue         1.2.0      2017-10-29 CRAN (R 3.4.2)                     
##  graphics   * 3.4.3      2017-12-07 local                              
##  grDevices  * 3.4.3      2017-12-07 local                              
##  grid         3.4.3      2017-12-07 local                              
##  gtable       0.2.0      2016-02-26 CRAN (R 3.4.0)                     
##  haven        1.1.1      2018-01-18 CRAN (R 3.4.3)                     
##  hms          0.4.2      2018-03-10 CRAN (R 3.4.3)                     
##  htmltools    0.3.6      2017-04-28 CRAN (R 3.4.0)                     
##  httr         1.3.1      2017-08-20 CRAN (R 3.4.1)                     
##  jsonlite     1.5        2017-06-01 CRAN (R 3.4.0)                     
##  knitr        1.20       2018-02-20 CRAN (R 3.4.3)                     
##  lattice      0.20-35    2017-03-25 CRAN (R 3.4.3)                     
##  lazyeval     0.2.1      2017-10-29 CRAN (R 3.4.2)                     
##  lubridate    1.7.4      2018-04-11 CRAN (R 3.4.3)                     
##  magrittr     1.5        2014-11-22 CRAN (R 3.4.0)                     
##  memoise      1.1.0      2017-04-21 CRAN (R 3.4.0)                     
##  methods    * 3.4.3      2017-12-07 local                              
##  mnormt       1.5-5      2016-10-15 CRAN (R 3.4.0)                     
##  modelr       0.1.1      2017-08-10 local                              
##  munsell      0.4.3      2016-02-13 CRAN (R 3.4.0)                     
##  nlme         3.1-137    2018-04-07 CRAN (R 3.4.4)                     
##  parallel     3.4.3      2017-12-07 local                              
##  pillar       1.2.1      2018-02-27 CRAN (R 3.4.3)                     
##  pkgconfig    2.0.1      2017-03-21 CRAN (R 3.4.0)                     
##  plyr         1.8.4      2016-06-08 CRAN (R 3.4.0)                     
##  psych        1.8.3.3    2018-03-30 CRAN (R 3.4.4)                     
##  purrr      * 0.2.4      2017-10-18 CRAN (R 3.4.2)                     
##  R6           2.2.2      2017-06-17 CRAN (R 3.4.0)                     
##  Rcpp         0.12.16    2018-03-13 CRAN (R 3.4.4)                     
##  readr      * 1.1.1      2017-05-16 CRAN (R 3.4.0)                     
##  readxl       1.0.0      2017-04-18 CRAN (R 3.4.0)                     
##  reshape2     1.4.3      2017-12-11 CRAN (R 3.4.3)                     
##  rlang        0.2.0.9001 2018-04-24 Github (r-lib/rlang@82b2727)       
##  rmarkdown    1.9        2018-03-01 CRAN (R 3.4.3)                     
##  rprojroot    1.3-2      2018-01-03 CRAN (R 3.4.3)                     
##  rstudioapi   0.7        2017-09-07 CRAN (R 3.4.1)                     
##  rvest        0.3.2      2016-06-17 CRAN (R 3.4.0)                     
##  scales       0.5.0.9000 2018-04-24 Github (hadley/scales@d767915)     
##  stats      * 3.4.3      2017-12-07 local                              
##  stringi      1.1.7      2018-03-12 CRAN (R 3.4.3)                     
##  stringr    * 1.3.0      2018-02-19 CRAN (R 3.4.3)                     
##  tibble     * 1.4.2      2018-01-22 CRAN (R 3.4.3)                     
##  tidyr      * 0.8.0      2018-01-29 CRAN (R 3.4.3)                     
##  tidyselect   0.2.4      2018-02-26 CRAN (R 3.4.3)                     
##  tidyverse  * 1.2.1      2017-11-14 CRAN (R 3.4.2)                     
##  tools        3.4.3      2017-12-07 local                              
##  utils      * 3.4.3      2017-12-07 local                              
##  withr        2.1.2      2018-04-24 Github (jimhester/withr@79d7b0d)   
##  xml2         1.2.0      2018-01-24 CRAN (R 3.4.3)                     
##  yaml         2.1.18     2018-03-08 CRAN (R 3.4.4)</code></pre>
</div>

<p>This work is licensed under the  <a href="http://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0 Creative Commons License</a>.</p>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
