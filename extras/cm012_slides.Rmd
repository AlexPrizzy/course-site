---
title: "Statistical learning: classification problems"
author: |
  | MACS 30500
  | University of Chicago
date: "February 8, 2017"
output: rcfss::cfss_slides
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(cache = TRUE,
                      message = FALSE,
                      warning = FALSE,
                      echo = FALSE,
                      interval = .4)

library(tidyverse)
library(modelr)
library(here)
theme_set(theme_bw(base_size = 18))
```

## Titanic

[![Sinking of the *Titanic*](https://static1.squarespace.com/static/5006453fe4b09ef2252ba068/5095eabce4b06cb305058603/5095eabce4b02d37bef4c24c/1352002236895/100_anniversary_titanic_sinking_by_esai8mellows-d4xbme8.jpg)](http://www.ultimatetitanic.com/the-sinking/)

## Titanic

<iframe width="560" height="315" src="https://www.youtube.com/embed/WNIPqafd4As" frameborder="0" allowfullscreen></iframe>

## Titanic

![[Titanic (1997)](https://en.wikipedia.org/wiki/Titanic_(1997_film))](http://i.giphy.com/KSeT85Vtym7m.gif)
    
## Get data

```{r titanic_data, message = FALSE}
library(titanic)
titanic <- titanic_train %>%
  as_tibble()

str(titanic)
```

## Linear regression

```{r titanic_ols}
ggplot(titanic, aes(Age, Survived)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)
```

## Linear regression

```{r titanic_ols_old}
ggplot(titanic, aes(Age, Survived)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, fullrange = TRUE) +
  xlim(0, 200)
```

## Logistic regression

$$P(\text{survival} = \text{Yes} | \text{age})$$

* Predicted probability of surviving

## Logistic regression

```{r titanic_age_glm, echo = TRUE}
survive_age <- glm(Survived ~ Age, data = titanic, family = binomial)
summary(survive_age)
```

## Logistic regression

```{r titanic_age_glm_plot}
ggplot(titanic, aes(Age, Survived)) +
  geom_point() +
  geom_smooth(method = "glm", method.args = list(family = "binomial"),
              se = FALSE)
```

## Logistic regression

```{r titanic_age_glm_plot_wide}
ggplot(titanic, aes(Age, Survived)) +
  geom_point() +
  geom_smooth(method = "glm", method.args = list(family = "binomial"),
              se = FALSE, fullrange = TRUE) +
  xlim(0,200)
```

```{r make_age_pred}
titanic_age <- titanic %>%
  data_grid(Age)
```

```{r logit}
logit2prob <- function(x){
  exp(x) / (1 + exp(x))
}
```

```{r extract_modelr, depends="make_age_pred"}
titanic_age <- titanic_age %>%
  add_predictions(survive_age) %>%
  mutate(pred = logit2prob(pred))
```

```{r plot_pred, depends="make_age_pred", eval = FALSE}
ggplot(titanic_age, aes(Age, pred)) +
  geom_line() +
  labs(title = "Relationship Between Age and Surviving the Titanic",
       y = "Predicted Probability of Survival")
```

## Multiple predictors

```{r survive_age_woman}
survive_age_woman <- glm(Survived ~ Age + Sex, data = titanic,
                         family = binomial)
summary(survive_age_woman)
```

## Multiple predictors

```{r survive_age_woman_pred}
titanic_age_sex <- titanic %>%
  data_grid(Age, Sex) %>%
  add_predictions(survive_age_woman) %>%
  mutate(pred = logit2prob(pred))
```

```{r survive_age_woman_plot, dependson="survive_age_woman"}
ggplot(titanic_age_sex, aes(Age, pred, color = Sex)) +
  geom_line() +
  labs(title = "Probability of Surviving the Titanic",
       y = "Predicted Probability of Survival",
       color = "Sex")
```

## Quadratic terms

```{r straight_line}
sim_line <- tibble(x = runif(1000),
                   y = x * 1)

ggplot(sim_line, aes(x, y)) +
  geom_line()
```

## Quadratic terms

```{r parabola}
sim_line <- tibble(x = runif(1000, -1, 1),
                   y = x^2 + x)

ggplot(sim_line, aes(x, y)) +
  geom_line()
```

## Quadratic terms

```{r quadratic}
sim_line <- tibble(x = runif(1000, -1, 1),
                   y = x^3 + x^2 + x)

ggplot(sim_line, aes(x, y)) +
  geom_line()
```

## Quadratic terms

```{r}
survive_age_square <- glm(Survived ~ Age + I(Age^2), data = titanic,
                          family = binomial)

titanic_age %>%
  add_predictions(survive_age) %>%
  mutate(pred = logit2prob(pred)) %>%
  ggplot(aes(Age, pred)) +
  geom_line() +
  labs(title = "Relationship Between Age and Surviving the Titanic",
       y = "Predicted Probability of Survival")
```

## Interactive terms

$$f = \beta_{0} + \beta_{1}\text{age} + \beta_{2}\text{gender}$$

## Interactive terms

$$f = \beta_{0} + \beta_{1}\text{age} + \beta_{2}\text{gender} + \beta_{3}(\text{age} \times \text{gender})$$

## Interactive terms

$$f = \beta_{0} + \beta_{1}\text{age} + \beta_{2}\text{gender}$$

$$f = \beta_{0} + \beta_{1}\text{age} + \beta_{2}\text{gender} + \beta_{3}(\text{age} \times \text{gender})$$

## Interactive terms

```{r age_woman_cross}
survive_age_woman_x <- glm(Survived ~ Age * Sex, data = titanic,
                           family = binomial)
```

```{r age_woman_cross_pred, dependson="age_woman_cross"}
titanic_age_sex_x <- titanic %>%
  data_grid(Age, Sex) %>%
  add_predictions(survive_age_woman_x) %>%
  mutate(pred = logit2prob(pred))
```

```{r age_woman_plot, dependson="age_woman_cross"}
ggplot(titanic_age_sex_x, aes(Age, pred, color = Sex)) +
  geom_line() +
  labs(title = "Probability of Surviving the Titanic",
       y = "Predicted Probability of Survival",
       color = "Sex")
```

## Accuracy of predictions

```{r accuracy_age, dependson="titanic_age_glm", echo = TRUE}
age_accuracy <- titanic %>%
  add_predictions(survive_age) %>%
  mutate(pred = logit2prob(pred),
         pred = as.numeric(pred > .5))

mean(age_accuracy$Survived == age_accuracy$pred, na.rm = TRUE)
```

## Accuracy of predictions

```{r accuracy_age_gender_x, dependson="age_woman_cross", echo = TRUE}
x_accuracy <- titanic %>%
  add_predictions(survive_age_woman_x) %>%
  mutate(pred = logit2prob(pred),
         pred = as.numeric(pred > .5))

mean(x_accuracy$Survived == x_accuracy$pred, na.rm = TRUE)
```

## Training/test sets

* Training set
* Test set
* Why split up?

## Test set for Titanic {.scrollable}

```{r accuracy_age_gender_x_test_set, dependson="age_woman_cross", message = FALSE, echo = TRUE}
titanic_split <- resample_partition(titanic, c(test = 0.3, train = 0.7))
map(titanic_split, dim)

train_model <- glm(Survived ~ Age * Sex, data = titanic_split$train,
                   family = binomial)
summary(train_model)

x_test_accuracy <- titanic_split$test %>%
  tbl_df() %>%
  add_predictions(train_model) %>%
  mutate(pred = logit2prob(pred),
         pred = as.numeric(pred > .5))

mean(x_test_accuracy$Survived == x_test_accuracy$pred, na.rm = TRUE)
```

## Exercise: depression and voting

Complete [this exercise](http://cfss.uchicago.edu/stat003_logistic_regression.html#exercise:_logistic_regression_with_mental_health)

----

![](https://eight2late.files.wordpress.com/2016/02/7214525854_733237dd83_z1.jpg?w=700)

----

![](https://s-media-cache-ak0.pinimg.com/564x/0b/87/df/0b87df1a54474716384f8ec94b52eab9.jpg)

----

![[Should I Have a Cookie?](http://iwastesomuchtime.com/58217)](http://data.iwastesomuchtime.com/November-26-2012-17-34-05-cookie.gif)

## Interpreting a decision tree

```{r titanic_tree, echo = FALSE}
library(tree)

titanic_tree_data <- titanic %>%
  mutate(Survived = ifelse(Survived == 1, "Survived",
                           ifelse(Survived == 0, "Died", NA)),
         Survived = as.factor(Survived),
         Sex = as.factor(Sex))

titanic_tree <- tree(Survived ~ Age + Sex, data = titanic_tree_data)

plot(titanic_tree)
text(titanic_tree, pretty = 0)
```

## Benefits/drawbacks to decision trees

+ Easy to explain
+ Easy to interpret/visualize
+ Good for qualitative predictors
- Lower accuracy rates
- Non-robust

## Random forests

![](http://www.discovertheforest.org/images/hero/home/6.jpg)

## Random forests

* Bootstrapping
* Reduces variance
* Bagging
* Random forest
    * Reliability

## The `caret` library

[Estimating statistical models using `caret`](http://cfss.uchicago.edu/stat004_decision_trees.html#estimating_statistical_models_using_caret)

## Exercise: depression and voting

Complete [this exercise](stat004_decision_trees.html#exercise:_random_forests_with_mental_health)


