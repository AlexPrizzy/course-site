---
title: "Statistical learning: classification and cross-validation"
author: |
  | MACS 30500
  | University of Chicago
output: rcfss::cfss_slides
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(cache = TRUE,
                      message = FALSE,
                      warning = FALSE,
                      echo = FALSE,
                      interval = .4)

set.seed(1234)

library(tidyverse)
library(modelr)
library(here)
theme_set(theme_minimal(base_size = 18))
```

----

![](https://eight2late.files.wordpress.com/2016/02/7214525854_733237dd83_z1.jpg?w=700)

## {.scrollable}

![](https://s-media-cache-ak0.pinimg.com/564x/0b/87/df/0b87df1a54474716384f8ec94b52eab9.jpg)

## {.scrollable}

![[Should I Have a Cookie?](http://iwastesomuchtime.com/58217)](http://data.iwastesomuchtime.com/November-26-2012-17-34-05-cookie.gif)

## Interpreting a decision tree

```{r titanic_data, include = FALSE}
library(titanic)
titanic <- titanic_train %>%
  as_tibble()
```

```{r titanic_tree, echo = FALSE}
library(tree)

titanic_tree_data <- titanic %>%
  mutate(Survived = ifelse(Survived == 1, "Survived",
                           ifelse(Survived == 0, "Died", NA)),
         Survived = as.factor(Survived),
         Sex = as.factor(Sex))

titanic_tree <- tree(Survived ~ Age + Sex, data = titanic_tree_data)

plot(titanic_tree)
text(titanic_tree, pretty = 0)
```

## A more complex tree

```{r titanic_tree_full}
titanic_tree_full_data <- titanic %>%
  mutate(Survived = if_else(Survived == 1, "Survived",
                           if_else(Survived == 0, "Died", NA_character_))) %>%
  mutate_if(is.character, as.factor)

titanic_tree_full <- tree(Survived ~ Pclass + Sex + Age + SibSp +
                       Parch + Fare + Embarked, data = titanic_tree_full_data)

plot(titanic_tree_full)
text(titanic_tree_full, pretty = 0)
```

## A more complexier tree

```{r titanic_tree_complicated, dependson="titanic_tree_full"}
titanic_tree_messy <- tree(Survived ~ Pclass + Sex + Age + SibSp +
                             Parch + Fare + Embarked,
                           data = titanic_tree_full_data,
                           control = tree.control(
                             nobs = nrow(titanic_tree_full_data),
                             mindev = 0,
                             minsize = 10)
)

plot(titanic_tree_messy)
text(titanic_tree_messy, pretty = 0)
```

## Benefits/drawbacks to decision trees

+ Easy to explain
+ Easy to interpret/visualize
+ Good for qualitative predictors
- Lower accuracy rates
- Non-robust

## Random forests

![](https://c402277.ssl.cf1.rackcdn.com/photos/946/images/story_full_width/forests-why-matter_63516847.jpg?1345534028)

## Sampling with replacement {.scrollable}

```{r sampling, echo = TRUE}
(numbers <- seq(from = 1, to = 10))

# sample without replacement
rerun(5, sample(numbers, replace = FALSE))

# sample with replacement
rerun(5, sample(numbers, replace = TRUE))
```

## Random forests

* Bootstrapping
* Reduces variance
* Bagging
* Random forest
    * Reliability

## Estimating statistical models using `caret`

* Not part of `tidyverse` (yet)
* Aggregator of hundreds of statistical learning algorithms
* Provides a single unified interface to disparate range of functions
    * Similar to `scikit-learn` for Python

## `train()` {.scrollable}

```{r caret_glm, echo = TRUE}
library(caret)

titanic_clean <- titanic %>%
  filter(!is.na(Survived), !is.na(Age))

caret_glm <- train(Survived ~ Age, data = titanic_clean,
                   method = "glm",
                   family = binomial,
                   trControl = trainControl(method = "none"))
summary(caret_glm)
```

## Estimating a random forest

```{r rf_prep_data, dependson="titanic_tree_full", include = FALSE}
titanic_rf_data <- titanic_tree_full_data %>%
  select(Survived, Pclass, Sex, Age, SibSp, Parch, Fare, Embarked) %>%
  na.omit()
titanic_rf_data
```

```{r rf_estimate, dependson="rf_prep_data", echo = TRUE}
age_sex_rf <- train(Survived ~ Age + Sex, data = titanic_rf_data,
                   method = "rf",
                   ntree = 200,
                   trControl = trainControl(method = "oob"))
age_sex_rf
```

## Structure of `train()` object {.scrollable}

```{r rf_str, dependson="rf_estimate"}
str(age_sex_rf, max.level = 1)
```

## Model statistics

```{r rf_finalmodel, dependson="rf_estimate"}
age_sex_rf$finalModel
```

## Results of a single tree

```{r getTree}
randomForest::getTree(age_sex_rf$finalModel, labelVar = TRUE)
```

## Variable importance

```{r rf_import, dependson="rf_estimate"}
varImpPlot(age_sex_rf$finalModel)
```

## Exercise: depression and voting {.scrollable}

![](https://i.pinimg.com/564x/24/81/96/24819625c9636fcfab5000a47811d93b--favorite-quotes-offices.jpg)

## Resampling methods

* Evaluating model fit/predictive power
* How to avoid overfitting the data

## Validation set

* Randomly split data into two distinct sets
    * Training set
    * Test set
* Train model on training set
* Evaluate fit on test set

## Regression

```{r auto, include = FALSE}
library(ISLR)

Auto <- as_tibble(Auto)
Auto
```

```{r auto_plot_lm, dependson="auto"}
ggplot(Auto, aes(horsepower, mpg)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)
```

## Mean squared error

$$MSE = \frac{1}{n} \sum_{i = 1}^{n}{(y_i - \hat{f}(x_i))^2}$$

* $y_i =$ the observed response value for the $i$th observation
* $\hat{f}(x_i) =$ the predicted response value for the $i$th observation given by $\hat{f}$
* $n =$ the total number of observations

## Split data

```{r auto_split, echo = TRUE}
set.seed(1234)

auto_split <- resample_partition(Auto, c(test = 0.5, train = 0.5))
auto_train <- as_tibble(auto_split$train)
auto_test <- as_tibble(auto_split$test)
```

## Train model

```{r auto_lm, dependson="auto_split", echo = TRUE}
auto_lm <- glm(mpg ~ horsepower, data = auto_train)
summary(auto_lm)
```

## Test model

```{r mse-function}
mse <- function(model, data) {
  x <- modelr:::residuals(model, data)
  mean(x ^ 2, na.rm = TRUE)
}
```

```{r mse, dependson="auto_split", echo = TRUE}
mse(auto_lm, auto_test)
```

## Compare models {.scrollable}

```{r mse_poly, dependson="auto_split"}
# write a custom model function
auto_poly_glm <- function(x){
  glm(mpg ~ poly(horsepower, x), data = auto_train)
}

# estimate models with higher order polynomials
auto_poly_results <- data_frame(terms = 1:5,
                                model = map(terms, auto_poly_glm),
                                MSE = map_dbl(model,
                                              mse,
                                              data = auto_test)
)

# visualize each model
data_grid(Auto, horsepower) %>%
  gather_predictions(`1` = auto_poly_results$model[[1]],
                     `2` = auto_poly_results$model[[2]],
                     `3` = auto_poly_results$model[[3]],
                     `4` = auto_poly_results$model[[4]],
                     `5` = auto_poly_results$model[[5]]) %>%
  ggplot(aes(horsepower, pred)) +
  geom_point(data = Auto, aes(y = mpg), alpha = .1) +
  geom_line(aes(color = model)) +
  scale_color_brewer(type = "qual", palette = "Dark2") +
  labs(x = "Horsepower",
       y = "MPG",
       color = "Highest-order\npolynomial")

# compare mse
ggplot(auto_poly_results, aes(terms, MSE)) +
  geom_line() +
  labs(title = "Comparing quadratic linear models",
       subtitle = "Using validation set",
       x = "Highest-order polynomial",
       y = "Mean Squared Error")
```

## Classification

```{r age_woman_cross, echo = TRUE}
survive_age_woman_x <- glm(Survived ~ Age * Sex, data = titanic,
                           family = binomial)
summary(survive_age_woman_x)
```

## Test error rate {.scrollable}

```{r logit}
# function to convert log-odds to probabilities
logit2prob <- function(x){
  exp(x) / (1 + exp(x))
}
```

```{r accuracy_age_gender_x_test_set, dependson="age_woman_cross", message = FALSE, echo = TRUE}
titanic_split <- resample_partition(titanic, c(test = 0.3, train = 0.7))
map(titanic_split, dim)

train_model <- glm(Survived ~ Age * Sex, data = titanic_split$train,
                   family = binomial)
summary(train_model)

x_test_accuracy <- titanic_split$test %>%
  as_tibble() %>%
  add_predictions(train_model) %>%
  mutate(pred = logit2prob(pred),
         pred = as.numeric(pred > .5))

mean(x_test_accuracy$Survived != x_test_accuracy$pred, na.rm = TRUE)
```

## Drawbacks to validation sets

```{r auto_variable_mse}
mse_variable <- function(Auto){
  auto_split <- resample_partition(Auto, c(test = 0.5, train = 0.5))
  auto_train <- as_tibble(auto_split$train)
  auto_test <- as_tibble(auto_split$test)
  
  results <- data_frame(terms = 1:5,
                        model = map(terms, auto_poly_glm),
                        MSE = map_dbl(model, mse, data = auto_test))
  
  return(results)
}

rerun(10, mse_variable(Auto)) %>%
  bind_rows(.id = "id") %>%
  ggplot(aes(terms, MSE, color = id)) +
  geom_line() +
  labs(title = "Variability of MSE estimates",
       subtitle = "Using the validation set approach",
       x = "Degree of Polynomial",
       y = "Mean Squared Error") +
  theme(legend.position = "none")
```

## Leave-one-out cross-validation

$$CV_{(n)} = \frac{1}{n} \sum_{i = 1}^{n}{MSE_i}$$

* Extension of validation set to repeatedly split data and average results
* Minimizes bias of estimated error rate
* Low variance
* Highly computationally intensive

## LOOCV in linear regression {.scrollable}

```{r loocv-data, dependson="Auto", echo = TRUE}
(loocv_data <- crossv_kfold(Auto, k = nrow(Auto)))
```

```{r loocv, dependson="Auto", echo = TRUE}
(loocv_models <- map(loocv_data$train, ~ lm(mpg ~ horsepower, data = .)))
(loocv_mse <- map2_dbl(loocv_models, loocv_data$test, mse))
mean(loocv_mse)
```

## LOOCV in linear regression

```{r loocv_poly, dependson="Auto"}
cv_error <- vector("numeric", 5)
terms <- 1:5

for(i in terms){
  loocv_models <- map(loocv_data$train, ~ lm(mpg ~ poly(horsepower, i),
                                             data = .)
  )
  loocv_mse <- map2_dbl(loocv_models, loocv_data$test, mse)
  cv_error[[i]] <- mean(loocv_mse)
}

cv_mse <- data_frame(terms = terms,
                     cv_MSE = cv_error)

ggplot(cv_mse, aes(terms, cv_MSE)) +
  geom_line() +
  labs(title = "Comparing quadratic linear models",
       subtitle = "Using LOOCV",
       x = "Highest-order polynomial",
       y = "Mean Squared Error")
```

## LOOCV in classification

```{r mse-glm}
mse.glm <- function (model, data){
  residuals.glm <- function(model, data) {
    modelr:::response(model, data) - stats::predict(model,
                                                    data,
                                                    type = "response")
  }
  
  x <- residuals(model, data)
  mean(x^2, na.rm = TRUE)
}
```

```{r titanic_loocv, echo = TRUE}
titanic_loocv <- crossv_kfold(titanic, k = nrow(titanic))
titanic_models <- map(titanic_loocv$train, ~ glm(Survived ~ Age * Sex,
                                                 data = .,
                                                 family = binomial))
titanic_mse <- map2_dbl(titanic_models, titanic_loocv$test, mse.glm)
mean(titanic_mse, na.rm = TRUE)
```

## Exercise: LOOCV in linear regression

![](https://thealexcreed.files.wordpress.com/2014/05/liftbitch.jpg)

## $k$-fold cross-validation

$$CV_{(k)} = \frac{1}{k} \sum_{i = 1}^{k}{MSE_i}$$

* Split data into $k$ folds
* Repeat training/test process for each fold
* LOOCV: $k=n$

## k-fold CV in linear regression

```r
cv10_data <- crossv_kfold(Auto, k = 10)
```

```{r 10_fold_auto}
cv10_data <- crossv_kfold(Auto, k = 10)

cv_error_fold10 <- vector("numeric", 5)
terms <- 1:5

for(i in terms){
  cv10_models <- map(cv10_data$train, ~ lm(mpg ~ poly(horsepower, i),
                                           data = .)
  )
  cv10_mse <- map2_dbl(cv10_models, cv10_data$test, mse)
  cv_error_fold10[[i]] <- mean(cv10_mse)
}
```

```{r 10_fold_auto_loocv, dependson=c("10_fold_auto","loocv_poly")}
data_frame(terms = terms,
           loocv = cv_error,
           fold10 = cv_error_fold10) %>%
  gather(method, MSE, loocv:fold10) %>%
  ggplot(aes(terms, MSE, color = method)) +
  geom_line() +
  labs(title = "MSE estimates",
       x = "Degree of Polynomial",
       y = "Mean Squared Error",
       color = "CV Method")
```

## Computational speed of LOOCV

```{r loocv_time}
library(profvis)

profvis({
  cv_error <- vector("numeric", 5)
  terms <- 1:5
  
  for(i in terms){
    loocv_models <- map(loocv_data$train, ~ lm(mpg ~ poly(horsepower, i), data = .))
    loocv_mse <- map2_dbl(loocv_models, loocv_data$test, mse)
    cv_error[[i]] <- mean(loocv_mse)
  }
})
```

## Computational speed of 10-fold CV

```{r kfold_time}
profvis({
  cv_error_fold10 <- vector("numeric", 5)
  terms <- 1:5
  
  for(i in terms){
    cv10_models <- map(cv10_data$train, ~ lm(mpg ~ poly(horsepower, i), data = .))
    cv10_mse <- map2_dbl(cv10_models, cv10_data$test, mse)
    cv_error_fold10[[i]] <- mean(cv10_mse)
  }
})
```

## k-fold CV in logistic regression

```{r titanic_kfold, echo = TRUE}
titanic_kfold <- crossv_kfold(titanic, k = 10)
titanic_models <- map(titanic_kfold$train, ~ glm(Survived ~ Age * Sex,
                                                 data = .,
                                                 family = binomial))
titanic_mse <- map2_dbl(titanic_models, titanic_kfold$test, mse.glm)
mean(titanic_mse, na.rm = TRUE)
```

## Exercise: k-fold CV

![](http://www.crossfitnbs.com/wp-content/uploads/2017/07/dwight.jpg)
