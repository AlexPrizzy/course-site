---
title: "Text analysis: classification and topic modeling"
author: |
  | MACS 30500
  | University of Chicago
date: "November 22, 2017"
output: rcfss::cfss_slides
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(cache = TRUE,
                      message = FALSE,
                      warning = FALSE,
                      echo = FALSE)

library(tidyverse)
library(tidytext)
library(stringr)
library(caret)
library(tm)

set.seed(1234)
theme_set(theme_minimal(base_size = 18))
```

## Supervised learning

1. Hand-code a small set of documents ($N = 1000$)
1. Train a statistical learning model on the hand-coded data
1. Evaluate the effectiveness of the statistical learning model
1. Apply the final model to the remaining set of documents ($N = 1000000$)

* Text classification

## `USCongress`

```{r get-docs}
data(USCongress, package = "RTextTools")

congress <- as_tibble(USCongress) %>%
  mutate(text = as.character(text))
str(congress)
```

* Set of hand-coded bills from US Congress
* Text description
* Major policy topic

## Create tidy text data frame {.scrollable}

```{r convert-tidytext, echo = TRUE}
(congress_tokens <- congress %>%
   unnest_tokens(output = word, input = text) %>%
   filter(!str_detect(word, "^[0-9]*$")) %>%
   anti_join(stop_words) %>%
   mutate(word = SnowballC::wordStem(word)))
```

## Create document-term matrix

```{r dtm, echo = TRUE}
(congress_dtm <- congress_tokens %>%
   count(ID, word) %>%
   cast_dtm(document = ID, term = word, value = n))
```

## Weighting

* Term frequency (tf)
* Term frequency-inverse document frequency (tf-idf)

## Weighting

```{r dtm-tf-idf, echo = TRUE}
congress_tokens %>%
  count(ID, word) %>%
  cast_dtm(document = ID, term = word, value = n,
           weighting = tm::weightTfIdf)
```

## Sparsity {.scrollable}

```{r removesparseterms, echo = TRUE}
removeSparseTerms(congress_dtm, sparse = .99)
removeSparseTerms(congress_dtm, sparse = .95)
removeSparseTerms(congress_dtm, sparse = .90)
```

```{r remove-sparse-terms-final}
congress_dtm <- removeSparseTerms(congress_dtm, sparse = .99)
```

## Exploratory analysis

```{r bind-tf-idf}
congress_tfidf <- congress_tokens %>%
  count(major, word) %>%
  bind_tf_idf(term_col = word, document_col = major, n_col = n)
```

```{r plot-tf-idf}
# sort the data frame and convert word to a factor column
plot_congress <- congress_tfidf %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word))))

# graph the top 10 tokens for 4 categories
plot_congress %>%
  filter(major %in% c(1:3, 6)) %>%
  mutate(major = factor(major, levels = c(1:3, 6),
                        labels = c("Macroeconomics", "Civil Rights",
                                   "Health", "Education"))) %>%
  group_by(major) %>%
  top_n(10) %>%
  ungroup() %>%
  ggplot(aes(word, tf_idf)) +
  geom_col() +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~major, scales = "free") +
  coord_flip()
```

## Estimate model

```r
congress_rf <- train(x = as.matrix(congress_dtm),
                     y = factor(congress$major),
                     method = "rf",
                     ntree = 200,
                     trControl = trainControl(method = "oob"))
```

```{r rf-train-10, eval = FALSE}
congress_rf_10 <- train(x = as.matrix(congress_dtm),
                        y = factor(congress$major),
                        method = "rf",
                        ntree = 10,
                        trControl = trainControl(method = "oob"))
```

```{r rf-train-200}
congress_rf_200 <- train(x = as.matrix(congress_dtm),
                         y = factor(congress$major),
                         method = "rf",
                         ntree = 200,
                         trControl = trainControl(method = "oob"))
```

## Evaluate model

```{r rf-error, echo = TRUE}
congress_rf_200$finalModel
```

## Evaluate model

```{r rf-varimp}
varImpPlot(congress_rf_200$finalModel)
```

## Topic modeling

* Keywords
* Links
* Themes
* Probabilistic topic models
    * Latent Dirichlet allocation

## Food and animals

1. I ate a banana and spinach smoothie for breakfast.
1. I like to eat broccoli and bananas.
1. Chinchillas and kittens are cute.
1. My sister adopted a kitten yesterday.
1. Look at this cute hamster munching on a piece of broccoli.

## LDA document structure

* Decide on the number of words N the document will have
    * [Dirichlet probability distribution](https://en.wikipedia.org/wiki/Dirichlet_distribution)
    * Fixed set of $k$ topics
* Generate each word in the document:
    * Pick a topic
    * Generate the word
* LDA backtracks from this assumption

## Food and animals

* Decide that $D$ will be 1/2 about food and 1/2 about cute animals.
* Pick 5 to be the number of words in $D$.
* Pick the first word to come from the food topic
* Pick the second word to come from the cute animals topic
* Pick the third word to come from the cute animals topic
* Pick the fourth word to come from the food topic
* Pick the fifth word to come from the food topic

## LDA with a known topic structure

* *Great Expectations* by Charles Dickens
* *The War of the Worlds* by H.G. Wells
* *Twenty Thousand Leagues Under the Sea* by Jules Verne
* *Pride and Prejudice* by Jane Austen

```{r topic_books, include = FALSE}
titles <- c("Twenty Thousand Leagues under the Sea", "The War of the Worlds",
            "Pride and Prejudice", "Great Expectations")

library(gutenbergr)

books <- gutenberg_works(title %in% titles) %>%
  gutenberg_download(meta_fields = "title", mirror = "ftp://aleph.gutenberg.org/")
```

```{r word_counts, dependson = "topic_books", include = FALSE, echo = TRUE}
library(tidytext)
library(stringr)

by_chapter <- books %>%
  group_by(title) %>%
  mutate(chapter = cumsum(str_detect(text, regex("^chapter ", ignore_case = TRUE)))) %>%
  ungroup() %>%
  filter(chapter > 0)

by_chapter_word <- by_chapter %>%
  unite(title_chapter, title, chapter) %>%
  unnest_tokens(word, text)

word_counts <- by_chapter_word %>%
  anti_join(stop_words) %>%
  count(title_chapter, word, sort = TRUE) %>%
  ungroup()

word_counts
```

## `topicmodels`

```{r chapters_dtm}
chapters_dtm <- word_counts %>%
  cast_dtm(title_chapter, word, n)
chapters_dtm
```

```{r chapters_lda, include = FALSE}
library(topicmodels)
chapters_lda <- LDA(chapters_dtm, k = 4, control = list(seed = 1234))
chapters_lda
```

## Terms associated with each topic

```{r chapters_lda_td, include = FALSE}
library(tidytext)

chapters_lda_td <- tidy(chapters_lda)
chapters_lda_td
```

```{r top_terms, include = FALSE}
top_terms <- chapters_lda_td %>%
  group_by(topic) %>%
  top_n(5, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)
top_terms
```

```{r top_terms_plot, fig.height=6, fig.width=7}
top_terms %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip()
```

## Per-document classification

```{r chapters_lda_gamma_raw, include = FALSE}
chapters_lda_gamma <- tidy(chapters_lda, matrix = "gamma")
chapters_lda_gamma
```

```{r chapters_lda_gamma, include = FALSE}
chapters_lda_gamma <- chapters_lda_gamma %>%
  separate(document, c("title", "chapter"), sep = "_", convert = TRUE)
chapters_lda_gamma
```

```{r chapters_lda_gamma_plot, fig.width=8, fig.height=6}
ggplot(chapters_lda_gamma, aes(gamma, fill = factor(topic))) +
  geom_histogram() +
  facet_wrap(~ title, nrow = 2)
```

```{r chapter_classifications, include = FALSE}
chapter_classifications <- chapters_lda_gamma %>%
  group_by(title, chapter) %>%
  top_n(1, gamma) %>%
  ungroup() %>%
  arrange(gamma)

chapter_classifications
```

## Consensus topic

```{r book_topics}
book_topics <- chapter_classifications %>%
  count(title, topic) %>%
  group_by(title) %>%
  top_n(1, n) %>%
  ungroup() %>%
  transmute(consensus = title, topic)

book_topics
```

## Mis-identification

```{r misidentification, echo = TRUE, dependson="book_topics"}
chapter_classifications %>%
  inner_join(book_topics, by = "topic") %>%
  count(title, consensus) %>%
  knitr::kable()
```

## Incorrectly classified words

```{r assignments, include = FALSE}
assignments <- augment(chapters_lda, data = chapters_dtm)
```

```{r assignments2, dependson = c("assignments", "book_topics"), include = FALSE}
assignments <- assignments %>%
  separate(document, c("title", "chapter"), sep = "_", convert = TRUE) %>%
  inner_join(book_topics, by = c(".topic" = "topic"))

assignments
```

```{r dependson = "assignments2"}
assignments %>%
  count(title, consensus, wt = count) %>%
  spread(consensus, n, fill = 0) %>%
  knitr::kable()
```

## Most commonly mistaken words

```{r wrong_words, dependson = "assignments2"}
wrong_words <- assignments %>%
  filter(title != consensus)

wrong_words %>%
  count(title, consensus, term, wt = count) %>%
  ungroup() %>%
  arrange(desc(n))
```

```{r dependson = "word_counts", include = FALSE}
word_counts %>%
  filter(word == "flopson")
```

## Associated Press articles

```{r associated_press, include = FALSE}
data("AssociatedPress", package = "topicmodels")

ap_td <- tidy(AssociatedPress)
ap_td
```

```{r ap_stopwords, dependson = "associated_press"}
ap_dtm <- ap_td %>%
  anti_join(stop_words, by = c(term = "word")) %>%
  cast_dtm(document, term, count)
ap_dtm
```

----

```{r ap_topic_4, dependson = "associated_press", include = FALSE}
ap_lda <- LDA(ap_dtm, k = 4, control = list(seed = 1234))
ap_lda
```

```{r ap_4_topn}
ap_lda_td <- tidy(ap_lda)

top_terms <- ap_lda_td %>%
  group_by(topic) %>%
  top_n(5, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

top_terms %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free", ncol = 2) +
  coord_flip()
```

----

```{r ap_topic_12, dependson = "associated_press", include = FALSE}
ap_lda <- LDA(ap_dtm, k = 12, control = list(seed = 1234))
ap_lda
```

```{r ap_12_topn, dependson="ap_topic_12", fig.height = 8}
ap_lda_td <- tidy(ap_lda)

top_terms <- ap_lda_td %>%
  group_by(topic) %>%
  top_n(5, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

top_terms %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free", ncol = 3) +
  coord_flip()
```

## Perplexity

* A statistical measure of how well a probability model predicts a sample
* Given the theoretical word distributions represented by the topics, compare that to the actual topic mixtures, or distribution of words in your documents
* Perplexity for LDA model with 12 topics
    * `r topicmodels::perplexity(ap_lda)`

```{r ap_12_perplex, dependson="ap_topic_12", include = FALSE}
perplexity(ap_lda)
```

----

```{r ap_lda_compare, dependson="associated_press", include = FALSE}
n_topics <- c(2, 4, 10, 20, 50, 100)

if(file.exists("../extras/ap_lda_compare.Rdata")){
  load(file = "../extras/ap_lda_compare.Rdata")
} else{
  ap_lda_compare <- n_topics %>%
    map(LDA, x = ap_dtm, control = list(seed = 1234))
}
```

```{r ap_lda_compare_viz, dependson="ap_lda_compare"} 
data_frame(k = n_topics,
           perplex = map_dbl(ap_lda_compare, perplexity)) %>%
  ggplot(aes(k, perplex)) +
  geom_point() +
  geom_line() +
  labs(title = "Evaluating LDA topic models",
       subtitle = "Optimal number of topics (smaller is better)",
       x = "Number of topics",
       y = "Perplexity")
```

## Topics from $k=100$

```{r ap_100_topn, dependson="ap_lda_compare"}
ap_lda_td <- tidy(ap_lda_compare[[6]])

top_terms <- ap_lda_td %>%
  group_by(topic) %>%
  top_n(5, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

top_terms %>%
  filter(topic <= 9) %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free", ncol = 3) +
  coord_flip()
```
