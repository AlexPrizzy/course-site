<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Statistical learning: resampling methods</title>

<script src="site_libs/jquery-1.12.4/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/readable.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/htmlwidgets-1.2/htmlwidgets.js"></script>
<script src="site_libs/d3-3.5.6/d3.min.js"></script>
<link href="site_libs/profvis-0.3.5/profvis.css" rel="stylesheet" />
<script src="site_libs/profvis-0.3.5/profvis.js"></script>
<link href="site_libs/highlight-6.2.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlight-6.2.0/highlight.js"></script>
<script src="site_libs/profvis-binding-0.3.5/profvis.js"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-45631879-2', 'auto');
  ga('send', 'pageview');

</script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 66px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 71px;
  margin-top: -71px;
}

.section h2 {
  padding-top: 71px;
  margin-top: -71px;
}
.section h3 {
  padding-top: 71px;
  margin-top: -71px;
}
.section h4 {
  padding-top: 71px;
  margin-top: -71px;
}
.section h5 {
  padding-top: 71px;
  margin-top: -71px;
}
.section h6 {
  padding-top: 71px;
  margin-top: -71px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Computing for the Social Sciences</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="faq.html">FAQ</a>
</li>
<li>
  <a href="syllabus.html">Syllabus</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Statistical learning: resampling methods</h1>

</div>


<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(modelr)
<span class="kw">library</span>(broom)
<span class="kw">set.seed</span>(<span class="dv">1234</span>)

<span class="kw">theme_set</span>(<span class="kw">theme_minimal</span>())</code></pre></div>
<div id="resampling-methods" class="section level1">
<h1>Resampling methods</h1>
<p>Resampling methods are essential to test and evaluate statistical models. Because you likely do not have the resources or capabilities to repeatedly sample from your population of interest, instead you can repeatedly draw from your original sample to obtain additional information about your model. For instance, you could repeatedly draw samples from your data, estimate a linear regression model on each sample, and then examine how the estimated model differs across each sample. This allows you to assess the variability and stability of your model in a way not possible if you can only fit the model once.</p>
</div>
<div id="validation-set" class="section level1">
<h1>Validation set</h1>
<p>One issue with using the same data to both fit and evaluate our model is that we will bias our model towards fitting the data that we have. We may fit our function to create the results we expect or desire, rather than the “true” function. Instead, we can split our data into distinct <strong>training</strong> and <strong>test</strong> sets. The training set can be used repeatedly to explore or train different models. Once we have a stable model, we can apply it to the test set of held-out data to determine (unbiasedly) whether the model makes accurate predictions.</p>
<div id="regression" class="section level2">
<h2>Regression</h2>
<p>Here we will examine the relationship between horsepower and car mileage in the <code>Auto</code> dataset (found in <code>library(ISLR)</code>):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ISLR)

Auto &lt;-<span class="st"> </span><span class="kw">as_tibble</span>(Auto)
Auto</code></pre></div>
<pre><code>## # A tibble: 392 x 9
##      mpg cylinders displacement horsepower weight acceleration  year
##  * &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;        &lt;dbl&gt; &lt;dbl&gt;
##  1    18         8          307        130   3504         12.0    70
##  2    15         8          350        165   3693         11.5    70
##  3    18         8          318        150   3436         11.0    70
##  4    16         8          304        150   3433         12.0    70
##  5    17         8          302        140   3449         10.5    70
##  6    15         8          429        198   4341         10.0    70
##  7    14         8          454        220   4354          9.0    70
##  8    14         8          440        215   4312          8.5    70
##  9    14         8          455        225   4425         10.0    70
## 10    15         8          390        190   3850          8.5    70
## # ... with 382 more rows, and 2 more variables: origin &lt;dbl&gt;, name &lt;fctr&gt;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(Auto, <span class="kw">aes</span>(horsepower, mpg)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>()</code></pre></div>
<p><img src="stat005_resampling_files/figure-html/auto_plot-1.png" width="672" /></p>
<p>The relationship does not appear to be strictly linear:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(Auto, <span class="kw">aes</span>(horsepower, mpg)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>)</code></pre></div>
<p><img src="stat005_resampling_files/figure-html/auto_plot_lm-1.png" width="672" /></p>
<p>Perhaps by adding <a href="stat003_logistic_regression.html#quadratic_terms">quadratic terms</a> to the linear regression we could improve overall model fit. To evaluate the model, we will split the data into a training set and test set, estimate a series of higher-order models, and calculate a test statistic summarizing the accuracy of the estimated <code>mpg</code>. To calculate the accuracy of the model, we will use <strong>Mean Squared Error</strong> (MSE), defined as</p>
<p><span class="math display">\[MSE = \frac{1}{n} \sum_{i = 1}^{n}{(y_i - \hat{f}(x_i))^2}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(y_i =\)</span> the observed response value for the <span class="math inline">\(i\)</span>th observation</li>
<li><span class="math inline">\(\hat{f}(x_i) =\)</span> the predicted response value for the <span class="math inline">\(i\)</span>th observation given by <span class="math inline">\(\hat{f}\)</span></li>
<li><span class="math inline">\(n =\)</span> the total number of observations</li>
</ul>
<p>Boo math! Actually this is pretty intuitive. All we’re doing is for each observation, calculating the difference between the actual and predicted values for <span class="math inline">\(y\)</span>, squaring that difference, then calculating the average across all observations. An MSE of 0 indicates the model perfectly predicted each observation. The larger the MSE, the more error in the model.</p>
<p>For this task, first we can use <code>modelr::resample_partition()</code> to create training and test sets (using a 50/50 split), then estimate a linear regression model without any quadratic terms.</p>
<ul>
<li>I use <code>set.seed()</code> in the beginning - whenever you are writing a script that involves randomization (here, random subsetting of the data), always set the seed at the beginning of the script. This ensures the results can be reproduced precisely.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></li>
<li>I also use the <code>glm()</code> function rather than <code>lm()</code> - if you don’t change the <code>family</code> parameter, the results of <code>lm()</code> and <code>glm()</code> are exactly the same.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1234</span>)

auto_split &lt;-<span class="st"> </span><span class="kw">resample_partition</span>(Auto, <span class="kw">c</span>(<span class="dt">test =</span> <span class="fl">0.5</span>, <span class="dt">train =</span> <span class="fl">0.5</span>))
auto_train &lt;-<span class="st"> </span><span class="kw">as_tibble</span>(auto_split<span class="op">$</span>train)
auto_test &lt;-<span class="st"> </span><span class="kw">as_tibble</span>(auto_split<span class="op">$</span>test)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">auto_lm &lt;-<span class="st"> </span><span class="kw">glm</span>(mpg <span class="op">~</span><span class="st"> </span>horsepower, <span class="dt">data =</span> auto_train)
<span class="kw">summary</span>(auto_lm)</code></pre></div>
<pre><code>## 
## Call:
## glm(formula = mpg ~ horsepower, data = auto_train)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -12.892   -2.864   -0.545    2.793   13.298  
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 38.005404   0.921129   41.26   &lt;2e-16 ***
## horsepower  -0.140459   0.007968  -17.63   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 20.48452)
## 
##     Null deviance: 10359.4  on 196  degrees of freedom
## Residual deviance:  3994.5  on 195  degrees of freedom
## AIC: 1157.9
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<p>To estimate the MSE for a single partition (i.e. for a training or test set), I wrote a special function <code>mse()</code>:<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mse &lt;-<span class="st"> </span><span class="cf">function</span>(model, data) {
  x &lt;-<span class="st"> </span>modelr<span class="op">:::</span><span class="kw">residuals</span>(model, data)
  <span class="kw">mean</span>(x <span class="op">^</span><span class="st"> </span><span class="dv">2</span>, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mse</span>(auto_lm, auto_test)</code></pre></div>
<pre><code>## [1] 28.57255</code></pre>
<p>For a strictly linear model, the MSE for the test set is 28.57. How does this compare to a quadratic model? We can use the <code>poly()</code> function in conjunction with a <code>map()</code> iteration to estimate the MSE for a series of models with higher-order polynomial terms:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># write a custom model function</span>
auto_poly_glm &lt;-<span class="st"> </span><span class="cf">function</span>(x){
  <span class="kw">glm</span>(mpg <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(horsepower, x), <span class="dt">data =</span> auto_train)
}

<span class="co"># estimate models with higher order polynomials</span>
auto_poly_results &lt;-<span class="st"> </span><span class="kw">data_frame</span>(<span class="dt">terms =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">1</span>, <span class="dt">to =</span> <span class="dv">5</span>),
                                <span class="dt">model =</span> <span class="kw">map</span>(terms, auto_poly_glm),
                                <span class="dt">MSE =</span> <span class="kw">map_dbl</span>(model,
                                              mse,
                                              <span class="dt">data =</span> auto_test)
)

<span class="co"># visualize each model</span>
<span class="kw">data_grid</span>(Auto, horsepower) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gather_predictions</span>(<span class="st">`</span><span class="dt">1</span><span class="st">`</span> =<span class="st"> </span>auto_poly_results<span class="op">$</span>model[[<span class="dv">1</span>]],
                     <span class="st">`</span><span class="dt">2</span><span class="st">`</span> =<span class="st"> </span>auto_poly_results<span class="op">$</span>model[[<span class="dv">2</span>]],
                     <span class="st">`</span><span class="dt">3</span><span class="st">`</span> =<span class="st"> </span>auto_poly_results<span class="op">$</span>model[[<span class="dv">3</span>]],
                     <span class="st">`</span><span class="dt">4</span><span class="st">`</span> =<span class="st"> </span>auto_poly_results<span class="op">$</span>model[[<span class="dv">4</span>]],
                     <span class="st">`</span><span class="dt">5</span><span class="st">`</span> =<span class="st"> </span>auto_poly_results<span class="op">$</span>model[[<span class="dv">5</span>]]) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(horsepower, pred)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> Auto, <span class="kw">aes</span>(<span class="dt">y =</span> mpg), <span class="dt">alpha =</span> .<span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">color =</span> model)) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_color_brewer</span>(<span class="dt">type =</span> <span class="st">&quot;qual&quot;</span>, <span class="dt">palette =</span> <span class="st">&quot;Dark2&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Horsepower&quot;</span>,
       <span class="dt">y =</span> <span class="st">&quot;MPG&quot;</span>,
       <span class="dt">color =</span> <span class="st">&quot;Highest-order</span><span class="ch">\n</span><span class="st">polynomial&quot;</span>)</code></pre></div>
<p><img src="stat005_resampling_files/figure-html/mse_poly-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compare mse</span>
<span class="kw">ggplot</span>(auto_poly_results, <span class="kw">aes</span>(terms, MSE)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Comparing quadratic linear models&quot;</span>,
       <span class="dt">subtitle =</span> <span class="st">&quot;Using validation set&quot;</span>,
       <span class="dt">x =</span> <span class="st">&quot;Highest-order polynomial&quot;</span>,
       <span class="dt">y =</span> <span class="st">&quot;Mean Squared Error&quot;</span>)</code></pre></div>
<p><img src="stat005_resampling_files/figure-html/mse_poly-2.png" width="672" /></p>
<p>Based on the MSE for the validation (test) set, a polynomial model with a quadratic term (<span class="math inline">\(\text{horsepower}^2\)</span>) produces the lowest average error. Adding cubic or higher-order terms is just not necessary.</p>
</div>
<div id="classification" class="section level2">
<h2>Classification</h2>
<p>Recall our efforts to <a href="stat003_logistic_regression.html#interactive_terms">predict passenger survival during the sinking of the Titanic</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(titanic)
titanic &lt;-<span class="st"> </span><span class="kw">as_tibble</span>(titanic_train)

titanic <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">head</span>() <span class="op">%&gt;%</span>
<span class="st">  </span>knitr<span class="op">::</span><span class="kw">kable</span>()</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">PassengerId</th>
<th align="right">Survived</th>
<th align="right">Pclass</th>
<th align="left">Name</th>
<th align="left">Sex</th>
<th align="right">Age</th>
<th align="right">SibSp</th>
<th align="right">Parch</th>
<th align="left">Ticket</th>
<th align="right">Fare</th>
<th align="left">Cabin</th>
<th align="left">Embarked</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">0</td>
<td align="right">3</td>
<td align="left">Braund, Mr. Owen Harris</td>
<td align="left">male</td>
<td align="right">22</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="left">A/5 21171</td>
<td align="right">7.2500</td>
<td align="left"></td>
<td align="left">S</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="left">Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td>
<td align="left">female</td>
<td align="right">38</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="left">PC 17599</td>
<td align="right">71.2833</td>
<td align="left">C85</td>
<td align="left">C</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">1</td>
<td align="right">3</td>
<td align="left">Heikkinen, Miss. Laina</td>
<td align="left">female</td>
<td align="right">26</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="left">STON/O2. 3101282</td>
<td align="right">7.9250</td>
<td align="left"></td>
<td align="left">S</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="left">Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
<td align="left">female</td>
<td align="right">35</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="left">113803</td>
<td align="right">53.1000</td>
<td align="left">C123</td>
<td align="left">S</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">0</td>
<td align="right">3</td>
<td align="left">Allen, Mr. William Henry</td>
<td align="left">male</td>
<td align="right">35</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="left">373450</td>
<td align="right">8.0500</td>
<td align="left"></td>
<td align="left">S</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">0</td>
<td align="right">3</td>
<td align="left">Moran, Mr. James</td>
<td align="left">male</td>
<td align="right">NA</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="left">330877</td>
<td align="right">8.4583</td>
<td align="left"></td>
<td align="left">Q</td>
</tr>
</tbody>
</table>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">survive_age_woman_x &lt;-<span class="st"> </span><span class="kw">glm</span>(Survived <span class="op">~</span><span class="st"> </span>Age <span class="op">*</span><span class="st"> </span>Sex, <span class="dt">data =</span> titanic,
                           <span class="dt">family =</span> binomial)
<span class="kw">summary</span>(survive_age_woman_x)</code></pre></div>
<pre><code>## 
## Call:
## glm(formula = Survived ~ Age * Sex, family = binomial, data = titanic)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.9401  -0.7136  -0.5883   0.7626   2.2455  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)   
## (Intercept)  0.59380    0.31032   1.913  0.05569 . 
## Age          0.01970    0.01057   1.863  0.06240 . 
## Sexmale     -1.31775    0.40842  -3.226  0.00125 **
## Age:Sexmale -0.04112    0.01355  -3.034  0.00241 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 964.52  on 713  degrees of freedom
## Residual deviance: 740.40  on 710  degrees of freedom
##   (177 observations deleted due to missingness)
## AIC: 748.4
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>We can use the same validation set approach to evaluate the model’s accuracy. For classification models, instead of using MSE we examine the <strong>test error rate</strong>. That is, of all the predictions generated for the test set, what percentage of predictions are incorrect? The goal is to minimize this value as much as possible (ideally, until we make no errors and our error rate is <span class="math inline">\(0%\)</span>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># function to convert log-odds to probabilities</span>
logit2prob &lt;-<span class="st"> </span><span class="cf">function</span>(x){
  <span class="kw">exp</span>(x) <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(x))
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">titanic_split &lt;-<span class="st"> </span><span class="kw">resample_partition</span>(titanic, <span class="kw">c</span>(<span class="dt">test =</span> <span class="fl">0.3</span>, <span class="dt">train =</span> <span class="fl">0.7</span>))
<span class="kw">map</span>(titanic_split, dim)</code></pre></div>
<pre><code>## $test
## [1] 267  12
## 
## $train
## [1] 624  12</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">train_model &lt;-<span class="st"> </span><span class="kw">glm</span>(Survived <span class="op">~</span><span class="st"> </span>Age <span class="op">*</span><span class="st"> </span>Sex, <span class="dt">data =</span> titanic_split<span class="op">$</span>train,
                   <span class="dt">family =</span> binomial)
<span class="kw">summary</span>(train_model)</code></pre></div>
<pre><code>## 
## Call:
## glm(formula = Survived ~ Age * Sex, family = binomial, data = titanic_split$train)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.0027  -0.7056  -0.6274   0.6999   2.0394  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  0.86045    0.38879   2.213 0.026886 *  
## Age          0.01755    0.01307   1.343 0.179157    
## Sexmale     -1.83123    0.50484  -3.627 0.000286 ***
## Age:Sexmale -0.02974    0.01642  -1.812 0.070040 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 687.03  on 504  degrees of freedom
## Residual deviance: 512.91  on 501  degrees of freedom
##   (119 observations deleted due to missingness)
## AIC: 520.91
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x_test_accuracy &lt;-<span class="st"> </span>titanic_split<span class="op">$</span>test <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">add_predictions</span>(train_model) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">pred =</span> <span class="kw">logit2prob</span>(pred),
         <span class="dt">pred =</span> <span class="kw">as.numeric</span>(pred <span class="op">&gt;</span><span class="st"> </span>.<span class="dv">5</span>))

<span class="kw">mean</span>(x_test_accuracy<span class="op">$</span>Survived <span class="op">!=</span><span class="st"> </span>x_test_accuracy<span class="op">$</span>pred, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## [1] 0.2488038</code></pre>
<p>This interactive model generates an error rate of 24.9%. We could compare this error rate to alternative classification models, either other logistic regression models (using different formulas) or a tree-based method.</p>
</div>
<div id="drawbacks-to-validation-sets" class="section level2">
<h2>Drawbacks to validation sets</h2>
<p>There are two main problems with validation sets:</p>
<ol style="list-style-type: decimal">
<li><p>Validation estimates of the test error rates can be highly variable depending on which observations are sampled into the training and test sets. See what happens if we repeat the sampling, estimation, and validation procedure for the <code>Auto</code> data set:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mse_variable &lt;-<span class="st"> </span><span class="cf">function</span>(Auto){
  auto_split &lt;-<span class="st"> </span><span class="kw">resample_partition</span>(Auto, <span class="kw">c</span>(<span class="dt">test =</span> <span class="fl">0.5</span>, <span class="dt">train =</span> <span class="fl">0.5</span>))
  auto_train &lt;-<span class="st"> </span><span class="kw">as_tibble</span>(auto_split<span class="op">$</span>train)
  auto_test &lt;-<span class="st"> </span><span class="kw">as_tibble</span>(auto_split<span class="op">$</span>test)

  results &lt;-<span class="st"> </span><span class="kw">data_frame</span>(<span class="dt">terms =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">1</span>, <span class="dt">to =</span> <span class="dv">5</span>),
                        <span class="dt">model =</span> <span class="kw">map</span>(terms, auto_poly_glm),
                        <span class="dt">MSE =</span> <span class="kw">map_dbl</span>(model, mse, <span class="dt">data =</span> auto_test))

  <span class="kw">return</span>(results)
}

<span class="kw">rerun</span>(<span class="dv">10</span>, <span class="kw">mse_variable</span>(Auto)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">bind_rows</span>(<span class="dt">.id =</span> <span class="st">&quot;id&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(terms, MSE, <span class="dt">color =</span> id)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Variability of MSE estimates&quot;</span>,
       <span class="dt">subtitle =</span> <span class="st">&quot;Using the validation set approach&quot;</span>,
       <span class="dt">x =</span> <span class="st">&quot;Degree of Polynomial&quot;</span>,
       <span class="dt">y =</span> <span class="st">&quot;Mean Squared Error&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>)</code></pre></div>
<p><img src="stat005_resampling_files/figure-html/auto_variable_mse-1.png" width="672" /></p>
<p>Depending on the specific training/test split, our MSE varies by up to 5.</p></li>
<li><p>If you don’t have a large data set, you’ll have to dramatically shrink the size of your training set. Most statistical learning methods perform better with more observations - if you don’t have enough data in the training set, you might overestimate the error rate in the test set.</p></li>
</ol>
</div>
</div>
<div id="leave-one-out-cross-validation" class="section level1">
<h1>Leave-one-out cross-validation</h1>
<p>An alternative method is <strong>leave-one-out cross validation</strong> (LOOCV). Like with the validation set approach, you split the data into two parts. However the difference is that you only remove one observation for the test set, and keep all remaining observations in the training set. The statistical learning method is fit on the <span class="math inline">\(n-1\)</span> training set. You then use the held-out observation to calculate the <span class="math inline">\(MSE = (y_1 - \hat{y}_1)^2\)</span> which should be an unbiased estimator of the test error. Because this MSE is highly dependent on which observation is held out, <strong>we repeat this process for every single observation in the data set</strong>. Mathematically, this looks like:</p>
<p><span class="math display">\[CV_{(n)} = \frac{1}{n} \sum_{i = 1}^{n}{MSE_i}\]</span></p>
<p>This method produces estimates of the error rate that have minimal bias and are relatively steady (i.e. non-varying), unlike the validation set approach where the MSE estimate is highly dependent on the sampling process for training/test sets. LOOCV is also highly flexible and works with any kind of predictive modeling.</p>
<p>Of course the downside is that this method is computationally difficult. You have to estimate <span class="math inline">\(n\)</span> different models - if you have a large <span class="math inline">\(n\)</span> or each individual model takes a long time to compute, you may be stuck waiting a long time for the computer to finish its calculations.</p>
<div id="loocv-in-linear-regression" class="section level2">
<h2>LOOCV in linear regression</h2>
<p>We can use the <code>crossv_kfold()</code> function in the <code>modelr</code> library to compute the LOOCV of any linear or logistic regression model. It takes two arguments: the data frame and the number of <span class="math inline">\(k\)</span>-folds (which we will define shortly). For our purposes now, all you need to know is that <code>k</code> should equal the number of observations in the data frame which we can retrieve using the <code>nrow()</code> function. For the <code>Auto</code> dataset, this looks like:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">loocv_data &lt;-<span class="st"> </span><span class="kw">crossv_kfold</span>(Auto, <span class="dt">k =</span> <span class="kw">nrow</span>(Auto))</code></pre></div>
<p>Now we estimate the linear model <span class="math inline">\(k\)</span> times, excluding the holdout test observation, then calculate the MSE:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">loocv_models &lt;-<span class="st"> </span><span class="kw">map</span>(loocv_data<span class="op">$</span>train, <span class="op">~</span><span class="st"> </span><span class="kw">lm</span>(mpg <span class="op">~</span><span class="st"> </span>horsepower, <span class="dt">data =</span> .))
loocv_mse &lt;-<span class="st"> </span><span class="kw">map2_dbl</span>(loocv_models, loocv_data<span class="op">$</span>test, mse)
<span class="kw">mean</span>(loocv_mse)</code></pre></div>
<pre><code>## [1] 24.23151</code></pre>
<p>The results of the mapped <code>mse()</code> function is the MSE for each iteration through the data, so there is one MSE for each observation. Calculating the <code>mean()</code> of that vector gives us the LOOCV MSE.</p>
<p>We can also use this method to compare the optimal number of polynomial terms as before.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cv_error &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="st">&quot;numeric&quot;</span>, <span class="dv">5</span>)
terms &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">1</span>, <span class="dt">to =</span> <span class="dv">5</span>)

<span class="cf">for</span>(i <span class="cf">in</span> terms){
  loocv_models &lt;-<span class="st"> </span><span class="kw">map</span>(loocv_data<span class="op">$</span>train, <span class="op">~</span><span class="st"> </span><span class="kw">lm</span>(mpg <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(horsepower, i),
                                             <span class="dt">data =</span> .)
  )
  loocv_mse &lt;-<span class="st"> </span><span class="kw">map2_dbl</span>(loocv_models, loocv_data<span class="op">$</span>test, mse)
  cv_error[[i]] &lt;-<span class="st"> </span><span class="kw">mean</span>(loocv_mse)
}

cv_mse &lt;-<span class="st"> </span><span class="kw">data_frame</span>(<span class="dt">terms =</span> terms,
                     <span class="dt">cv_MSE =</span> cv_error)
cv_mse</code></pre></div>
<pre><code>## # A tibble: 5 x 2
##   terms cv_MSE
##   &lt;int&gt;  &lt;dbl&gt;
## 1     1   24.2
## 2     2   19.2
## 3     3   19.3
## 4     4   19.4
## 5     5   19.0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(cv_mse, <span class="kw">aes</span>(terms, cv_MSE)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Comparing quadratic linear models&quot;</span>,
       <span class="dt">subtitle =</span> <span class="st">&quot;Using LOOCV&quot;</span>,
       <span class="dt">x =</span> <span class="st">&quot;Highest-order polynomial&quot;</span>,
       <span class="dt">y =</span> <span class="st">&quot;Mean Squared Error&quot;</span>)</code></pre></div>
<p><img src="stat005_resampling_files/figure-html/loocv_poly-1.png" width="672" /></p>
<p>And arrive at a similar conclusion. There may be a very marginal advantage to adding a fifth-order polynomial, but not substantial enough for the additional complexity over a mere second-order polynomial.</p>
</div>
<div id="loocv-in-classification" class="section level2">
<h2>LOOCV in classification</h2>
<p>Let’s use classification to validate the interactive terms model from before. For technical reasons, we need to use a custom <code>mse.glm()</code> function to properly calculate the MSE for binary response variables:<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mse.glm &lt;-<span class="st"> </span><span class="cf">function</span> (model, data){
  residuals.glm &lt;-<span class="st"> </span><span class="cf">function</span>(model, data) {
    modelr<span class="op">:::</span><span class="kw">response</span>(model, data) <span class="op">-</span><span class="st"> </span>stats<span class="op">::</span><span class="kw">predict</span>(model,
                                                    data,
                                                    <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)
  }
  
  x &lt;-<span class="st"> </span><span class="kw">residuals</span>(model, data)
  <span class="kw">mean</span>(x<span class="op">^</span><span class="dv">2</span>, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">titanic_loocv &lt;-<span class="st"> </span><span class="kw">crossv_kfold</span>(titanic, <span class="dt">k =</span> <span class="kw">nrow</span>(titanic))
titanic_models &lt;-<span class="st"> </span><span class="kw">map</span>(titanic_loocv<span class="op">$</span>train, <span class="op">~</span><span class="st"> </span><span class="kw">glm</span>(Survived <span class="op">~</span><span class="st"> </span>Age <span class="op">*</span><span class="st"> </span>Sex,
                                                 <span class="dt">data =</span> .,
                                                 <span class="dt">family =</span> binomial))
titanic_mse &lt;-<span class="st"> </span><span class="kw">map2_dbl</span>(titanic_models, titanic_loocv<span class="op">$</span>test, mse.glm)
<span class="kw">mean</span>(titanic_mse, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## [1] 0.1703518</code></pre>
<p>In a classification problem, the LOOCV tells us the average error rate based on our predictions. So here, it tells us that the interactive <code>Age * Sex</code> model has a 17% error rate. This is similar to the validation set result (<span class="math inline">\(24.9\%\)</span>)</p>
</div>
<div id="exercise-loocv-in-linear-regression" class="section level2">
<h2>Exercise: LOOCV in linear regression</h2>
<ol style="list-style-type: decimal">
<li><p>Estimate the LOOCV MSE of a linear regression of the relationship between admission rate and cost in the <a href="stat002_linear_models.html#exercise:_linear_regression_with_scorecard"><code>scorecard</code> dataset</a>.</p>
<details> <summary>Click for the solution</summary>
<p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rcfss)

scorecard_loocv &lt;-<span class="st"> </span><span class="kw">crossv_kfold</span>(scorecard, <span class="dt">k =</span> <span class="kw">nrow</span>(scorecard)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">model =</span> <span class="kw">map</span>(train, <span class="op">~</span><span class="st"> </span><span class="kw">lm</span>(cost <span class="op">~</span><span class="st"> </span>admrate, <span class="dt">data =</span> .)),
         <span class="dt">mse =</span> <span class="kw">map2_dbl</span>(model, test, mse))
<span class="kw">mean</span>(scorecard_loocv<span class="op">$</span>mse, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## [1] 147752431</code></pre>
</p>
<p></details></p></li>
<li><p>Estimate the LOOCV MSE of a <a href="stat003_logistic_regression.html#exercise:_logistic_regression_with_mental_health">logistic regression model of voter turnout</a> using only <code>mhealth</code> as the predictor. Compare this to the LOOCV MSE of a logistic regression model using all available predictors. Which is the better model?</p>
<details> <summary>Click for the solution</summary>
<p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># basic model</span>
mh_loocv_lite &lt;-<span class="st"> </span><span class="kw">crossv_kfold</span>(mental_health, <span class="dt">k =</span> <span class="kw">nrow</span>(mental_health)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">model =</span> <span class="kw">map</span>(train, <span class="op">~</span><span class="st"> </span><span class="kw">glm</span>(vote96 <span class="op">~</span><span class="st"> </span>mhealth, <span class="dt">data =</span> .,
                                  <span class="dt">family =</span> binomial)),
         <span class="dt">mse =</span> <span class="kw">map2_dbl</span>(model, test, mse.glm))
<span class="kw">mean</span>(mh_loocv_lite<span class="op">$</span>mse, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## [1] 0.2092831</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># full model</span>
mh_loocv_full &lt;-<span class="st"> </span><span class="kw">crossv_kfold</span>(mental_health, <span class="dt">k =</span> <span class="kw">nrow</span>(mental_health)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">model =</span> <span class="kw">map</span>(train, <span class="op">~</span><span class="st"> </span><span class="kw">glm</span>(vote96 <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> .,
                                  <span class="dt">family =</span> binomial)),
         <span class="dt">mse =</span> <span class="kw">map2_dbl</span>(model, test, mse.glm))
<span class="kw">mean</span>(mh_loocv_full<span class="op">$</span>mse, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## [1] 0.1824597</code></pre>
<p>The full model is better and has a lower error rate.</p>
</p>
<p></details></p></li>
</ol>
</div>
</div>
<div id="k-fold-cross-validation" class="section level1">
<h1>k-fold cross-validation</h1>
<p>A less computationally-intensive approach to cross validation is <strong><span class="math inline">\(k\)</span>-fold cross-validation</strong>. Rather than dividing the data into <span class="math inline">\(n\)</span> groups, one divides the observations into <span class="math inline">\(k\)</span> groups, or <strong>folds</strong>, of approximately equal size. The first fold is treated as the validation set, and the model is estimated on the remaining <span class="math inline">\(k-1\)</span> folds. This process is repeated <span class="math inline">\(k\)</span> times, with each fold serving as the validation set precisely once. The <span class="math inline">\(k\)</span>-fold CV estimate is calculated by averaging the MSE values for each fold:</p>
<p><span class="math display">\[CV_{(k)} = \frac{1}{k} \sum_{i = 1}^{k}{MSE_i}\]</span></p>
<p>As you probably figured out by now, LOOCV is the special case of <span class="math inline">\(k\)</span>-fold cross-validation where <span class="math inline">\(k = n\)</span>. More typically researchers will use <span class="math inline">\(k=5\)</span> or <span class="math inline">\(k=10\)</span> depending on the size of the data set and the complexity of the statistical model.</p>
<div id="k-fold-cv-in-linear-regression" class="section level2">
<h2>k-fold CV in linear regression</h2>
<p>Let’s go back to the <code>Auto</code> data set. Instead of LOOCV, let’s use 10-fold CV to compare the different polynomial models.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cv10_data &lt;-<span class="st"> </span><span class="kw">crossv_kfold</span>(Auto, <span class="dt">k =</span> <span class="dv">10</span>)

cv_error_fold10 &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="st">&quot;numeric&quot;</span>, <span class="dv">5</span>)
terms &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">1</span>, <span class="dt">to =</span> <span class="dv">5</span>)

<span class="cf">for</span>(i <span class="cf">in</span> terms){
  cv10_models &lt;-<span class="st"> </span><span class="kw">map</span>(cv10_data<span class="op">$</span>train, <span class="op">~</span><span class="st"> </span><span class="kw">lm</span>(mpg <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(horsepower, i),
                                           <span class="dt">data =</span> .)
  )
  cv10_mse &lt;-<span class="st"> </span><span class="kw">map2_dbl</span>(cv10_models, cv10_data<span class="op">$</span>test, mse)
  cv_error_fold10[[i]] &lt;-<span class="st"> </span><span class="kw">mean</span>(cv10_mse)
}

cv_error_fold10</code></pre></div>
<pre><code>## [1] 24.46588 19.37772 19.51389 19.82524 19.36807</code></pre>
<p>How do these results compare to the LOOCV values?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data_frame</span>(<span class="dt">terms =</span> terms,
           <span class="dt">loocv =</span> cv_error,
           <span class="dt">fold10 =</span> cv_error_fold10) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gather</span>(method, MSE, loocv<span class="op">:</span>fold10) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(terms, MSE, <span class="dt">color =</span> method)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;MSE estimates&quot;</span>,
       <span class="dt">x =</span> <span class="st">&quot;Degree of Polynomial&quot;</span>,
       <span class="dt">y =</span> <span class="st">&quot;Mean Squared Error&quot;</span>,
       <span class="dt">color =</span> <span class="st">&quot;CV Method&quot;</span>)</code></pre></div>
<p><img src="stat005_resampling_files/figure-html/10_fold_auto_loocv-1.png" width="672" /></p>
<p>Pretty much the same results.</p>
</div>
<div id="computational-speed-of-loocv-vs.-k-fold-cv" class="section level2">
<h2>Computational speed of LOOCV vs. <span class="math inline">\(k\)</span>-fold CV</h2>
<div id="loocv" class="section level3">
<h3>LOOCV</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(profvis)

<span class="kw">profvis</span>({
  cv_error &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="st">&quot;numeric&quot;</span>, <span class="dv">5</span>)
  terms &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">1</span>, <span class="dt">to =</span> <span class="dv">5</span>)
  
  <span class="cf">for</span>(i <span class="cf">in</span> terms){
    loocv_models &lt;-<span class="st"> </span><span class="kw">map</span>(loocv_data<span class="op">$</span>train, <span class="op">~</span><span class="st"> </span><span class="kw">lm</span>(mpg <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(horsepower, i), <span class="dt">data =</span> .))
    loocv_mse &lt;-<span class="st"> </span><span class="kw">map2_dbl</span>(loocv_models, loocv_data<span class="op">$</span>test, mse)
    cv_error[[i]] &lt;-<span class="st"> </span><span class="kw">mean</span>(loocv_mse)
  }
})</code></pre></div>
<div id="htmlwidget-91bc29b1dd4828be45d4" style="width:100%;height:600px;" class="profvis html-widget"></div>
<script type="application/json" data-for="htmlwidget-91bc29b1dd4828be45d4">{"x":{"message":{"prof":{"time":[1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,16,16,16,16,16,17,17,17,17,17,17,17,17,17,17,17,17,18,18,18,18,18,18,18,19,19,19,19,19,19,19,19,19,19,19,19,20,20,20,20,20,20,20,20,20,20,20,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,22,22,22,22,22,22,22,22,22,22,22,22,23,23,23,23,23,23,23,23,23,23,23,23,23,24,24,24,24,24,24,24,24,24,24,24,25,25,25,25,25,25,25,25,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,27,27,27,27,27,27,28,28,28,28,28,28,28,28,29,29,29,29,29,29,29,29,29,29,29,29,29,30,30,30,30,30,30,30,30,30,31,31,31,31,31,31,31,31,32,32,32,32,32,32,32,33,33,33,33,33,33,33,34,34,34,34,34,34,34,34,34,34,34,34,35,35,35,35,35,35,35,35,35,35,35,35,35,36,36,36,36,36,36,36,36,37,37,37,37,37,37,37,37,37,37,37,37,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,39,39,39,39,39,39,39,39,39,39,39,40,40,40,40,40,40,40,40,40,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,42,42,42,42,42,42,42,42,42,42,42,43,43,43,43,43,43,43,43,43,43,43,43,44,44,44,44,44,44,44,45,45,45,45,45,45,45,46,46,46,46,46,46,46,46,47,47,47,47,47,47,47,47,47,47,47,47,47,48,48,48,48,48,48,48,48,48,48,48,49,49,49,49,49,49,49,49,49,49,49,49,50,50,50,50,50,50,50,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,52,52,52,52,52,52,52,52,52,53,53,53,53,53,53,53,53,53,53,53,54,54,54,54,54,54,54,54,54,54,54,54,54,55,55,55,55,55,55,55,55,55,55,55,55,56,56,56,56,56,56,56,56,56,56,56,56,56,56,56,57,57,57,57,57,57,57,57,57,57,57,58,58,58,58,58,58,58,58,58,58,58,58,58,59,59,59,59,59,59,59,59,59,59,59,59,59,60,60,60,60,60,60,60,60,61,61,61,61,61,61,61,61,61,62,62,62,62,62,62,63,63,63,63,63,63,63,63,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,65,65,65,65,65,66,66,66,66,66,66,66,67,67,67,67,67,67,67,67,67,67,67,68,68,68,68,68,68,68,69,69,69,69,69,69,69,70,70,70,70,70,70,70,70,70,70,71,71,71,71,71,71,71,71,71,71,71,72,72,72,72,72,72,72,72,72,72,72,72,72,73,73,73,73,73,73,73,73,73,73,74,74,74,74,74,74,74,74,74,74,74,74,75,75,75,75,75,75,75,75,75,75,75,75,76,76,76,76,76,76,76,76,76,76,76,76,77,77,77,77,77,77,77,77,77,77,77,78,78,78,78,78,78,78,78,78,78,78,78,78,79,79,79,79,79,79,79,79,79,79,79,79,79,80,80,80,80,80,80,80,80,80,80,80,80,80,81,81,81,81,81,81,81,81,81,81,82,82,82,82,82,82,82,82,82,82,82,82,82,83,83,83,83,83,84,84,84,84,84,84,84,84,84,84,84,84,84,85,85,85,85,85,85,85,85,85,85,85,85,85,85,85,86,86,86,86,86,86,86,87,87,87,87,87,87,87,87,87,87,87,87,87,88,88,88,88,88,89,89,89,89,89,89,89,89,89,89,89,89,90,90,90,90,90,90,90,90,90,90,90,90,91,91,91,91,91,91,91,91,91,91,91,91,92,92,92,92,92,92,92,92,92,92,92,92,92,93,93,93,93,93,93,94,94,94,94,94,94,94,94,94,94,94,94,95,95,95,95,95,95,95,96,96,96,96,96,96,96,96,96,96,96,96,96,96,97,97,97,97,97,97,97,97,97,97,97,97,97,98,98,98,98,98,98,98,98,98,98,98,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,100,100,100,100,100,100,100,101,101,101,101,101,101,101,101,101,102,102,102,102,102,103,103,104,104,104,104,104,104,104,104,105,105,105,105,105,105,105,105,105,105,105,106,106,106,106,106,106,106,106,106,107,107,107,107,107,107,107,107,107,107,107,107,107,107,108,108,108,108,108,108,109,109,109,109,109,109,109,109,110,110,110,110,110,110,110,111,111,111,111,111,111,111,111,111,111,111,111,112,112,112,112,112,112,112,112,112,112,112,112,113,113,113,113,113,113,113,113,113,113,113,113,114,114,114,114,114,114,114,115,115,115,115,115,116,116,116,116,116,116,116,116,116,116,116,116,116,117,117,117,117,117,118,118,118,118,118,118,118,118,118,119,119,119,119,119,119,119,119,119,119,119,120,120,120,120,121,121,121,121,121,121,122,122,122,122,122,122,122,122,122,122,122,123,123,123,123,123,123,124,124,124,124,124,124,124,125,125,125,125,125,125,126,126,126,126,126,126,126,127,127,127,127,127,127,127,127,127,128,128,128,128,128,128,128,128,128,128,128,128,129,129,129,129,129,129,129,129,130,130,130,130,130,130,131,131,131,131,131,131,131,131,131,132,132,132,132,132,132,132,132,133,133,133,133,133,133,134,134,134,134,134,134,135,135,135,135,135,135,135,135,135,135,135,136,136,136,136,136,136,136,136,136,136,137,137,137,137,137,137,137,137,137,137,137,137,137,138,138,138,138,138,138,139,139,139,139,139,139,139,139,140,140,140,140,140,140,140,140,140,140,140,140,141,141,141,141,141,141,141,141,141,141,141,141,142,142,142,142,142,142,142,142,142,142,143,143,143,143,143,143,143,143,143,143,144,144,144,144,144,144,144,144,144,145,145,145,145,145,145,145,145,146,146,146,146,146,146,146,146,146,147,147,147,147,147,147,147,147,147,147,147,147,147,147,147,148,148,148,148,148,148,148,148,148,148,148,148,148,148,149,149,149,149,149,149,150,150,150,150,150,150,150,150,150,150,150,150,150,150,150,150,150,151,151,151,151,151,151,151,151,151,151,151,151,151,151,152,152,152,152,152,152,152,152,152,152,152,152,152,153,153,153,153,153,153,153,153,153,153,153,153,154,154,154,154,154,154,154,154,154,154,154,154,155,155,155,155,155,155,155,155,155,155,155,155,156,156,156,156,156,156,156,156,156,156,156,156,157,157,157,157,157,157,157,157,157,157,157,157,157,158,158,158,158,158,158,158,158,158,158,158,158,159,159,159,159,159,159,159,159,159,160,160,160,160,160,160,161,161,161,161,161,161,162,162,162,162,162,162,162,162,162,162,162,163,163,163,163,163,163,163,163,163,163,164,164,164,164,164,164,164,164,164,164,164,164,165,165,165,165,165,165,165,165,165,165,165,165,165,166,166,166,166,166,166,167,167,167,167,167,167,167,167,167,167,167,168,168,168,168,168,168,168,168,168,168,168,168,168,169,169,169,169,169,169,169,169,169,169,169,169,170,170,170,170,170,170,170,170,170,170,170,170,170,170,171,171,171,171,171,171,171,171,171,171,172,172,172,172,172,172,172,172,172,172,172,173,173,173,173,173,173,173,174,174,174,174,174,174,174,174,174,174,174,175,175,175,175,175,175,175,175,175,175,175,175,175,176,176,176,176,176,176,176,176,176,176,176,176,177,177,177,177,177,177,177,177,178,178,178,178,178,178,178,178,178,178,178,178,178,179,179,179,179,179,179,179,179,179,179,179,179,180,180,180,180,180,180,180,181,181,181,181,181,181,181,181,181,182,182,182,182,182,182,182,182,182,182,182,182,183,183,183,183,183,183,183,183,183,183,183,183,184,184,184,184,184,184,184,184,184,184,184,184,184,185,185,185,185,185,185,185,185,185,185,185,185,185,185,186,186,186,186,186,186,187,187,187,187,187,187,187,187,187,187,187,187,188,188,188,188,188,188,188,188,188,188,188,188,188,188,188,189,189,189,189,189,190,190,190,190,190,190,190,190,190,190,190,191,191,191,191,191,191,191,191,191,191,191,191,191,191,192,192,192,192,192,192,192,192,192,192,192,193,193,193,193,193,193,193,194,194,194,194,194,194,194,194,194,194,194,194,194,194,194,194,195,195,195,195,195,195,195,195,195,195,195,195,195,196,196,196,196,196,196,196,196,196,196,196,196,196,196,197,197,197,197,197,197,197,197,197,197,197,197,197,197,197,197,198,198,198,198,198,198,198,198,198,198,198,199,199,199,199,199,199,199,199,199,199,199,199,199,200,200,200,200,200,200,201,201,201,201,201,201,201,201,201,202,202,202,202,202,202,202,202,202,202,202,202,203,203,203,203,203,203,203,203,203,203,203,203,203,203,203,203,204,204,204,204,204,204,204,204,204,204,204,204,205,205,205,205,205,205,206,206,206,206,206,206,206,206,206,207,207,207,207,207,207,207,207,207,207,207,208,208,208,208,209,209,209,209,209,209,209,209,209,209,209,209,210,210,210,210,210,210,210,210,210,210,211,211,211,211,211,211,211,211,211,211,212,212,212,212,212,212,212,212,212,212,212,212,212,212,212,213,213,213,213,213,213,214,214,214,214,214,214,214,214,214,214,214,215,215,215,215,215,215,215,215,215,215,216,216,216,216,216,216,216,216,216,216,216,216,216,217,217,217,217,217,217,217,217,218,218,218,218,218,218,218,219,219,219,219,219,219,219,219,219,219,219,220,220,220,220,220,220,220,220,220,220,220,220,220,221,221,221,221,221,221,221,221,221,221,221,221,221,222,222,222,222,222,222,222,222,223,223,223,223,223,223,223,223,223,223,223,223,223,224,224,224,224,224,224,224,224,224,224,225,225,225,225,225,225,225,225,226,226,226,226,226,226,226,227,227,227,227,227,227,227,227,227,228,228,228,228,228,228,228,228,228,228,228,229,229,229,229,229,229,229,229,229,229,229,229,230,230,230,230,230,230,230,230,230,230,230,231,231,231,231,231,231,231,231,231,231,231,231,231,231,232,232,232,232,232,232,232,232,232,232,232,233,233,233,233,233,233,233,233,233,233,233,234,234,234,234,234,234,234,234,234,234,235,235,235,235,235,235,235,235,235,235,235,235,235,236,236,236,236,236,236,236,236,236,236,236,236,237,237,237,237,237,237,237,237,237,237,237,237,237,237,238,238,238,238,238,238,238,238,238,238,238,238,238,239,239,239,239,239,240,240,240,240,240,240,240,240,240,241,241,241,241,241,241,241,241,241,241,241,242,242,242,242,242,242,242,242,242,242,242,242,242,243,243,243,243,243,243,244,244,244,244,244,244,244,244,244,244,244,244,244,245,245,245,245,245,245,245,245,245,245,245,245,245,246,246,246,246,246,246,246,246,246,246,246,246,246,246,247,247,247,247,247,247,247,247,247,247,247,247,247,248,248,248,248,248,248,248,248,248,248,249,249,249,249,249,250,250,250,250,250,250,250,250,250,250,251,251,251,251,251,251,251,251,251,252,252,252,252,252,252,252,252,252,252,252,252,253,253,253,253,253,253,253,253,253,254,254,254,254,254,255,255,255,255,255,255,255,255,255,255,256,256,256,256,256,256,256,256,256,256,256,256,256,257,257,257,257,257,257,257,257,257,258,258,258,258,258,258,258,258,258,258,259,259,259,259,259,259,259,259,259,259,259,259,259,260,260,260,260,260,261,261,261,261,261,261,261,261,261,262,262,262,262,262,262,262,262,262,262,262,263,263,263,263,263,263,263,263,263,263,263,263,264,264,264,264,264,264,264,264,264,264,264,265,265,265,265,265,266,266,266,266,266,266,266,266,266,266,266,267,267,267,267,267,267,267,267,267,267,267,267,268,268,268,268,268,268,268,268,268,268,268,268,269,269,269,269,269,269,269,269,269,269,269,269,270,270,270,270,270,270,270,270,270,270,270,270,270,270,270,270,270,270,271,271,271,271,271,271,272,272,272,272,272,272,272,272,272,272,272,272,272,272,272,272,273,273,273,273,273,273,273,273,273,273,273,273,273,273,274,274,274,274,274,274,274,274,274,274,274,274,275,275,275,275,275,276,276,276,276,276,276,276,276,276,276,276,276,277,277,277,277,277,278,278,278,278,278,278,278,278,278,278,278,278,278,278,279,279,279,279,279,279,279,279,279,280,280,280,280,280,280,280,281,281,281,281,281,281,281,281,281,281,281,281,281,281,282,282,282,282,282,282,283,283,283,283,283,283,283,283,283,283,283,283,283,283,283,284,284,284,284,284,284,284,285,285,285,285,285,285,285,285,285,285,285,285,285,285,286,286,286,286,286,286,286,286,286,286,286,286,286,286,287,287,287,287,287,287,287,287,287,287,287,287,287,287,288,288,288,288,288,288,288,288,288,288,288,288,289,289,289,289,289,289,289,289,289,289,289,289,289,289,289,289,290,290,290,290,290,290,290,290,290,291,291,291,291,291,291,291,291,292,292,292,292,292,292,292,292,292,292,293,293,293,293,293,293,293,294,294,294,294,294,294,294,294,294,294,294,294,294,294,294,294,295,295,295,295,295,295,295,295,295,295,295,296,296,296,296,296,296,296,296,296,296,296,296,297,297,297,297,297,297,297,298,298,298,298,298,298,298,298,298,298,298,298,298,299,299,299,299,299,299,299,300,300,300,300,300,300,300,300,301,301,301,301,301,301,301,301,301,301,301,301,301,301,301,302,302,302,302,302,302,302,302,302,302,302,302,302,302,303,303,303,303,303,303,303,303,303,303,303,303,303,303,304,304,304,304,304,304,304,304,304,304,304,304,305,305,305,305,305,305,305,305,305,305,305,306,306,306,306,306,306,306,306,306,307,307,307,307,307,307,307,307,307,307,307,307,308,308,308,308,308,308,308,309,309,309,309,309,309,309,309,309,309,310,310,310,310,310,310,310,311,311,311,311,311,311,311,311,312,312,312,312,312,312,312,312,313,313,313,313,313,313,313,313,313,313,313,313,313,313,314,314,314,314,314,314,314,314,314,314,314,314,314,314,315,315,315,315,315,315,315,315,315,315,315,315,316,316,316,316,316,316,316,316,316,316,317,317,317,317,317,317,318,318,318,318,318,318,318,318,318,318,318,318,318,318,318,319,319,319,319,319,319,320,320,320,320,320,320,320,320,320,320,321,321,321,321,321,322,322,322,322,322,322,322,322,322,322,322,322,323,323,323,323,323,323,323,323,323,323,323,323,323,324,324,324,324,324,324,324,324,324,324,324,324,324,325,325,325,325,325,325,325,325,325,325,326,326,326,326,326,326,326,326,326,326,326,326,326,326,326,326,326,326,327,327,327,327,327,327,327,327,327,327,327,327,327,328,328,328,328,328,328,328,328,328,328,328,328,328,328,328,329,329,329,329,329,329,329,329,329,329,329,329,329,329,329,329,329,330,330,330,330,330,331,331,331,331,331,331,331,331,331,331,331,331,331,331,331,332,332,332,332,332,332,332,332,332,332,332,333,333,333,333,333,333,333,333,333,333,333,333,333,334,334,334,334,334,334,334,334,334,334,334,334,334,335,335,335,335,335,335,335,335,335,335,335,335,335,335,335,336,336,336,336,336,336,336,336,336,336,336,336,336,337,337,337,337,337,338,338,338,338,338,338,338,338,338,338,338,338,338,338,339,339,339,339,339,339,339,339,339,339,339,339,340,340,340,340,340,340,340,340,340,340,340,340,341,341,341,341,341,342,342,342,342,342,342,342,342,342,342,342,342,343,343,343,343,343,343,343,343,343,344,344,344,344,344,344,344,344,344,344,344,344,345,345,345,345,345,345,345,345,345,345,345,346,346,346,346,346,346,346,346,346,346,346,347,347,347,347,347,347,348,348,348,348,348,348,348,348,348,348,348,348,349,349,349,349,349,349,349,349,349,349,349,349,349,349,350,350,350,350,350,350,350,351,351,351,351,351,351,351,351,351,351,351,351,352,352,352,352,352,352,352,352,352,352,352,353,353,353,353,353,353,353,353,353,353,353,354,354,354,354,354,354,354,354,354,354,354,354,355,355,355,355,355,355,355,355,355,355,355,356,356,356,356,356,356,356,356,356,356,357,357,358,358,358,358,358,358,358,358,359,359,359,359,359,359,359,359,359,359,359,359,359,360,360,360,360,360,360,360,360,360,360,361,361,361,361,361,361,361,361,361,361,361,361,361,362,362,362,362,362,362,362,362,362,362,362,362,362,362,362,363,363,363,363,363,363,363,363,363,363,363,363,363,364,364,364,364,364,364,365,365,365,365,365,365,365,365,365,365,365,365,365,365,366,366,366,366,366,366,366,366,366,367,367,367,367,367,367,367,367,367,368,368,368,368,368,368,368,369,369,369,369,369,369,369,370,370,370,370,370,370,370,371,371,371,371,371,371,371,371,371,371,371,371,371,371,372,372,372,372,372,372,372,372,372,372,372,372,372,373,373,373,373,373,373,373,373,374,374,374,374,374,374,374,374,374,374,374,374,374,374,374,374,375,375,375,375,375,375,375,375,376,376,376,376,376,376,377,377,377,377,377,377,377,377,377,377,377,377,377,378,378,378,378,378,378,378,378,378,378,378,379,379,379,379,379,379,379,379,379,379,379,379,379,379,380,380,380,380,380,381,381,381,381,381,381,381,381,381,381,381,382,382,382,382,382,382,382,382,382,383,383,383,383,383,383,383,383,383,383,383,383,384,384,384,384,384,384,384,384,384,384,384,384,384,385,385,385,385,385,385,386,386,386,386,386,386,387,387,387,387,387,387,388,388,388,388,388,388,389,389,389,389,389,389,390,390,390,390,390,390,391,391,391,391,391,391,392,392,392,392,392,392,393,393,393,393,393,393,394,394,394,394,394,394,395,395,395,395,395,395,396,396,396,396,396,396,397,397,397,397,397,397,398,398,398,398,398,398,399,399,399,399,399,399,400,400,400,400,400,400,401,401,401,401,401,401,402,402,402,402,402,402,403,403,403,403,403,403,403,403,403,403,403,403,404,404,404,404,404,404,404,404,404,404,404,404,404,405,405,405,405,405,405,405,405,405,405,405,405,405,406,406,406,406,406,406,406,407,407,407,407,407,407,407,407,407,408,408,408,408,408,408,408,408,408,408,408,408,409,409,409,409,409,409,409,409,409,409,409,410,410,410,410,410,410,410,410,410,410,410,410,410,411,411,411,411,411,411,411,411,411,411,411,412,412,412,412,412,412,412,412,412,412,413,413,413,413,413,413,413,413,413,413,414,414,414,414,414,414,414,414,414,414,414,415,415,415,415,415,415,415,415,415,415,415,416,416,416,416,416,416,416,416,416,416,416,417,417,417,417,417,417,417,417,417,417,418,418,418,418,418,418,418,418,418,418,418,419,419,419,419,419,419,419,419,419,420,420,420,420,420,420,420,420,420,420,420,421,421,421,421,421,421,421,421,421,421,421,421,421,422,422,422,422,422,422,422,422,422,423,423,423,423,423,423,423,423,423,423,423,423,423,423,423,423,424,424,424,424,424,424,424,424,424,425,425,425,425,425,425,425,425,425,426,426,426,426,426,426,426,426,426,426,426,426,426,426,426,427,427,427,427,427,427,427,427,428,428,428,428,428,428,428,428,428,428,428,429,429,429,429,429,429,429,429,429,429,429,429,430,430,430,430,430,430,430,430,430,431,431,431,431,431,431,431,431,431,432,432,432,432,432,432,432,432,432,432,432,432,433,433,433,433,433,433,433,433,433,433,433,434,434,434,434,434,434,434,435,435,435,435,435,435,435,435,435,435,435,436,436,436,436,436,436,436,436,436,436,437,437,437,437,437,437,437,437,438,438,438,438,438,438,438,438,438,438,438,439,439,439,439,439,439,439,439,439,440,440,440,440,440,440,440,441,441,441,441,441,441,441,441,441,441,442,442,442,442,442,442,442,442,442,442,442,442,442,443,443,443,443,443,443,443,443,443,443,443,443,443,443,443,443,443,444,444,444,444,444,444,444,444,444,445,445,445,445,445,445,445,445,445,445,445,445,445,445,445,446,446,446,446,446,446,446,446,446,446,446,447,447,447,447,447,447,447,447,447,448,448,448,448,448,448,448,448,448,448,448,448,448,449,449,449,449,449,449,449,449,449,449,449,449,449,449,449,450,450,450,450,450,450,450,450,450,450,450,450,450,451,451,451,451,451,451,451,451,451,451,451,451,451],"depth":[12,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,18,17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,5,4,3,2,1,2,1,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,4,3,2,1,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,18,17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,18,17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,2,1,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1],"label":["is.matrix","is.matrix","FUN","vapply","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","mean.default","mean","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","[[","[.data.frame","[","na.omit.data.frame","na.omit",".External2","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","c","dim.data.frame","dim","dim","nrow","[.tbl_df","[","as.data.frame.resample","as.data.frame","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","%in%","deparse","paste","FUN","lapply","sapply",".getXlevels","lm",".f",".Call","map","set_tibble_class","[.tbl_df","[","as.data.frame.resample","as.data.frame","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","lm.fit","lm",".f",".Call","map","lm.fit","lm",".f",".Call","map","NextMethod","[.factor","FUN","lapply","map","[.tbl_df","[","as.data.frame.resample","as.data.frame","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","%in%","[[.data.frame","[[","$.data.frame","$","model.offset","as.vector","lm",".f",".Call","map","names","%in%","[[.data.frame","[[","[.data.frame","[","na.omit.data.frame","na.omit",".External2","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","outer","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","colnames<-","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","lapply","sapply",".getXlevels","lm",".f",".Call","map","$<-","lm",".f",".Call","map","outer","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map",".External2","model.matrix.default","model.matrix","lm",".f",".Call","map","sys.call","%in%","[[.data.frame","[[","$.data.frame","$","model.weights","as.vector","lm",".f",".Call","map",".deparseOpts","deparse","paste","FUN","vapply","model.matrix.default","model.matrix","lm",".f",".Call","map","c","%in%","deparse","paste","FUN","lapply","sapply","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","colSums","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map",".Fortran","qr.qy","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","length","length","dim.data.frame","dim","dim","nrow","logical","na.omit.data.frame","na.omit",".External2","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","vapply",".getXlevels","lm",".f",".Call","map","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","match.fun","outer","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","[[","$.data.frame","$","model.weights","as.vector","lm",".f",".Call","map","names","names","model.matrix.default","model.matrix","lm",".f",".Call","map","[","lapply",".getXlevels","lm",".f",".Call","map",".External2","model.matrix.default","model.matrix","lm",".f",".Call","map","any","na.omit.data.frame","na.omit",".External2","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","map","[.tbl_df","[","as.data.frame.resample","as.data.frame","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","colSums","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","deparse","mode","%in%","deparse","paste","FUN","lapply","sapply","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","<GC>","na.omit",".External2","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","NextMethod","[.data.frame","[","lapply",".getXlevels","lm",".f",".Call","map","sys.call","%in%","[[.data.frame","[[","[.data.frame","[","na.omit.data.frame","na.omit",".External2","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","qr.qy","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map",".External2","model.matrix.default","model.matrix","lm",".f",".Call","map",".External2","model.matrix.default","model.matrix","lm",".f",".Call","map","unique","simplify2array","sapply",".getXlevels","lm",".f",".Call","map","prod","colSums","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map",".External","terms.formula","terms","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","is.matrix","is.matrix","FUN","vapply","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","<GC>","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","as.character","pmatch",".deparseOpts","deparse","paste","FUN","vapply","model.matrix.default","model.matrix","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","vapply","model.matrix.default","model.matrix","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl",".getNamespaceInfo","getExportedValue","::","response_var.default","response_var","eval","response","modelr:::residuals",".f",".Call","map2_dbl","FUN","lapply","map","[.tbl_df","[","as.data.frame.resample","as.data.frame","eval","response","modelr:::residuals",".f",".Call","map2_dbl","$","formula","formula.lm","stats::formula","response_var.default","response_var","eval","response","modelr:::residuals",".f",".Call","map2_dbl","c","%in%","deparse","paste","FUN","lapply","sapply","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","unique","simplify2array","sapply","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","deparse","paste","FUN","lapply","sapply","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","set_tibble_class","[.tbl_df","[","as.data.frame.resample","as.data.frame","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","eval","match.arg","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","$","terms.default","terms","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","model.matrix.default","model.matrix","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","sum",".deparseOpts","deparse","paste","FUN","lapply","sapply","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","response(model, data) - stats::predict(model, data)","modelr:::residuals",".f",".Call","map2_dbl","terms","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","poly","eval","eval","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","$","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","as.list","vapply","model.matrix.default","model.matrix","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","poly","eval","eval","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","c","pmatch",".deparseOpts","deparse","paste","FUN","vapply","model.matrix.default","model.matrix","lm",".f",".Call","map","match.fun","vapply","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","colSums","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","qr.qy","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","%in%",".deparseOpts","deparse","paste","FUN","vapply","model.matrix.default","model.matrix","lm",".f",".Call","map","as.list.data.frame","as.list","vapply","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","[.data.frame","[","na.omit.data.frame","na.omit",".External2","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","[.data.frame","[","na.omit.data.frame","na.omit",".External2","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","<GC>","colnames<-","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","[[.data.frame","[[","$.data.frame","$","model.weights","as.vector","lm",".f",".Call","map","match.fun","outer","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map",".getXlevels","lm",".f",".Call","map",".set_row_names","[.tbl_df","[","as.data.frame.resample","as.data.frame","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","[[.data.frame","[[","[.data.frame","[","na.omit.data.frame","na.omit",".External2","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map",".External2","model.matrix.default","model.matrix","lm",".f",".Call","map","deparse","mode","%in%","deparse","paste","FUN","vapply","model.matrix.default","model.matrix","lm",".f",".Call","map","model.response","lm",".f",".Call","map","x$data[x$idx, , drop = FALSE]","[","as.data.frame.resample","as.data.frame","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","colSums","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","[.tbl_df","[","as.data.frame.resample","as.data.frame","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","c","pmatch",".deparseOpts","deparse","paste","FUN","vapply","model.matrix.default","model.matrix","lm",".f",".Call","map","as.character","model.response","lm",".f",".Call","map","outer","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map",".External2","model.matrix.default","model.matrix","lm",".f",".Call","map","<GC>","[[.data.frame","[[","na.omit.data.frame","na.omit",".External2","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","c","structure","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map",".External","terms.formula","terms","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","pmatch",".deparseOpts","deparse","mode","%in%","deparse","paste","FUN","vapply","model.matrix.default","model.matrix","lm",".f",".Call","map",".External2","model.matrix.default","model.matrix","lm",".f",".Call","map","sapply","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","lm.fit","lm",".f",".Call","map",".Call","map","as.list","vapply","model.matrix.default","model.matrix","lm",".f",".Call","map","na.omit.data.frame","na.omit",".External2","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","getOption","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map",".Fortran","qr.default","qr","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","as.character","model.response","lm",".f",".Call","map","getExportedValue","::","eval","eval","lm",".f",".Call","map",".External2","model.matrix.default","model.matrix","lm",".f",".Call","map","is.atomic","na.omit.data.frame","na.omit",".External2","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","qr","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","as.list.default","as.list","lapply","sapply","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map",".External2","model.matrix.default","model.matrix","lm",".f",".Call","map","eval","lm",".f",".Call","map","length","length","na.omit.data.frame","na.omit",".External2","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","model.response","lm",".f",".Call","map","NextMethod","[.data.frame","[","lapply",".getXlevels","lm",".f",".Call","map","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","lm",".f",".Call","map","as.character","model.response","lm",".f",".Call","map","paste0","FUN","vapply","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","model.matrix.default","model.matrix","lm",".f",".Call","map",".External2","model.matrix.default","model.matrix","lm",".f",".Call","map","model.matrix.default","model.matrix","lm",".f",".Call","map",".External2","model.matrix.default","model.matrix","lm",".f",".Call","map","as.data.frame","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","[.tbl_df","[","as.data.frame.resample","as.data.frame","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","model.matrix.default","model.matrix","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","sys.function","formals","match.arg","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","<GC>","mean.default","mean",".f",".Call","map2_dbl","<GC>","mean.default","mean",".f",".Call","map2_dbl","formula","formula.lm","stats::formula","response_var.default","response_var","eval","response","modelr:::residuals",".f",".Call","map2_dbl","stats::formula(model)[[2L]]","[[","response_var.default","response_var","eval","response","modelr:::residuals",".f",".Call","map2_dbl","deparse","paste","FUN","lapply","sapply","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","asNamespace","get",":::",".f",".Call","map2_dbl","vapply",".checkMFClasses","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","structure","poly","eval","eval","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","deparse","paste","FUN","vapply","model.matrix.default","model.matrix","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","FUN","vapply","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","names","names","model.matrix.default","model.matrix","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","as.data.frame","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","eval","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","mode","%in%","deparse","paste","FUN","lapply","sapply","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","lapply","map","[.tbl_df","[","as.data.frame.resample","as.data.frame","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","%in%",".deparseOpts","deparse","mode","%in%","deparse","paste","FUN","vapply","model.matrix.default","model.matrix","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","length","length","[.tbl_df","[","as.data.frame.resample","as.data.frame","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","deparse","paste","FUN","lapply","sapply","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","structure","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","pmatch",".deparseOpts","deparse","paste","FUN","vapply","model.matrix.default","model.matrix","lm",".f",".Call","map","structure","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","colnames<-","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","nrow","[.tbl_df","[","as.data.frame.resample","as.data.frame","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","%in%",".deparseOpts","deparse","paste","FUN","lapply","sapply",".getXlevels","lm",".f",".Call","map","terms","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","sys.call","match.call","lm",".f",".Call","map","eval","eval","lm",".f",".Call","map","as.list","lapply","sapply","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","sys.call","%in%","[[.data.frame","[[","model.matrix.default","model.matrix","lm",".f",".Call","map","colnames<-","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","[.data.frame","[","na.omit.data.frame","na.omit",".External2","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","structure","lm.fit","lm",".f",".Call","map","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","<GC>","mean","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","outer","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","%in%","[[.data.frame","[[","na.omit.data.frame","na.omit",".External2","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","na.omit",".External2","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","paste0","FUN","vapply","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","[","lapply",".getXlevels","lm",".f",".Call","map","unique","simplify2array","sapply","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","qr.default","qr","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","outer","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","deparse","paste","FUN","lapply","sapply","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","unique","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","[[.data.frame","[[","model.response","lm",".f",".Call","map","anyDuplicated","[.data.frame","[","lapply",".getXlevels","lm",".f",".Call","map","qr","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","outer","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","c","pmatch",".deparseOpts","deparse","paste","FUN","vapply","model.matrix.default","model.matrix","lm",".f",".Call","map",".deparseOpts","deparse","paste","FUN","lapply","sapply","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","nrow","lm.fit","lm",".f",".Call","map","%in%",".deparseOpts","deparse","paste","FUN","vapply","model.matrix.default","model.matrix","lm",".f",".Call","map","NCOL","colnames","qr.default","qr","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map",".getXlevels","lm",".f",".Call","map","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","as.matrix","qr.default","qr","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map",".External2","model.matrix.default","model.matrix","lm",".f",".Call","map","<GC>","pmatch",".deparseOpts","deparse","paste","FUN","lapply","sapply","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","nrow","logical","na.omit.data.frame","na.omit",".External2","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","[","[.data.frame","[","na.omit.data.frame","na.omit",".External2","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","deparse","mode","%in%","deparse","paste","FUN","lapply","sapply","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","%in%","structure","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","as.character","model.response","lm",".f",".Call","map","sys.call","%in%","[[.data.frame","[[","model.response","lm",".f",".Call","map","length","length","dim.data.frame","dim","dim","ncol","model.matrix.default","model.matrix","lm",".f",".Call","map","deparse","mode","%in%","deparse","paste","FUN","lapply","sapply","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","colSums","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","<GC>","UseMethod(\"response_var\")","response_var","eval","response","modelr:::residuals",".f",".Call","map2_dbl","map","[.tbl_df","[","as.data.frame.resample","as.data.frame","eval","response","modelr:::residuals",".f",".Call","map2_dbl","mean",".f",".Call","map2_dbl","deparse","paste","FUN","vapply","model.matrix.default","model.matrix","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","lapply","sapply","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","names","names","model.matrix.default","model.matrix","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","any",".deparseOpts","deparse","paste","FUN","lapply","sapply","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","eval","response","modelr:::residuals",".f",".Call","map2_dbl",".getNamespaceInfo","getExportedValue","::","response_var.default","response_var","eval","response","modelr:::residuals",".f",".Call","map2_dbl","[.tbl_df","[","as.data.frame.resample","as.data.frame","eval","response","modelr:::residuals",".f",".Call","map2_dbl","deparse","paste","FUN","lapply","sapply","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","poly","eval","eval","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","nrow","[.tbl_df","[","as.data.frame.resample","as.data.frame","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","deparse","paste","FUN","lapply","sapply","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","deparse","paste","FUN","lapply","sapply","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","<GC>","FUN","vapply",".checkMFClasses","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","UseMethod(\"response_var\")","response_var","eval","response","modelr:::residuals",".f",".Call","map2_dbl","model.matrix","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","vapply","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","as.character","makepredictcall.poly","makepredictcall","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","is.numeric","is.numeric","FUN","vapply","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","<Anonymous>","[[.data.frame","[[","na.omit.data.frame","na.omit",".External2","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","%in%","deparse","paste","FUN","vapply","model.matrix.default","model.matrix","lm",".f",".Call","map","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","deparse","paste","FUN","lapply","sapply",".getXlevels","lm",".f",".Call","map","[.data.frame","[","na.omit.data.frame","na.omit",".External2","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","outer","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","length","NCOL","qr.qy","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","is.data.frame","colSums","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","lm.fit","lm",".f",".Call","map","vapply","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","[.data.frame","[","na.omit.data.frame","na.omit",".External2","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","as.character","model.response","lm",".f",".Call","map","[[.data.frame","[[","na.omit.data.frame","na.omit",".External2","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","[.data.frame","[","na.omit.data.frame","na.omit",".External2","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","lapply","map","[.tbl_df","[","as.data.frame.resample","as.data.frame","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map",".Fortran","qr.qy","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","<GC>","[[","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","$<-","lm",".f",".Call","map","as.list","vapply","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","makepredictcall","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","qr","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","is.factor","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","as.vector","lm",".f",".Call","map","deparse","paste","FUN","vapply","model.matrix.default","model.matrix","lm",".f",".Call","map","qr.default","qr","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","vapply","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","[[.data.frame","[[","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","is.data.frame","colSums","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","lm.fit","lm",".f",".Call","map","paste","FUN","lapply","sapply",".getXlevels","lm",".f",".Call","map","na.omit.data.frame","na.omit",".External2","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","[.tbl_df","[","as.data.frame.resample","as.data.frame","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map",".deparseOpts","deparse","paste","FUN","lapply","sapply",".getXlevels","lm",".f",".Call","map",".getXlevels","lm",".f",".Call","map",".External","terms.formula","terms","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","colnames<-","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","colSums","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","sys.call","%in%","[[.data.frame","[[","$.data.frame","$","model.offset","as.vector","lm",".f",".Call","map","length","length","dim.data.frame","dim","dim","nrow","[.tbl_df","[","as.data.frame.resample","as.data.frame","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","c","lm.fit","lm",".f",".Call","map","c","pmatch",".deparseOpts","deparse","paste","FUN","lapply","sapply","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","<GC>","qr.default","qr","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","names","%in%","[[.data.frame","[[","$.data.frame","$","model.weights","as.vector","lm",".f",".Call","map","lm.fit","lm",".f",".Call","map","outer","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","lm.fit","lm",".f",".Call","map","lapply","map","[.tbl_df","[","as.data.frame.resample","as.data.frame","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","names","[.data.frame","[","lapply",".getXlevels","lm",".f",".Call","map",".External2","model.matrix.default","model.matrix","lm",".f",".Call","map","get","match.fun","outer","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","c","lm.fit","lm",".f",".Call","map","dim","dim","nrow","[.tbl_df","[","as.data.frame.resample","as.data.frame","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map",".External2","model.matrix.default","model.matrix","lm",".f",".Call","map","class<-","set_tibble_class","[.tbl_df","[","as.data.frame.resample","as.data.frame","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","lapply","map","[.tbl_df","[","as.data.frame.resample","as.data.frame","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","any",".deparseOpts","deparse","paste","FUN","vapply","model.matrix.default","model.matrix","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","matrix","poly","eval","eval","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","length","length","dim.data.frame","dim","dim","nrow","[.tbl_df","[","as.data.frame.resample","as.data.frame","eval","response","modelr:::residuals",".f",".Call","map2_dbl",".External2","model.matrix.default","model.matrix","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","terms.default","terms","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","lapply","sapply","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl",".checkMFClasses","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","deparse","mode","%in%","deparse","paste","FUN","lapply","sapply","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","paste","FUN","vapply","model.matrix.default","model.matrix","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","lapply","map","[.tbl_df","[","as.data.frame.resample","as.data.frame","eval","response","modelr:::residuals",".f",".Call","map2_dbl",".checkMFClasses","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","$","[.tbl_df","[","as.data.frame.resample","as.data.frame","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl",".checkMFClasses","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","formals","match.arg","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","dim","dim","nrow","[.tbl_df","[","as.data.frame.resample","as.data.frame","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","length","length","[.tbl_df","[","as.data.frame.resample","as.data.frame","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","length","length","dim.data.frame","dim","dim","ncol","model.matrix.default","model.matrix","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","structure","poly","eval","eval","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","unique","simplify2array","sapply","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","eval","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","unique.default","unique","simplify2array","sapply","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","$","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","simplify2array","sapply","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","match.arg","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","eval","match.arg","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","eval","match.arg","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl",".deparseOpts","deparse","mode","%in%","deparse","paste","FUN","vapply","model.matrix.default","model.matrix","lm",".f",".Call","map",".Fortran","qr.default","qr","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","$","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","na.omit",".External2","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","model.matrix.default","model.matrix","lm",".f",".Call","map","pmatch",".deparseOpts","deparse","paste","FUN","lapply","sapply","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","model.offset","as.vector","lm",".f",".Call","map","deparse","paste","FUN","vapply","model.matrix.default","model.matrix","lm",".f",".Call","map","model.matrix","lm",".f",".Call","map","outer","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","deparse","paste","FUN","lapply","sapply","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","<GC>","colnames<-","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","[[.data.frame","[[","$.data.frame","$","model.offset","as.vector","lm",".f",".Call","map","mode","%in%","deparse","mode","%in%","deparse","paste","FUN","lapply","sapply","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","[.data.frame","[","na.omit.data.frame","na.omit",".External2","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","mode","%in%","deparse","paste","FUN","lapply","sapply","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","NextMethod","[.factor","FUN","lapply","map","[.tbl_df","[","as.data.frame.resample","as.data.frame","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","is.matrix","lm",".f",".Call","map","as.list","lapply","map","[.tbl_df","[","as.data.frame.resample","as.data.frame","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","<GC>","structure","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","<GC>","structure","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","as.list","lapply","map","[.tbl_df","[","as.data.frame.resample","as.data.frame","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","[.data.frame","[","na.omit.data.frame","na.omit",".External2","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","$<-","lm",".f",".Call","map",".deparseOpts","deparse","mode","%in%","deparse","paste","FUN","lapply","sapply",".getXlevels","lm",".f",".Call","map","x$data[x$idx, , drop = FALSE]","$","as.data.frame.resample","as.data.frame","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","outer","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","lm.fit","lm",".f",".Call","map","paste","FUN","lapply","sapply","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","<Anonymous>","[[.data.frame","[[","model.matrix.default","model.matrix","lm",".f",".Call","map","outer","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","paste0","FUN","vapply","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","<GC>","lm.fit","lm",".f",".Call","map","outer","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map",".Fortran","qr.default","qr","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map",".External2","model.matrix.default","model.matrix","lm",".f",".Call","map","is.numeric","is.numeric","FUN","vapply","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map",".External","terms.formula","terms","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","%in%","[[.data.frame","[[","$.data.frame","$","model.offset","as.vector","lm",".f",".Call","map","[.tbl_df","[","as.data.frame.resample","as.data.frame","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","length","dim.data.frame","dim","dim","ncol","model.matrix.default","model.matrix","lm",".f",".Call","map","na.omit",".External2","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map",".Call","map","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","c","pmatch",".deparseOpts","deparse","paste","FUN","lapply","sapply",".getXlevels","lm",".f",".Call","map","na.omit",".External2","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map",".Fortran","qr.qy","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","pmatch",".deparseOpts","deparse","mode","%in%","deparse","paste","FUN","lapply","sapply",".getXlevels","lm",".f",".Call","map","length","length","na.omit.data.frame","na.omit",".External2","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","as.character","model.response","lm",".f",".Call","map","attr","[.data.frame","[","na.omit.data.frame","na.omit",".External2","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","paste","FUN","vapply","model.matrix.default","model.matrix","lm",".f",".Call","map",".getNamespaceInfo","getExportedValue","::","eval","eval","lm",".f",".Call","map","is.data.frame","colnames","lm.fit","lm",".f",".Call","map","terms","model.matrix.default","model.matrix","lm",".f",".Call","map",".External2","model.matrix.default","model.matrix","lm",".f",".Call","map","lapply","map","[.tbl_df","[","as.data.frame.resample","as.data.frame","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","[.data.frame","[","na.omit.data.frame","na.omit",".External2","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","<GC>",".External2","model.matrix.default","model.matrix","lm",".f",".Call","map","deparse","mode","%in%","deparse","paste","FUN","lapply","sapply","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","<Anonymous>","[[.data.frame","[[","model.response","lm",".f",".Call","map","as.character","model.response","lm",".f",".Call","map","[.data.frame","[","na.omit.data.frame","na.omit",".External2","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","lapply","map","[.tbl_df","[","as.data.frame.resample","as.data.frame","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","lm.fit","lm",".f",".Call","map",".External","terms.formula","terms","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","is.function","match.fun","vapply","model.matrix.default","model.matrix","lm",".f",".Call","map","paste","FUN","lapply","sapply","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","is.data.frame","colSums","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","<GC>","lm.fit","lm",".f",".Call","map","<GC>","lm.fit","lm",".f",".Call","map","<GC>","lm.fit","lm",".f",".Call","map","<GC>","lm.fit","lm",".f",".Call","map","<GC>","lm.fit","lm",".f",".Call","map","<GC>","lm.fit","lm",".f",".Call","map","<GC>","lm.fit","lm",".f",".Call","map","<GC>","lm.fit","lm",".f",".Call","map","<GC>","lm.fit","lm",".f",".Call","map","<GC>","lm.fit","lm",".f",".Call","map","<GC>","lm.fit","lm",".f",".Call","map","<GC>","lm.fit","lm",".f",".Call","map","<GC>","lm.fit","lm",".f",".Call","map","<GC>","lm.fit","lm",".f",".Call","map","<GC>","lm.fit","lm",".f",".Call","map","<GC>","lm.fit","lm",".f",".Call","map","<GC>","lm.fit","lm",".f",".Call","map","<GC>","lm.fit","lm",".f",".Call","map","length","length","dim.data.frame","dim","dim","ncol","model.matrix.default","model.matrix","lm",".f",".Call","map",".Fortran","qr.qy","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","[.data.frame","[","na.omit.data.frame","na.omit",".External2","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","delete.response","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl",".External2","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","paste","FUN","lapply","sapply","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","get0","getExportedValue","::","response_var.default","response_var","eval","response","modelr:::residuals",".f",".Call","map2_dbl","deparse","paste","FUN","lapply","sapply","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl",".set_row_names","[.tbl_df","[","as.data.frame.resample","as.data.frame","eval","response","modelr:::residuals",".f",".Call","map2_dbl","is.function","match.fun","vapply",".checkMFClasses","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","length","length","model.matrix.default","model.matrix","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","poly","eval","eval","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","poly","eval","eval","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","poly","eval","eval","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","simplify2array","sapply","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl",".set_row_names","[.tbl_df","[","as.data.frame.resample","as.data.frame","eval","response","modelr:::residuals",".f",".Call","map2_dbl","vapply","model.matrix.default","model.matrix","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","%in%","[[.data.frame","[[","model.matrix.default","model.matrix","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","deparse","paste","FUN","lapply","sapply","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","as.data.frame","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","length","length","dim.data.frame","dim","dim","nrow","[.tbl_df","[","as.data.frame.resample","as.data.frame","eval","response","modelr:::residuals",".f",".Call","map2_dbl","getOption","model.matrix.default","model.matrix","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","vapply","model.matrix.default","model.matrix","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","NextMethod","[.factor","FUN","lapply","map","[.tbl_df","[","as.data.frame.resample","as.data.frame","eval","response","modelr:::residuals",".f",".Call","map2_dbl","model.matrix.default","model.matrix","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","match.fun","lapply","sapply","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","structure","poly","eval","eval","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl",".External2","model.matrix.default","model.matrix","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","$","model.matrix.default","model.matrix","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","deparse","paste","FUN","vapply","model.matrix.default","model.matrix","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","$","formula.lm","stats::formula","response_var.default","response_var","eval","response","modelr:::residuals",".f",".Call","map2_dbl",".checkMFClasses","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","poly","eval","eval","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","FUN","vapply","model.matrix.default","model.matrix","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","model.matrix.default","model.matrix","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","poly","eval","eval","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","stats::formula","response_var.default","response_var","eval","response","modelr:::residuals",".f",".Call","map2_dbl","match.arg","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","lapply","sapply","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","deparse","paste","FUN","lapply","sapply","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","pmatch",".deparseOpts","deparse","mode","%in%","deparse","paste","FUN","vapply","model.matrix.default","model.matrix","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","vapply","model.matrix.default","model.matrix","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","as.list","lapply","map","[.tbl_df","[","as.data.frame.resample","as.data.frame","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","poly","eval","eval","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","$","model.matrix.default","model.matrix","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","dim","dim","ncol","paste0","FUN","vapply",".checkMFClasses","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","dim","dim","nrow","[.tbl_df","[","as.data.frame.resample","as.data.frame","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","as.list","lapply","map","[.tbl_df","[","as.data.frame.resample","as.data.frame","eval","response","modelr:::residuals",".f",".Call","map2_dbl","deparse","paste","FUN","lapply","sapply","model.frame.default","model.frame","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl"],"filenum":[null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,2,2,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,2,2,null,null,null,null,null,null,null,null,null,1,null,null,null,null,1,null,null,null,null,1,null,null,null,null,null,2,2,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,1,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,1,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,2,2,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,1,null,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,3,null,null,null,1,null,null,3,null,null,null,1,null,null,null,null,null,null,null,null,null,null,3,null,null,null,1,null,null,null,null,3,null,null,null,1,null,null,5,5,null,5,3,null,null,null,1,null,null,null,2,2,null,null,5,3,null,null,null,1,null,null,null,5,5,null,5,3,null,null,null,1,null,null,null,null,null,null,null,null,null,null,3,null,null,null,1,null,null,null,null,null,null,3,null,null,null,1,null,null,null,null,null,null,null,null,3,null,null,null,1,null,2,2,null,null,null,null,null,3,null,null,null,1,null,null,null,3,null,null,null,1,null,null,null,null,3,null,null,null,1,null,3,null,null,null,1,null,null,null,3,null,null,null,1,null,null,null,null,null,null,null,null,null,null,3,null,null,null,1,3,null,null,null,1,null,null,3,null,null,null,1,null,null,null,null,null,null,3,null,null,null,1,null,null,3,null,null,null,1,null,null,3,null,null,null,1,null,null,null,null,null,3,null,null,null,1,null,null,null,null,null,null,3,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,1,null,2,2,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,1,2,2,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,2,2,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,1,null,null,null,null,1,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,1,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,1,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,null,1,null,null,null,null,3,null,null,null,1,2,2,null,null,null,null,null,3,null,null,null,1,null,null,null,3,null,null,null,1,null,3,null,null,null,1,null,null,null,null,3,null,null,null,1,null,null,null,3,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,1,null,null,5,5,null,5,3,null,null,null,1,5,5,5,null,5,3,null,null,null,1,null,null,null,null,null,null,null,null,3,null,null,null,1,null,null,null,null,null,1,null,null,null,3,null,null,null,1,null,null,null,null,null,null,null,3,null,null,null,1,null,null,null,null,null,null,null,3,null,null,null,1,null,null,null,null,null,3,null,null,null,1,null,null,null,null,null,3,null,null,null,1,null,null,null,null,3,null,null,null,1,null,null,null,3,null,null,null,1,null,null,null,null,3,null,null,null,1,null,null,null,null,null,null,null,null,null,null,3,null,null,null,1,null,null,2,2,null,null,null,null,null,3,null,null,null,1,null,3,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,3,null,null,null,1,null,null,2,2,null,null,null,null,null,3,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,2,2,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,3,null,null,null,1,null,5,null,5,3,null,null,null,1,null,2,2,null,null,5,3,null,null,null,1,null,null,null,1,null,null,null,null,null,null,null,3,null,null,null,1,null,null,null,null,null,3,null,null,null,1,null,null,null,null,null,3,null,null,null,1,null,null,null,null,null,null,null,null,null,null,3,null,null,null,1,5,3,null,null,null,1,null,null,5,5,null,5,3,null,null,null,1,2,2,null,null,5,3,null,null,null,1,null,null,null,null,null,null,null,null,3,null,null,null,1,null,null,null,3,null,null,null,1,null,null,3,null,null,null,1,null,null,null,null,null,null,3,null,null,null,1,null,2,2,null,null,null,null,null,3,null,null,null,1,null,null,null,null,null,null,null,null,3,null,null,null,1,null,null,null,3,null,null,null,1,null,null,null,null,null,null,null,null,3,null,null,null,1,null,null,null,null,null,3,null,null,null,1,5,null,5,3,null,null,null,1,null,null,3,null,null,null,1,null,null,null,null,3,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,1,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,2,2,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,1,null,null,null,null,1,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,1,null,null,null,null,1,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,1,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,2,2,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,2,2,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,1,null,null,2,2,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,2,2,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,1,null,null,2,2,null,null,null,null,null,3,null,null,null,1,null,null,2,2,null,null,null,null,null,3,null,null,null,1,null,null,null,null,null,null,null,null,null,3,null,null,null,1,null,null,null,null,null,null,null,3,null,null,null,1,null,null,null,null,null,null,2,2,null,null,5,3,null,null,null,1,null,null,null,null,3,null,null,null,1,null,null,null,3,null,null,null,1,null,null,null,null,null,3,null,null,null,1,null,null,3,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,3,null,null,null,1,null,null,null,null,null,null,3,null,null,null,1,null,null,2,2,null,null,5,3,null,null,null,1,null,null,3,null,null,null,1,null,2,2,null,null,null,null,null,3,null,null,null,1,null,null,3,null,null,null,1,null,null,null,3,null,null,null,1,null,null,null,2,2,null,null,null,null,null,3,null,null,null,1,null,null,2,2,null,null,null,null,null,3,null,null,null,1,null,null,null,null,null,null,null,null,null,3,null,null,null,1,null,null,null,null,null,null,null,3,null,null,null,1,null,null,null,null,null,null,3,null,null,null,1,null,null,null,null,3,null,null,null,1,null,null,null,null,null,null,null,3,null,null,null,1,null,null,3,null,null,null,1,null,null,null,null,null,3,null,null,null,1,null,null,3,null,null,null,1,null,null,null,3,null,null,null,1,null,null,null,3,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,1,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,2,2,null,null,null,null,null,null,null,null,null,1,null,null,null,null,1,null,null,null,2,2,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,2,2,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,1,2,2,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,2,2,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,1,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,1,null,null,null,null,null,null,1,null,null,null,null,null,null,1,null,null,2,2,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,null,2,2,null,null,null,null,null,null,null,null,null,1,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,3,null,null,null,1,null,null,null,null,3,null,null,null,1,null,null,null,null,null,null,null,3,null,null,null,1,null,null,5,5,null,5,3,null,null,null,1,null,null,null,null,null,null,null,null,3,null,null,null,1,null,2,2,null,null,5,3,null,null,null,1,null,null,null,null,null,3,null,null,null,1,null,null,null,null,null,3,null,null,null,1,null,null,null,null,null,null,3,null,null,null,1,null,null,null,null,null,null,3,null,null,null,1,null,null,null,null,null,null,3,null,null,null,1,null,null,null,null,null,3,null,null,null,1,null,2,2,null,null,5,3,null,null,null,1,null,null,null,null,3,null,null,null,1,null,null,null,null,null,null,3,null,null,null,1,null,null,null,null,null,null,null,null,3,null,null,null,1,null,null,null,null,3,null,null,null,1,null,null,null,null,null,null,2,2,null,null,5,3,null,null,null,1,null,null,null,null,3,null,null,null,1,null,null,null,null,3,null,null,null,1,null,null,null,null,null,2,2,null,null,5,3,null,null,null,1,null,null,null,3,null,null,null,1,null,null,null,null,null,null,3,null,null,null,1,null,null,null,null,null,null,null,3,null,null,null,1,null,null,null,null,3,null,null,null,1,null,null,null,null,3,null,null,null,1,null,null,null,null,null,null,null,3,null,null,null,1,null,null,5,5,null,5,3,null,null,null,1,null,null,3,null,null,null,1,null,null,null,null,null,null,3,null,null,null,1,null,null,null,null,null,3,null,null,null,1,null,null,null,3,null,null,null,1,null,null,null,null,null,null,3,null,null,null,1,5,5,null,5,3,null,null,null,1,null,null,3,null,null,null,1,null,null,null,null,null,3,null,null,null,1,null,null,null,null,null,null,null,null,3,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,3,null,null,null,1,null,null,null,null,3,null,null,null,1,null,null,null,2,2,null,null,null,null,null,3,null,null,null,1,null,null,null,null,null,null,3,null,null,null,1,null,null,null,null,3,null,null,null,1,null,null,null,null,null,null,null,null,3,null,null,null,1,null,null,null,2,2,null,null,null,null,null,3,null,null,null,1,null,null,null,2,2,null,null,5,3,null,null,null,1,null,null,null,null,null,null,null,null,3,null,null,null,1],"linenum":[null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,64,64,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,null,64,64,null,null,null,null,null,null,null,null,null,8,null,null,null,null,8,null,null,null,null,8,null,null,null,null,null,64,64,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,8,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,8,null,null,null,null,null,null,8,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,64,64,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,8,null,null,null,null,null,null,8,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,56,null,null,null,9,null,null,56,null,null,null,9,null,null,null,null,null,null,null,null,null,null,56,null,null,null,9,null,null,null,null,56,null,null,null,9,null,null,7,2,null,20,56,null,null,null,9,null,null,null,64,64,null,null,20,56,null,null,null,9,null,null,null,7,2,null,20,56,null,null,null,9,null,null,null,null,null,null,null,null,null,null,56,null,null,null,9,null,null,null,null,null,null,56,null,null,null,9,null,null,null,null,null,null,null,null,56,null,null,null,9,null,64,64,null,null,null,null,null,56,null,null,null,9,null,null,null,56,null,null,null,9,null,null,null,null,56,null,null,null,9,null,56,null,null,null,9,null,null,null,56,null,null,null,9,null,null,null,null,null,null,null,null,null,null,56,null,null,null,9,56,null,null,null,9,null,null,56,null,null,null,9,null,null,null,null,null,null,56,null,null,null,9,null,null,56,null,null,null,9,null,null,56,null,null,null,9,null,null,null,null,null,56,null,null,null,9,null,null,null,null,null,null,56,null,null,null,9,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,8,null,64,64,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,8,64,64,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,64,64,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,8,null,null,null,null,8,null,8,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,null,null,8,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,8,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,8,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,null,8,null,null,null,null,56,null,null,null,9,64,64,null,null,null,null,null,56,null,null,null,9,null,null,null,56,null,null,null,9,null,56,null,null,null,9,null,null,null,null,56,null,null,null,9,null,null,null,56,null,null,null,9,null,null,null,null,null,9,null,null,null,null,null,9,null,null,7,2,null,20,56,null,null,null,9,7,7,2,null,20,56,null,null,null,9,null,null,null,null,null,null,null,null,56,null,null,null,9,null,null,null,null,null,9,null,null,null,56,null,null,null,9,null,null,null,null,null,null,null,56,null,null,null,9,null,null,null,null,null,null,null,56,null,null,null,9,null,null,null,null,null,56,null,null,null,9,null,null,null,null,null,56,null,null,null,9,null,null,null,null,56,null,null,null,9,null,null,null,56,null,null,null,9,null,null,null,null,56,null,null,null,9,null,null,null,null,null,null,null,null,null,null,56,null,null,null,9,null,null,64,64,null,null,null,null,null,56,null,null,null,9,null,56,null,null,null,9,null,null,null,null,null,null,null,null,null,null,null,null,56,null,null,null,9,null,null,64,64,null,null,null,null,null,56,null,null,null,9,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,64,64,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,56,null,null,null,9,null,2,null,20,56,null,null,null,9,null,64,64,null,null,20,56,null,null,null,9,null,null,null,9,null,null,null,null,null,null,null,56,null,null,null,9,null,null,null,null,null,56,null,null,null,9,null,null,null,null,null,56,null,null,null,9,null,null,null,null,null,null,null,null,null,null,56,null,null,null,9,20,56,null,null,null,9,null,null,7,2,null,20,56,null,null,null,9,64,64,null,null,20,56,null,null,null,9,null,null,null,null,null,null,null,null,56,null,null,null,9,null,null,null,56,null,null,null,9,null,null,56,null,null,null,9,null,null,null,null,null,null,56,null,null,null,9,null,64,64,null,null,null,null,null,56,null,null,null,9,null,null,null,null,null,null,null,null,56,null,null,null,9,null,null,null,56,null,null,null,9,null,null,null,null,null,null,null,null,56,null,null,null,9,null,null,null,null,null,56,null,null,null,9,2,null,20,56,null,null,null,9,null,null,56,null,null,null,9,null,null,null,null,56,null,null,null,9,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,8,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,64,64,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,8,null,null,null,null,8,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,8,null,null,null,null,8,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,8,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,64,64,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,64,64,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,8,null,null,64,64,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,64,64,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,8,null,null,64,64,null,null,null,null,null,56,null,null,null,9,null,null,64,64,null,null,null,null,null,56,null,null,null,9,null,null,null,null,null,null,null,null,null,56,null,null,null,9,null,null,null,null,null,null,null,56,null,null,null,9,null,null,null,null,null,null,64,64,null,null,20,56,null,null,null,9,null,null,null,null,56,null,null,null,9,null,null,null,56,null,null,null,9,null,null,null,null,null,56,null,null,null,9,null,null,56,null,null,null,9,null,null,null,null,null,null,null,null,null,null,null,56,null,null,null,9,null,null,null,null,null,null,56,null,null,null,9,null,null,64,64,null,null,20,56,null,null,null,9,null,null,56,null,null,null,9,null,64,64,null,null,null,null,null,56,null,null,null,9,null,null,56,null,null,null,9,null,null,null,56,null,null,null,9,null,null,null,64,64,null,null,null,null,null,56,null,null,null,9,null,null,64,64,null,null,null,null,null,56,null,null,null,9,null,null,null,null,null,null,null,null,null,56,null,null,null,9,null,null,null,null,null,null,null,56,null,null,null,9,null,null,null,null,null,null,56,null,null,null,9,null,null,null,null,56,null,null,null,9,null,null,null,null,null,null,null,56,null,null,null,9,null,null,56,null,null,null,9,null,null,null,null,null,56,null,null,null,9,null,null,56,null,null,null,9,null,null,null,56,null,null,null,9,null,null,null,56,null,null,null,9,null,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,8,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,64,64,null,null,null,null,null,null,null,null,null,8,null,null,null,null,8,null,null,null,64,64,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,64,64,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,null,8,64,64,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,64,64,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,8,null,8,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,8,null,null,null,null,null,null,8,null,null,null,null,null,null,8,null,null,64,64,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,null,null,64,64,null,null,null,null,null,null,null,null,null,8,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,null,null,null,null,null,null,null,null,null,null,8,null,null,56,null,null,null,9,null,null,null,null,56,null,null,null,9,null,null,null,null,null,null,null,56,null,null,null,9,null,null,7,2,null,20,56,null,null,null,9,null,null,null,null,null,null,null,null,56,null,null,null,9,null,64,64,null,null,20,56,null,null,null,9,null,null,null,null,null,56,null,null,null,9,null,null,null,null,null,56,null,null,null,9,null,null,null,null,null,null,56,null,null,null,9,null,null,null,null,null,null,56,null,null,null,9,null,null,null,null,null,null,56,null,null,null,9,null,null,null,null,null,56,null,null,null,9,null,64,64,null,null,20,56,null,null,null,9,null,null,null,null,56,null,null,null,9,null,null,null,null,null,null,56,null,null,null,9,null,null,null,null,null,null,null,null,56,null,null,null,9,null,null,null,null,56,null,null,null,9,null,null,null,null,null,null,64,64,null,null,20,56,null,null,null,9,null,null,null,null,56,null,null,null,9,null,null,null,null,56,null,null,null,9,null,null,null,null,null,64,64,null,null,20,56,null,null,null,9,null,null,null,56,null,null,null,9,null,null,null,null,null,null,56,null,null,null,9,null,null,null,null,null,null,null,56,null,null,null,9,null,null,null,null,56,null,null,null,9,null,null,null,null,56,null,null,null,9,null,null,null,null,null,null,null,56,null,null,null,9,null,null,7,2,null,20,56,null,null,null,9,null,null,56,null,null,null,9,null,null,null,null,null,null,56,null,null,null,9,null,null,null,null,null,56,null,null,null,9,null,null,null,56,null,null,null,9,null,null,null,null,null,null,56,null,null,null,9,7,2,null,20,56,null,null,null,9,null,null,56,null,null,null,9,null,null,null,null,null,56,null,null,null,9,null,null,null,null,null,null,null,null,56,null,null,null,9,null,null,null,null,null,null,null,null,null,null,null,null,56,null,null,null,9,null,null,null,null,56,null,null,null,9,null,null,null,64,64,null,null,null,null,null,56,null,null,null,9,null,null,null,null,null,null,56,null,null,null,9,null,null,null,null,56,null,null,null,9,null,null,null,null,null,null,null,null,56,null,null,null,9,null,null,null,64,64,null,null,null,null,null,56,null,null,null,9,null,null,null,64,64,null,null,20,56,null,null,null,9,null,null,null,null,null,null,null,null,56,null,null,null,9],"memalloc":[59.2464218139648,59.2464218139648,59.2464218139648,59.2464218139648,59.2464218139648,59.2464218139648,59.2464218139648,59.2464218139648,59.2464218139648,59.2464218139648,59.2464218139648,59.2464218139648,60.4633712768555,60.4633712768555,60.4633712768555,60.4633712768555,60.4633712768555,60.4633712768555,60.4633712768555,60.4633712768555,60.4633712768555,60.4633712768555,60.4633712768555,61.4151916503906,61.4151916503906,61.4151916503906,61.4151916503906,61.4151916503906,61.4151916503906,61.4151916503906,61.4151916503906,61.4151916503906,61.4151916503906,61.4151916503906,61.4151916503906,61.4151916503906,62.8443832397461,62.8443832397461,62.8443832397461,62.8443832397461,62.8443832397461,62.8443832397461,62.8443832397461,62.8443832397461,62.8443832397461,62.8443832397461,62.8443832397461,62.8443832397461,62.8443832397461,62.8443832397461,64.2098770141602,64.2098770141602,64.2098770141602,64.2098770141602,64.2098770141602,64.2098770141602,64.2098770141602,64.2098770141602,64.2098770141602,64.2098770141602,64.2098770141602,64.2098770141602,64.2098770141602,64.2098770141602,64.2098770141602,64.2098770141602,64.2098770141602,66.0163497924805,66.0163497924805,66.0163497924805,66.0163497924805,66.0163497924805,66.0163497924805,66.0163497924805,66.0163497924805,66.0163497924805,66.0163497924805,66.0163497924805,67.0924377441406,67.0924377441406,67.0924377441406,67.0924377441406,67.0924377441406,67.0924377441406,67.0924377441406,67.0924377441406,67.0924377441406,67.0924377441406,67.0924377441406,67.0924377441406,67.0924377441406,68.8353500366211,68.8353500366211,68.8353500366211,68.8353500366211,68.8353500366211,70.6450119018555,70.6450119018555,70.6450119018555,70.6450119018555,70.6450119018555,72.5190048217773,72.5190048217773,72.5190048217773,72.5190048217773,72.5190048217773,72.5190048217773,72.5190048217773,72.5190048217773,72.5190048217773,72.5190048217773,72.5190048217773,72.5190048217773,72.5190048217773,72.5190048217773,72.5190048217773,72.5190048217773,72.5190048217773,74.2494888305664,74.2494888305664,74.2494888305664,74.2494888305664,74.2494888305664,74.2494888305664,74.2494888305664,74.2494888305664,74.2494888305664,74.2494888305664,74.2494888305664,76.2794570922852,76.2794570922852,76.2794570922852,76.2794570922852,76.2794570922852,76.2794570922852,76.2794570922852,76.2794570922852,76.2794570922852,76.2794570922852,76.2794570922852,76.2794570922852,76.2794570922852,76.2794570922852,76.2794570922852,76.2794570922852,76.2794570922852,77.9641952514648,77.9641952514648,77.9641952514648,77.9641952514648,77.9641952514648,77.9641952514648,77.9641952514648,77.9641952514648,77.9641952514648,77.9641952514648,77.9641952514648,77.9641952514648,80.1202011108398,80.1202011108398,80.1202011108398,80.1202011108398,80.1202011108398,80.1202011108398,80.1202011108398,80.1202011108398,80.1202011108398,80.1202011108398,80.1202011108398,80.1202011108398,82.0416717529297,82.0416717529297,82.0416717529297,82.0416717529297,82.0416717529297,82.0416717529297,82.0416717529297,83.849723815918,83.849723815918,83.849723815918,83.849723815918,83.849723815918,62.8146362304688,62.8146362304688,62.8146362304688,62.8146362304688,62.8146362304688,62.8146362304688,62.8146362304688,62.8146362304688,62.8146362304688,62.8146362304688,62.8146362304688,62.8146362304688,64.7885894775391,64.7885894775391,64.7885894775391,64.7885894775391,64.7885894775391,64.7885894775391,64.7885894775391,66.8422546386719,66.8422546386719,66.8422546386719,66.8422546386719,66.8422546386719,66.8422546386719,66.8422546386719,66.8422546386719,66.8422546386719,66.8422546386719,66.8422546386719,66.8422546386719,68.9118270874023,68.9118270874023,68.9118270874023,68.9118270874023,68.9118270874023,68.9118270874023,68.9118270874023,68.9118270874023,68.9118270874023,68.9118270874023,68.9118270874023,71.0610275268555,71.0610275268555,71.0610275268555,71.0610275268555,71.0610275268555,71.0610275268555,71.0610275268555,71.0610275268555,71.0610275268555,71.0610275268555,71.0610275268555,71.0610275268555,71.0610275268555,71.0610275268555,71.0610275268555,74.7627334594727,74.7627334594727,74.7627334594727,74.7627334594727,74.7627334594727,74.7627334594727,74.7627334594727,74.7627334594727,74.7627334594727,74.7627334594727,74.7627334594727,74.7627334594727,76.8125686645508,76.8125686645508,76.8125686645508,76.8125686645508,76.8125686645508,76.8125686645508,76.8125686645508,76.8125686645508,76.8125686645508,76.8125686645508,76.8125686645508,76.8125686645508,76.8125686645508,78.9107131958008,78.9107131958008,78.9107131958008,78.9107131958008,78.9107131958008,78.9107131958008,78.9107131958008,78.9107131958008,78.9107131958008,78.9107131958008,78.9107131958008,81.6169967651367,81.6169967651367,81.6169967651367,81.6169967651367,81.6169967651367,81.6169967651367,81.6169967651367,81.6169967651367,84.1073379516602,84.1073379516602,84.1073379516602,84.1073379516602,84.1073379516602,84.1073379516602,84.1073379516602,84.1073379516602,84.1073379516602,84.1073379516602,84.1073379516602,84.1073379516602,84.1073379516602,84.1073379516602,84.1073379516602,84.1073379516602,84.1073379516602,84.1073379516602,86.0096740722656,86.0096740722656,86.0096740722656,86.0096740722656,86.0096740722656,86.0096740722656,88.494987487793,88.494987487793,88.494987487793,88.494987487793,88.494987487793,88.494987487793,88.494987487793,88.494987487793,66.0162048339844,66.0162048339844,66.0162048339844,66.0162048339844,66.0162048339844,66.0162048339844,66.0162048339844,66.0162048339844,66.0162048339844,66.0162048339844,66.0162048339844,66.0162048339844,66.0162048339844,68.249382019043,68.249382019043,68.249382019043,68.249382019043,68.249382019043,68.249382019043,68.249382019043,68.249382019043,68.249382019043,70.3203430175781,70.3203430175781,70.3203430175781,70.3203430175781,70.3203430175781,70.3203430175781,70.3203430175781,70.3203430175781,72.6830444335938,72.6830444335938,72.6830444335938,72.6830444335938,72.6830444335938,72.6830444335938,72.6830444335938,75.7566299438477,75.7566299438477,75.7566299438477,75.7566299438477,75.7566299438477,75.7566299438477,75.7566299438477,78.0606231689453,78.0606231689453,78.0606231689453,78.0606231689453,78.0606231689453,78.0606231689453,78.0606231689453,78.0606231689453,78.0606231689453,78.0606231689453,78.0606231689453,78.0606231689453,80.2202606201172,80.2202606201172,80.2202606201172,80.2202606201172,80.2202606201172,80.2202606201172,80.2202606201172,80.2202606201172,80.2202606201172,80.2202606201172,80.2202606201172,80.2202606201172,80.2202606201172,83.6984939575195,83.6984939575195,83.6984939575195,83.6984939575195,83.6984939575195,83.6984939575195,83.6984939575195,83.6984939575195,85.9983596801758,85.9983596801758,85.9983596801758,85.9983596801758,85.9983596801758,85.9983596801758,85.9983596801758,85.9983596801758,85.9983596801758,85.9983596801758,85.9983596801758,85.9983596801758,88.2351379394531,88.2351379394531,88.2351379394531,88.2351379394531,88.2351379394531,88.2351379394531,88.2351379394531,88.2351379394531,88.2351379394531,88.2351379394531,88.2351379394531,88.2351379394531,88.2351379394531,88.2351379394531,88.2351379394531,88.2351379394531,91.459228515625,91.459228515625,91.459228515625,91.459228515625,91.459228515625,91.459228515625,91.459228515625,91.459228515625,91.459228515625,91.459228515625,91.459228515625,70.4579772949219,70.4579772949219,70.4579772949219,70.4579772949219,70.4579772949219,70.4579772949219,70.4579772949219,70.4579772949219,70.4579772949219,72.9656295776367,72.9656295776367,72.9656295776367,72.9656295776367,72.9656295776367,72.9656295776367,72.9656295776367,72.9656295776367,72.9656295776367,72.9656295776367,72.9656295776367,72.9656295776367,72.9656295776367,72.9656295776367,72.9656295776367,72.9656295776367,72.9656295776367,75.5184707641602,75.5184707641602,75.5184707641602,75.5184707641602,75.5184707641602,75.5184707641602,75.5184707641602,75.5184707641602,75.5184707641602,75.5184707641602,75.5184707641602,77.5332412719727,77.5332412719727,77.5332412719727,77.5332412719727,77.5332412719727,77.5332412719727,77.5332412719727,77.5332412719727,77.5332412719727,77.5332412719727,77.5332412719727,77.5332412719727,79.9965667724609,79.9965667724609,79.9965667724609,79.9965667724609,79.9965667724609,79.9965667724609,79.9965667724609,82.3229141235352,82.3229141235352,82.3229141235352,82.3229141235352,82.3229141235352,82.3229141235352,82.3229141235352,84.4156951904297,84.4156951904297,84.4156951904297,84.4156951904297,84.4156951904297,84.4156951904297,84.4156951904297,84.4156951904297,87.1273651123047,87.1273651123047,87.1273651123047,87.1273651123047,87.1273651123047,87.1273651123047,87.1273651123047,87.1273651123047,87.1273651123047,87.1273651123047,87.1273651123047,87.1273651123047,87.1273651123047,89.3685989379883,89.3685989379883,89.3685989379883,89.3685989379883,89.3685989379883,89.3685989379883,89.3685989379883,89.3685989379883,89.3685989379883,89.3685989379883,89.3685989379883,90.9356842041016,90.9356842041016,90.9356842041016,90.9356842041016,90.9356842041016,90.9356842041016,90.9356842041016,90.9356842041016,90.9356842041016,90.9356842041016,90.9356842041016,90.9356842041016,91.0815582275391,91.0815582275391,91.0815582275391,91.0815582275391,91.0815582275391,91.0815582275391,91.0815582275391,71.1487579345703,71.1487579345703,71.1487579345703,71.1487579345703,71.1487579345703,71.1487579345703,71.1487579345703,71.1487579345703,71.1487579345703,71.1487579345703,71.1487579345703,71.1487579345703,71.1487579345703,71.1487579345703,71.1487579345703,71.3123474121094,71.3123474121094,71.3123474121094,71.3123474121094,71.3123474121094,71.3123474121094,71.3123474121094,71.3123474121094,71.3123474121094,71.4659271240234,71.4659271240234,71.4659271240234,71.4659271240234,71.4659271240234,71.4659271240234,71.4659271240234,71.4659271240234,71.4659271240234,71.4659271240234,71.4659271240234,71.6568069458008,71.6568069458008,71.6568069458008,71.6568069458008,71.6568069458008,71.6568069458008,71.6568069458008,71.6568069458008,71.6568069458008,71.6568069458008,71.6568069458008,71.6568069458008,71.6568069458008,71.8274841308594,71.8274841308594,71.8274841308594,71.8274841308594,71.8274841308594,71.8274841308594,71.8274841308594,71.8274841308594,71.8274841308594,71.8274841308594,71.8274841308594,71.8274841308594,71.9916839599609,71.9916839599609,71.9916839599609,71.9916839599609,71.9916839599609,71.9916839599609,71.9916839599609,71.9916839599609,71.9916839599609,71.9916839599609,71.9916839599609,71.9916839599609,71.9916839599609,71.9916839599609,71.9916839599609,72.1647033691406,72.1647033691406,72.1647033691406,72.1647033691406,72.1647033691406,72.1647033691406,72.1647033691406,72.1647033691406,72.1647033691406,72.1647033691406,72.1647033691406,72.3263931274414,72.3263931274414,72.3263931274414,72.3263931274414,72.3263931274414,72.3263931274414,72.3263931274414,72.3263931274414,72.3263931274414,72.3263931274414,72.3263931274414,72.3263931274414,72.3263931274414,72.4862594604492,72.4862594604492,72.4862594604492,72.4862594604492,72.4862594604492,72.4862594604492,72.4862594604492,72.4862594604492,72.4862594604492,72.4862594604492,72.4862594604492,72.4862594604492,72.4862594604492,71.0439147949219,71.0439147949219,71.0439147949219,71.0439147949219,71.0439147949219,71.0439147949219,71.0439147949219,71.0439147949219,71.2071075439453,71.2071075439453,71.2071075439453,71.2071075439453,71.2071075439453,71.2071075439453,71.2071075439453,71.2071075439453,71.2071075439453,71.3764266967773,71.3764266967773,71.3764266967773,71.3764266967773,71.3764266967773,71.3764266967773,71.537971496582,71.537971496582,71.537971496582,71.537971496582,71.537971496582,71.537971496582,71.537971496582,71.537971496582,71.7324905395508,71.7324905395508,71.7324905395508,71.7324905395508,71.7324905395508,71.7324905395508,71.7324905395508,71.7324905395508,71.7324905395508,71.7324905395508,71.7324905395508,71.7324905395508,71.7324905395508,71.7324905395508,71.7324905395508,71.8920669555664,71.8920669555664,71.8920669555664,71.8920669555664,71.8920669555664,72.1013870239258,72.1013870239258,72.1013870239258,72.1013870239258,72.1013870239258,72.1013870239258,72.1013870239258,72.3047790527344,72.3047790527344,72.3047790527344,72.3047790527344,72.3047790527344,72.3047790527344,72.3047790527344,72.3047790527344,72.3047790527344,72.3047790527344,72.3047790527344,72.4921188354492,72.4921188354492,72.4921188354492,72.4921188354492,72.4921188354492,72.4921188354492,72.4921188354492,71.048713684082,71.048713684082,71.048713684082,71.048713684082,71.048713684082,71.048713684082,71.048713684082,71.2079544067383,71.2079544067383,71.2079544067383,71.2079544067383,71.2079544067383,71.2079544067383,71.2079544067383,71.2079544067383,71.2079544067383,71.2079544067383,71.3683395385742,71.3683395385742,71.3683395385742,71.3683395385742,71.3683395385742,71.3683395385742,71.3683395385742,71.3683395385742,71.3683395385742,71.3683395385742,71.3683395385742,74.3420791625977,74.3420791625977,74.3420791625977,74.3420791625977,74.3420791625977,74.3420791625977,74.3420791625977,74.3420791625977,74.3420791625977,74.3420791625977,74.3420791625977,74.3420791625977,74.3420791625977,76.9977035522461,76.9977035522461,76.9977035522461,76.9977035522461,76.9977035522461,76.9977035522461,76.9977035522461,76.9977035522461,76.9977035522461,76.9977035522461,79.2266845703125,79.2266845703125,79.2266845703125,79.2266845703125,79.2266845703125,79.2266845703125,79.2266845703125,79.2266845703125,79.2266845703125,79.2266845703125,79.2266845703125,79.2266845703125,81.5157623291016,81.5157623291016,81.5157623291016,81.5157623291016,81.5157623291016,81.5157623291016,81.5157623291016,81.5157623291016,81.5157623291016,81.5157623291016,81.5157623291016,81.5157623291016,85.014045715332,85.014045715332,85.014045715332,85.014045715332,85.014045715332,85.014045715332,85.014045715332,85.014045715332,85.014045715332,85.014045715332,85.014045715332,85.014045715332,88.0028228759766,88.0028228759766,88.0028228759766,88.0028228759766,88.0028228759766,88.0028228759766,88.0028228759766,88.0028228759766,88.0028228759766,88.0028228759766,88.0028228759766,90.6394195556641,90.6394195556641,90.6394195556641,90.6394195556641,90.6394195556641,90.6394195556641,90.6394195556641,90.6394195556641,90.6394195556641,90.6394195556641,90.6394195556641,90.6394195556641,90.6394195556641,93.6483917236328,93.6483917236328,93.6483917236328,93.6483917236328,93.6483917236328,93.6483917236328,93.6483917236328,93.6483917236328,93.6483917236328,93.6483917236328,93.6483917236328,93.6483917236328,93.6483917236328,96.2437515258789,96.2437515258789,96.2437515258789,96.2437515258789,96.2437515258789,96.2437515258789,96.2437515258789,96.2437515258789,96.2437515258789,96.2437515258789,96.2437515258789,96.2437515258789,96.2437515258789,76.2183303833008,76.2183303833008,76.2183303833008,76.2183303833008,76.2183303833008,76.2183303833008,76.2183303833008,76.2183303833008,76.2183303833008,76.2183303833008,78.9855194091797,78.9855194091797,78.9855194091797,78.9855194091797,78.9855194091797,78.9855194091797,78.9855194091797,78.9855194091797,78.9855194091797,78.9855194091797,78.9855194091797,78.9855194091797,78.9855194091797,81.2664337158203,81.2664337158203,81.2664337158203,81.2664337158203,81.2664337158203,83.3083724975586,83.3083724975586,83.3083724975586,83.3083724975586,83.3083724975586,83.3083724975586,83.3083724975586,83.3083724975586,83.3083724975586,83.3083724975586,83.3083724975586,83.3083724975586,83.3083724975586,85.1879806518555,85.1879806518555,85.1879806518555,85.1879806518555,85.1879806518555,85.1879806518555,85.1879806518555,85.1879806518555,85.1879806518555,85.1879806518555,85.1879806518555,85.1879806518555,85.1879806518555,85.1879806518555,85.1879806518555,87.2407150268555,87.2407150268555,87.2407150268555,87.2407150268555,87.2407150268555,87.2407150268555,87.2407150268555,88.5598602294922,88.5598602294922,88.5598602294922,88.5598602294922,88.5598602294922,88.5598602294922,88.5598602294922,88.5598602294922,88.5598602294922,88.5598602294922,88.5598602294922,88.5598602294922,88.5598602294922,90.2142715454102,90.2142715454102,90.2142715454102,90.2142715454102,90.2142715454102,92.2732543945312,92.2732543945312,92.2732543945312,92.2732543945312,92.2732543945312,92.2732543945312,92.2732543945312,92.2732543945312,92.2732543945312,92.2732543945312,92.2732543945312,92.2732543945312,94.4347229003906,94.4347229003906,94.4347229003906,94.4347229003906,94.4347229003906,94.4347229003906,94.4347229003906,94.4347229003906,94.4347229003906,94.4347229003906,94.4347229003906,94.4347229003906,96.2751998901367,96.2751998901367,96.2751998901367,96.2751998901367,96.2751998901367,96.2751998901367,96.2751998901367,96.2751998901367,96.2751998901367,96.2751998901367,96.2751998901367,96.2751998901367,98.8962707519531,98.8962707519531,98.8962707519531,98.8962707519531,98.8962707519531,98.8962707519531,98.8962707519531,98.8962707519531,98.8962707519531,98.8962707519531,98.8962707519531,98.8962707519531,98.8962707519531,101.229858398438,101.229858398438,101.229858398438,101.229858398438,101.229858398438,101.229858398438,102.676666259766,102.676666259766,102.676666259766,102.676666259766,102.676666259766,102.676666259766,102.676666259766,102.676666259766,102.676666259766,102.676666259766,102.676666259766,102.676666259766,104.248596191406,104.248596191406,104.248596191406,104.248596191406,104.248596191406,104.248596191406,104.248596191406,106.171684265137,106.171684265137,106.171684265137,106.171684265137,106.171684265137,106.171684265137,106.171684265137,106.171684265137,106.171684265137,106.171684265137,106.171684265137,106.171684265137,106.171684265137,106.171684265137,79.3790512084961,79.3790512084961,79.3790512084961,79.3790512084961,79.3790512084961,79.3790512084961,79.3790512084961,79.3790512084961,79.3790512084961,79.3790512084961,79.3790512084961,79.3790512084961,79.3790512084961,81.2206192016602,81.2206192016602,81.2206192016602,81.2206192016602,81.2206192016602,81.2206192016602,81.2206192016602,81.2206192016602,81.2206192016602,81.2206192016602,81.2206192016602,83.4701614379883,83.4701614379883,83.4701614379883,83.4701614379883,83.4701614379883,83.4701614379883,83.4701614379883,83.4701614379883,83.4701614379883,83.4701614379883,83.4701614379883,83.4701614379883,83.4701614379883,83.4701614379883,83.4701614379883,86.1501388549805,86.1501388549805,86.1501388549805,86.1501388549805,86.1501388549805,86.1501388549805,86.1501388549805,88.557502746582,88.557502746582,88.557502746582,88.557502746582,88.557502746582,88.557502746582,88.557502746582,88.557502746582,88.557502746582,90.8220291137695,90.8220291137695,90.8220291137695,90.8220291137695,90.8220291137695,93.1859512329102,93.1859512329102,96.8109436035156,96.8109436035156,96.8109436035156,96.8109436035156,96.8109436035156,96.8109436035156,96.8109436035156,96.8109436035156,99.0844039916992,99.0844039916992,99.0844039916992,99.0844039916992,99.0844039916992,99.0844039916992,99.0844039916992,99.0844039916992,99.0844039916992,99.0844039916992,99.0844039916992,101.857238769531,101.857238769531,101.857238769531,101.857238769531,101.857238769531,101.857238769531,101.857238769531,101.857238769531,101.857238769531,103.950958251953,103.950958251953,103.950958251953,103.950958251953,103.950958251953,103.950958251953,103.950958251953,103.950958251953,103.950958251953,103.950958251953,103.950958251953,103.950958251953,103.950958251953,103.950958251953,105.478080749512,105.478080749512,105.478080749512,105.478080749512,105.478080749512,105.478080749512,107.192901611328,107.192901611328,107.192901611328,107.192901611328,107.192901611328,107.192901611328,107.192901611328,107.192901611328,108.49681854248,108.49681854248,108.49681854248,108.49681854248,108.49681854248,108.49681854248,108.49681854248,81.1758651733398,81.1758651733398,81.1758651733398,81.1758651733398,81.1758651733398,81.1758651733398,81.1758651733398,81.1758651733398,81.1758651733398,81.1758651733398,81.1758651733398,81.1758651733398,82.6920776367188,82.6920776367188,82.6920776367188,82.6920776367188,82.6920776367188,82.6920776367188,82.6920776367188,82.6920776367188,82.6920776367188,82.6920776367188,82.6920776367188,82.6920776367188,84.9920196533203,84.9920196533203,84.9920196533203,84.9920196533203,84.9920196533203,84.9920196533203,84.9920196533203,84.9920196533203,84.9920196533203,84.9920196533203,84.9920196533203,84.9920196533203,87.5899276733398,87.5899276733398,87.5899276733398,87.5899276733398,87.5899276733398,87.5899276733398,87.5899276733398,90.2878189086914,90.2878189086914,90.2878189086914,90.2878189086914,90.2878189086914,93.1766891479492,93.1766891479492,93.1766891479492,93.1766891479492,93.1766891479492,93.1766891479492,93.1766891479492,93.1766891479492,93.1766891479492,93.1766891479492,93.1766891479492,93.1766891479492,93.1766891479492,95.8992919921875,95.8992919921875,95.8992919921875,95.8992919921875,95.8992919921875,100.290802001953,100.290802001953,100.290802001953,100.290802001953,100.290802001953,100.290802001953,100.290802001953,100.290802001953,100.290802001953,103.13941192627,103.13941192627,103.13941192627,103.13941192627,103.13941192627,103.13941192627,103.13941192627,103.13941192627,103.13941192627,103.13941192627,103.13941192627,105.628128051758,105.628128051758,105.628128051758,105.628128051758,108.248794555664,108.248794555664,108.248794555664,108.248794555664,108.248794555664,108.248794555664,110.90601348877,110.90601348877,110.90601348877,110.90601348877,110.90601348877,110.90601348877,110.90601348877,110.90601348877,110.90601348877,110.90601348877,110.90601348877,85.031005859375,85.031005859375,85.031005859375,85.031005859375,85.031005859375,85.031005859375,87.7156372070312,87.7156372070312,87.7156372070312,87.7156372070312,87.7156372070312,87.7156372070312,87.7156372070312,90.3698806762695,90.3698806762695,90.3698806762695,90.3698806762695,90.3698806762695,90.3698806762695,93.0378723144531,93.0378723144531,93.0378723144531,93.0378723144531,93.0378723144531,93.0378723144531,93.0378723144531,94.7928466796875,94.7928466796875,94.7928466796875,94.7928466796875,94.7928466796875,94.7928466796875,94.7928466796875,94.7928466796875,94.7928466796875,94.9812469482422,94.9812469482422,94.9812469482422,94.9812469482422,94.9812469482422,94.9812469482422,94.9812469482422,94.9812469482422,94.9812469482422,94.9812469482422,94.9812469482422,94.9812469482422,95.1359024047852,95.1359024047852,95.1359024047852,95.1359024047852,95.1359024047852,95.1359024047852,95.1359024047852,95.1359024047852,95.3042449951172,95.3042449951172,95.3042449951172,95.3042449951172,95.3042449951172,95.3042449951172,95.5122299194336,95.5122299194336,95.5122299194336,95.5122299194336,95.5122299194336,95.5122299194336,95.5122299194336,95.5122299194336,95.5122299194336,95.6657562255859,95.6657562255859,95.6657562255859,95.6657562255859,95.6657562255859,95.6657562255859,95.6657562255859,95.6657562255859,95.7601089477539,95.7601089477539,95.7601089477539,95.7601089477539,95.7601089477539,95.7601089477539,73.3016815185547,73.3016815185547,73.3016815185547,73.3016815185547,73.3016815185547,73.3016815185547,73.3611373901367,73.3611373901367,73.3611373901367,73.3611373901367,73.3611373901367,73.3611373901367,73.3611373901367,73.3611373901367,73.3611373901367,73.3611373901367,73.3611373901367,73.5292587280273,73.5292587280273,73.5292587280273,73.5292587280273,73.5292587280273,73.5292587280273,73.5292587280273,73.5292587280273,73.5292587280273,73.5292587280273,73.7212829589844,73.7212829589844,73.7212829589844,73.7212829589844,73.7212829589844,73.7212829589844,73.7212829589844,73.7212829589844,73.7212829589844,73.7212829589844,73.7212829589844,73.7212829589844,73.7212829589844,73.8653335571289,73.8653335571289,73.8653335571289,73.8653335571289,73.8653335571289,73.8653335571289,74.0195617675781,74.0195617675781,74.0195617675781,74.0195617675781,74.0195617675781,74.0195617675781,74.0195617675781,74.0195617675781,74.1772384643555,74.1772384643555,74.1772384643555,74.1772384643555,74.1772384643555,74.1772384643555,74.1772384643555,74.1772384643555,74.1772384643555,74.1772384643555,74.1772384643555,74.1772384643555,74.4172744750977,74.4172744750977,74.4172744750977,74.4172744750977,74.4172744750977,74.4172744750977,74.4172744750977,74.4172744750977,74.4172744750977,74.4172744750977,74.4172744750977,74.4172744750977,74.5534133911133,74.5534133911133,74.5534133911133,74.5534133911133,74.5534133911133,74.5534133911133,74.5534133911133,74.5534133911133,74.5534133911133,74.5534133911133,74.7238693237305,74.7238693237305,74.7238693237305,74.7238693237305,74.7238693237305,74.7238693237305,74.7238693237305,74.7238693237305,74.7238693237305,74.7238693237305,74.8755569458008,74.8755569458008,74.8755569458008,74.8755569458008,74.8755569458008,74.8755569458008,74.8755569458008,74.8755569458008,74.8755569458008,73.3597946166992,73.3597946166992,73.3597946166992,73.3597946166992,73.3597946166992,73.3597946166992,73.3597946166992,73.3597946166992,73.5587997436523,73.5587997436523,73.5587997436523,73.5587997436523,73.5587997436523,73.5587997436523,73.5587997436523,73.5587997436523,73.5587997436523,73.7446594238281,73.7446594238281,73.7446594238281,73.7446594238281,73.7446594238281,73.7446594238281,73.7446594238281,73.7446594238281,73.7446594238281,73.7446594238281,73.7446594238281,73.7446594238281,73.7446594238281,73.7446594238281,73.7446594238281,73.9309234619141,73.9309234619141,73.9309234619141,73.9309234619141,73.9309234619141,73.9309234619141,73.9309234619141,73.9309234619141,73.9309234619141,73.9309234619141,73.9309234619141,73.9309234619141,73.9309234619141,73.9309234619141,74.1225814819336,74.1225814819336,74.1225814819336,74.1225814819336,74.1225814819336,74.1225814819336,74.302131652832,74.302131652832,74.302131652832,74.302131652832,74.302131652832,74.302131652832,74.302131652832,74.302131652832,74.302131652832,74.302131652832,74.302131652832,74.302131652832,74.302131652832,74.302131652832,74.302131652832,74.302131652832,74.302131652832,74.4744491577148,74.4744491577148,74.4744491577148,74.4744491577148,74.4744491577148,74.4744491577148,74.4744491577148,74.4744491577148,74.4744491577148,74.4744491577148,74.4744491577148,74.4744491577148,74.4744491577148,74.4744491577148,76.6286773681641,76.6286773681641,76.6286773681641,76.6286773681641,76.6286773681641,76.6286773681641,76.6286773681641,76.6286773681641,76.6286773681641,76.6286773681641,76.6286773681641,76.6286773681641,76.6286773681641,79.2855072021484,79.2855072021484,79.2855072021484,79.2855072021484,79.2855072021484,79.2855072021484,79.2855072021484,79.2855072021484,79.2855072021484,79.2855072021484,79.2855072021484,79.2855072021484,81.8455429077148,81.8455429077148,81.8455429077148,81.8455429077148,81.8455429077148,81.8455429077148,81.8455429077148,81.8455429077148,81.8455429077148,81.8455429077148,81.8455429077148,81.8455429077148,74.3599166870117,74.3599166870117,74.3599166870117,74.3599166870117,74.3599166870117,74.3599166870117,74.3599166870117,74.3599166870117,74.3599166870117,74.3599166870117,74.3599166870117,74.3599166870117,77.193244934082,77.193244934082,77.193244934082,77.193244934082,77.193244934082,77.193244934082,77.193244934082,77.193244934082,77.193244934082,77.193244934082,77.193244934082,77.193244934082,80.2401962280273,80.2401962280273,80.2401962280273,80.2401962280273,80.2401962280273,80.2401962280273,80.2401962280273,80.2401962280273,80.2401962280273,80.2401962280273,80.2401962280273,80.2401962280273,80.2401962280273,83.0951766967773,83.0951766967773,83.0951766967773,83.0951766967773,83.0951766967773,83.0951766967773,83.0951766967773,83.0951766967773,83.0951766967773,83.0951766967773,83.0951766967773,83.0951766967773,85.9982452392578,85.9982452392578,85.9982452392578,85.9982452392578,85.9982452392578,85.9982452392578,85.9982452392578,85.9982452392578,85.9982452392578,89.6339797973633,89.6339797973633,89.6339797973633,89.6339797973633,89.6339797973633,89.6339797973633,92.4935836791992,92.4935836791992,92.4935836791992,92.4935836791992,92.4935836791992,92.4935836791992,96.2096405029297,96.2096405029297,96.2096405029297,96.2096405029297,96.2096405029297,96.2096405029297,96.2096405029297,96.2096405029297,96.2096405029297,96.2096405029297,96.2096405029297,99.7957916259766,99.7957916259766,99.7957916259766,99.7957916259766,99.7957916259766,99.7957916259766,99.7957916259766,99.7957916259766,99.7957916259766,99.7957916259766,102.925888061523,102.925888061523,102.925888061523,102.925888061523,102.925888061523,102.925888061523,102.925888061523,102.925888061523,102.925888061523,102.925888061523,102.925888061523,102.925888061523,105.884773254395,105.884773254395,105.884773254395,105.884773254395,105.884773254395,105.884773254395,105.884773254395,105.884773254395,105.884773254395,105.884773254395,105.884773254395,105.884773254395,105.884773254395,108.826950073242,108.826950073242,108.826950073242,108.826950073242,108.826950073242,108.826950073242,111.911811828613,111.911811828613,111.911811828613,111.911811828613,111.911811828613,111.911811828613,111.911811828613,111.911811828613,111.911811828613,111.911811828613,111.911811828613,114.190574645996,114.190574645996,114.190574645996,114.190574645996,114.190574645996,114.190574645996,114.190574645996,114.190574645996,114.190574645996,114.190574645996,114.190574645996,114.190574645996,114.190574645996,80.6519165039062,80.6519165039062,80.6519165039062,80.6519165039062,80.6519165039062,80.6519165039062,80.6519165039062,80.6519165039062,80.6519165039062,80.6519165039062,80.6519165039062,80.6519165039062,83.7206726074219,83.7206726074219,83.7206726074219,83.7206726074219,83.7206726074219,83.7206726074219,83.7206726074219,83.7206726074219,83.7206726074219,83.7206726074219,83.7206726074219,83.7206726074219,83.7206726074219,83.7206726074219,86.9740219116211,86.9740219116211,86.9740219116211,86.9740219116211,86.9740219116211,86.9740219116211,86.9740219116211,86.9740219116211,86.9740219116211,86.9740219116211,89.50390625,89.50390625,89.50390625,89.50390625,89.50390625,89.50390625,89.50390625,89.50390625,89.50390625,89.50390625,89.50390625,92.0169448852539,92.0169448852539,92.0169448852539,92.0169448852539,92.0169448852539,92.0169448852539,92.0169448852539,94.9203262329102,94.9203262329102,94.9203262329102,94.9203262329102,94.9203262329102,94.9203262329102,94.9203262329102,94.9203262329102,94.9203262329102,94.9203262329102,94.9203262329102,98.6478576660156,98.6478576660156,98.6478576660156,98.6478576660156,98.6478576660156,98.6478576660156,98.6478576660156,98.6478576660156,98.6478576660156,98.6478576660156,98.6478576660156,98.6478576660156,98.6478576660156,101.495025634766,101.495025634766,101.495025634766,101.495025634766,101.495025634766,101.495025634766,101.495025634766,101.495025634766,101.495025634766,101.495025634766,101.495025634766,101.495025634766,104.616455078125,104.616455078125,104.616455078125,104.616455078125,104.616455078125,104.616455078125,104.616455078125,104.616455078125,108.805931091309,108.805931091309,108.805931091309,108.805931091309,108.805931091309,108.805931091309,108.805931091309,108.805931091309,108.805931091309,108.805931091309,108.805931091309,108.805931091309,108.805931091309,111.66722869873,111.66722869873,111.66722869873,111.66722869873,111.66722869873,111.66722869873,111.66722869873,111.66722869873,111.66722869873,111.66722869873,111.66722869873,111.66722869873,115.236679077148,115.236679077148,115.236679077148,115.236679077148,115.236679077148,115.236679077148,115.236679077148,117.749702453613,117.749702453613,117.749702453613,117.749702453613,117.749702453613,117.749702453613,117.749702453613,117.749702453613,117.749702453613,84.1497573852539,84.1497573852539,84.1497573852539,84.1497573852539,84.1497573852539,84.1497573852539,84.1497573852539,84.1497573852539,84.1497573852539,84.1497573852539,84.1497573852539,84.1497573852539,87.0089340209961,87.0089340209961,87.0089340209961,87.0089340209961,87.0089340209961,87.0089340209961,87.0089340209961,87.0089340209961,87.0089340209961,87.0089340209961,87.0089340209961,87.0089340209961,90.5513076782227,90.5513076782227,90.5513076782227,90.5513076782227,90.5513076782227,90.5513076782227,90.5513076782227,90.5513076782227,90.5513076782227,90.5513076782227,90.5513076782227,90.5513076782227,90.5513076782227,92.6859817504883,92.6859817504883,92.6859817504883,92.6859817504883,92.6859817504883,92.6859817504883,92.6859817504883,92.6859817504883,92.6859817504883,92.6859817504883,92.6859817504883,92.6859817504883,92.6859817504883,92.6859817504883,95.8799667358398,95.8799667358398,95.8799667358398,95.8799667358398,95.8799667358398,95.8799667358398,99.1284942626953,99.1284942626953,99.1284942626953,99.1284942626953,99.1284942626953,99.1284942626953,99.1284942626953,99.1284942626953,99.1284942626953,99.1284942626953,99.1284942626953,99.1284942626953,102.554740905762,102.554740905762,102.554740905762,102.554740905762,102.554740905762,102.554740905762,102.554740905762,102.554740905762,102.554740905762,102.554740905762,102.554740905762,102.554740905762,102.554740905762,102.554740905762,102.554740905762,105.711349487305,105.711349487305,105.711349487305,105.711349487305,105.711349487305,109.612869262695,109.612869262695,109.612869262695,109.612869262695,109.612869262695,109.612869262695,109.612869262695,109.612869262695,109.612869262695,109.612869262695,109.612869262695,112.741561889648,112.741561889648,112.741561889648,112.741561889648,112.741561889648,112.741561889648,112.741561889648,112.741561889648,112.741561889648,112.741561889648,112.741561889648,112.741561889648,112.741561889648,112.741561889648,115.75171661377,115.75171661377,115.75171661377,115.75171661377,115.75171661377,115.75171661377,115.75171661377,115.75171661377,115.75171661377,115.75171661377,115.75171661377,118.753387451172,118.753387451172,118.753387451172,118.753387451172,118.753387451172,118.753387451172,118.753387451172,121.278053283691,121.278053283691,121.278053283691,121.278053283691,121.278053283691,121.278053283691,121.278053283691,121.278053283691,121.278053283691,121.278053283691,121.278053283691,121.278053283691,121.278053283691,121.278053283691,121.278053283691,121.278053283691,89.5454177856445,89.5454177856445,89.5454177856445,89.5454177856445,89.5454177856445,89.5454177856445,89.5454177856445,89.5454177856445,89.5454177856445,89.5454177856445,89.5454177856445,89.5454177856445,89.5454177856445,93.2611846923828,93.2611846923828,93.2611846923828,93.2611846923828,93.2611846923828,93.2611846923828,93.2611846923828,93.2611846923828,93.2611846923828,93.2611846923828,93.2611846923828,93.2611846923828,93.2611846923828,93.2611846923828,96.25244140625,96.25244140625,96.25244140625,96.25244140625,96.25244140625,96.25244140625,96.25244140625,96.25244140625,96.25244140625,96.25244140625,96.25244140625,96.25244140625,96.25244140625,96.25244140625,96.25244140625,96.25244140625,99.291259765625,99.291259765625,99.291259765625,99.291259765625,99.291259765625,99.291259765625,99.291259765625,99.291259765625,99.291259765625,99.291259765625,99.291259765625,102.584777832031,102.584777832031,102.584777832031,102.584777832031,102.584777832031,102.584777832031,102.584777832031,102.584777832031,102.584777832031,102.584777832031,102.584777832031,102.584777832031,102.584777832031,105.96070098877,105.96070098877,105.96070098877,105.96070098877,105.96070098877,105.96070098877,108.809326171875,108.809326171875,108.809326171875,108.809326171875,108.809326171875,108.809326171875,108.809326171875,108.809326171875,108.809326171875,112.090782165527,112.090782165527,112.090782165527,112.090782165527,112.090782165527,112.090782165527,112.090782165527,112.090782165527,112.090782165527,112.090782165527,112.090782165527,112.090782165527,115.450386047363,115.450386047363,115.450386047363,115.450386047363,115.450386047363,115.450386047363,115.450386047363,115.450386047363,115.450386047363,115.450386047363,115.450386047363,115.450386047363,115.450386047363,115.450386047363,115.450386047363,115.450386047363,118.476341247559,118.476341247559,118.476341247559,118.476341247559,118.476341247559,118.476341247559,118.476341247559,118.476341247559,118.476341247559,118.476341247559,118.476341247559,118.476341247559,119.587348937988,119.587348937988,119.587348937988,119.587348937988,119.587348937988,119.587348937988,119.71736907959,119.71736907959,119.71736907959,119.71736907959,119.71736907959,119.71736907959,119.71736907959,119.71736907959,119.71736907959,90.4572448730469,90.4572448730469,90.4572448730469,90.4572448730469,90.4572448730469,90.4572448730469,90.4572448730469,90.4572448730469,90.4572448730469,90.4572448730469,90.4572448730469,90.6381225585938,90.6381225585938,90.6381225585938,90.6381225585938,90.7959213256836,90.7959213256836,90.7959213256836,90.7959213256836,90.7959213256836,90.7959213256836,90.7959213256836,90.7959213256836,90.7959213256836,90.7959213256836,90.7959213256836,90.7959213256836,90.9428558349609,90.9428558349609,90.9428558349609,90.9428558349609,90.9428558349609,90.9428558349609,90.9428558349609,90.9428558349609,90.9428558349609,90.9428558349609,91.130012512207,91.130012512207,91.130012512207,91.130012512207,91.130012512207,91.130012512207,91.130012512207,91.130012512207,91.130012512207,91.130012512207,91.3461761474609,91.3461761474609,91.3461761474609,91.3461761474609,91.3461761474609,91.3461761474609,91.3461761474609,91.3461761474609,91.3461761474609,91.3461761474609,91.3461761474609,91.3461761474609,91.3461761474609,91.3461761474609,91.3461761474609,91.5152587890625,91.5152587890625,91.5152587890625,91.5152587890625,91.5152587890625,91.5152587890625,91.6554336547852,91.6554336547852,91.6554336547852,91.6554336547852,91.6554336547852,91.6554336547852,91.6554336547852,91.6554336547852,91.6554336547852,91.6554336547852,91.6554336547852,90.3182373046875,90.3182373046875,90.3182373046875,90.3182373046875,90.3182373046875,90.3182373046875,90.3182373046875,90.3182373046875,90.3182373046875,90.3182373046875,90.4728240966797,90.4728240966797,90.4728240966797,90.4728240966797,90.4728240966797,90.4728240966797,90.4728240966797,90.4728240966797,90.4728240966797,90.4728240966797,90.4728240966797,90.4728240966797,90.4728240966797,90.6418228149414,90.6418228149414,90.6418228149414,90.6418228149414,90.6418228149414,90.6418228149414,90.6418228149414,90.6418228149414,90.8074569702148,90.8074569702148,90.8074569702148,90.8074569702148,90.8074569702148,90.8074569702148,90.8074569702148,90.9772567749023,90.9772567749023,90.9772567749023,90.9772567749023,90.9772567749023,90.9772567749023,90.9772567749023,90.9772567749023,90.9772567749023,90.9772567749023,90.9772567749023,91.1757583618164,91.1757583618164,91.1757583618164,91.1757583618164,91.1757583618164,91.1757583618164,91.1757583618164,91.1757583618164,91.1757583618164,91.1757583618164,91.1757583618164,91.1757583618164,91.1757583618164,91.3494567871094,91.3494567871094,91.3494567871094,91.3494567871094,91.3494567871094,91.3494567871094,91.3494567871094,91.3494567871094,91.3494567871094,91.3494567871094,91.3494567871094,91.3494567871094,91.3494567871094,91.5410079956055,91.5410079956055,91.5410079956055,91.5410079956055,91.5410079956055,91.5410079956055,91.5410079956055,91.5410079956055,91.6906585693359,91.6906585693359,91.6906585693359,91.6906585693359,91.6906585693359,91.6906585693359,91.6906585693359,91.6906585693359,91.6906585693359,91.6906585693359,91.6906585693359,91.6906585693359,91.6906585693359,91.8347396850586,91.8347396850586,91.8347396850586,91.8347396850586,91.8347396850586,91.8347396850586,91.8347396850586,91.8347396850586,91.8347396850586,91.8347396850586,90.4619674682617,90.4619674682617,90.4619674682617,90.4619674682617,90.4619674682617,90.4619674682617,90.4619674682617,90.4619674682617,90.6597137451172,90.6597137451172,90.6597137451172,90.6597137451172,90.6597137451172,90.6597137451172,90.6597137451172,90.8204498291016,90.8204498291016,90.8204498291016,90.8204498291016,90.8204498291016,90.8204498291016,90.8204498291016,90.8204498291016,90.8204498291016,92.2358474731445,92.2358474731445,92.2358474731445,92.2358474731445,92.2358474731445,92.2358474731445,92.2358474731445,92.2358474731445,92.2358474731445,92.2358474731445,92.2358474731445,95.2321853637695,95.2321853637695,95.2321853637695,95.2321853637695,95.2321853637695,95.2321853637695,95.2321853637695,95.2321853637695,95.2321853637695,95.2321853637695,95.2321853637695,95.2321853637695,98.4675445556641,98.4675445556641,98.4675445556641,98.4675445556641,98.4675445556641,98.4675445556641,98.4675445556641,98.4675445556641,98.4675445556641,98.4675445556641,98.4675445556641,102.894386291504,102.894386291504,102.894386291504,102.894386291504,102.894386291504,102.894386291504,102.894386291504,102.894386291504,102.894386291504,102.894386291504,102.894386291504,102.894386291504,102.894386291504,102.894386291504,106.368469238281,106.368469238281,106.368469238281,106.368469238281,106.368469238281,106.368469238281,106.368469238281,106.368469238281,106.368469238281,106.368469238281,106.368469238281,109.592346191406,109.592346191406,109.592346191406,109.592346191406,109.592346191406,109.592346191406,109.592346191406,109.592346191406,109.592346191406,109.592346191406,109.592346191406,112.713119506836,112.713119506836,112.713119506836,112.713119506836,112.713119506836,112.713119506836,112.713119506836,112.713119506836,112.713119506836,112.713119506836,116.508651733398,116.508651733398,116.508651733398,116.508651733398,116.508651733398,116.508651733398,116.508651733398,116.508651733398,116.508651733398,116.508651733398,116.508651733398,116.508651733398,116.508651733398,94.8912811279297,94.8912811279297,94.8912811279297,94.8912811279297,94.8912811279297,94.8912811279297,94.8912811279297,94.8912811279297,94.8912811279297,94.8912811279297,94.8912811279297,94.8912811279297,98.3824920654297,98.3824920654297,98.3824920654297,98.3824920654297,98.3824920654297,98.3824920654297,98.3824920654297,98.3824920654297,98.3824920654297,98.3824920654297,98.3824920654297,98.3824920654297,98.3824920654297,98.3824920654297,101.843231201172,101.843231201172,101.843231201172,101.843231201172,101.843231201172,101.843231201172,101.843231201172,101.843231201172,101.843231201172,101.843231201172,101.843231201172,101.843231201172,101.843231201172,105.927871704102,105.927871704102,105.927871704102,105.927871704102,105.927871704102,108.795822143555,108.795822143555,108.795822143555,108.795822143555,108.795822143555,108.795822143555,108.795822143555,108.795822143555,108.795822143555,112.99861907959,112.99861907959,112.99861907959,112.99861907959,112.99861907959,112.99861907959,112.99861907959,112.99861907959,112.99861907959,112.99861907959,112.99861907959,116.98876953125,116.98876953125,116.98876953125,116.98876953125,116.98876953125,116.98876953125,116.98876953125,116.98876953125,116.98876953125,116.98876953125,116.98876953125,116.98876953125,116.98876953125,120.415084838867,120.415084838867,120.415084838867,120.415084838867,120.415084838867,120.415084838867,124.197082519531,124.197082519531,124.197082519531,124.197082519531,124.197082519531,124.197082519531,124.197082519531,124.197082519531,124.197082519531,124.197082519531,124.197082519531,124.197082519531,124.197082519531,128.115158081055,128.115158081055,128.115158081055,128.115158081055,128.115158081055,128.115158081055,128.115158081055,128.115158081055,128.115158081055,128.115158081055,128.115158081055,128.115158081055,128.115158081055,130.634231567383,130.634231567383,130.634231567383,130.634231567383,130.634231567383,130.634231567383,130.634231567383,130.634231567383,130.634231567383,130.634231567383,130.634231567383,130.634231567383,130.634231567383,130.634231567383,134.22045135498,134.22045135498,134.22045135498,134.22045135498,134.22045135498,134.22045135498,134.22045135498,134.22045135498,134.22045135498,134.22045135498,134.22045135498,134.22045135498,134.22045135498,106.517028808594,106.517028808594,106.517028808594,106.517028808594,106.517028808594,106.517028808594,106.517028808594,106.517028808594,106.517028808594,106.517028808594,100.772186279297,100.772186279297,100.772186279297,100.772186279297,100.772186279297,104.572486877441,104.572486877441,104.572486877441,104.572486877441,104.572486877441,104.572486877441,104.572486877441,104.572486877441,104.572486877441,104.572486877441,108.347724914551,108.347724914551,108.347724914551,108.347724914551,108.347724914551,108.347724914551,108.347724914551,108.347724914551,108.347724914551,111.987602233887,111.987602233887,111.987602233887,111.987602233887,111.987602233887,111.987602233887,111.987602233887,111.987602233887,111.987602233887,111.987602233887,111.987602233887,111.987602233887,115.697288513184,115.697288513184,115.697288513184,115.697288513184,115.697288513184,115.697288513184,115.697288513184,115.697288513184,115.697288513184,118.610252380371,118.610252380371,118.610252380371,118.610252380371,118.610252380371,122.481063842773,122.481063842773,122.481063842773,122.481063842773,122.481063842773,122.481063842773,122.481063842773,122.481063842773,122.481063842773,122.481063842773,125.530944824219,125.530944824219,125.530944824219,125.530944824219,125.530944824219,125.530944824219,125.530944824219,125.530944824219,125.530944824219,125.530944824219,125.530944824219,125.530944824219,125.530944824219,129.724433898926,129.724433898926,129.724433898926,129.724433898926,129.724433898926,129.724433898926,129.724433898926,129.724433898926,129.724433898926,133.110054016113,133.110054016113,133.110054016113,133.110054016113,133.110054016113,133.110054016113,133.110054016113,133.110054016113,133.110054016113,133.110054016113,136.314979553223,136.314979553223,136.314979553223,136.314979553223,136.314979553223,136.314979553223,136.314979553223,136.314979553223,136.314979553223,136.314979553223,136.314979553223,136.314979553223,136.314979553223,139.453659057617,139.453659057617,139.453659057617,139.453659057617,139.453659057617,102.700942993164,102.700942993164,102.700942993164,102.700942993164,102.700942993164,102.700942993164,102.700942993164,102.700942993164,102.700942993164,106.438697814941,106.438697814941,106.438697814941,106.438697814941,106.438697814941,106.438697814941,106.438697814941,106.438697814941,106.438697814941,106.438697814941,106.438697814941,109.47615814209,109.47615814209,109.47615814209,109.47615814209,109.47615814209,109.47615814209,109.47615814209,109.47615814209,109.47615814209,109.47615814209,109.47615814209,109.47615814209,112.85774230957,112.85774230957,112.85774230957,112.85774230957,112.85774230957,112.85774230957,112.85774230957,112.85774230957,112.85774230957,112.85774230957,112.85774230957,116.245941162109,116.245941162109,116.245941162109,116.245941162109,116.245941162109,119.189376831055,119.189376831055,119.189376831055,119.189376831055,119.189376831055,119.189376831055,119.189376831055,119.189376831055,119.189376831055,119.189376831055,119.189376831055,122.314727783203,122.314727783203,122.314727783203,122.314727783203,122.314727783203,122.314727783203,122.314727783203,122.314727783203,122.314727783203,122.314727783203,122.314727783203,122.314727783203,126.637306213379,126.637306213379,126.637306213379,126.637306213379,126.637306213379,126.637306213379,126.637306213379,126.637306213379,126.637306213379,126.637306213379,126.637306213379,126.637306213379,130.698913574219,130.698913574219,130.698913574219,130.698913574219,130.698913574219,130.698913574219,130.698913574219,130.698913574219,130.698913574219,130.698913574219,130.698913574219,130.698913574219,134.627830505371,134.627830505371,134.627830505371,134.627830505371,134.627830505371,134.627830505371,134.627830505371,134.627830505371,134.627830505371,134.627830505371,134.627830505371,134.627830505371,134.627830505371,134.627830505371,134.627830505371,134.627830505371,134.627830505371,134.627830505371,138.004768371582,138.004768371582,138.004768371582,138.004768371582,138.004768371582,138.004768371582,139.504615783691,139.504615783691,139.504615783691,139.504615783691,139.504615783691,139.504615783691,139.504615783691,139.504615783691,139.504615783691,139.504615783691,139.504615783691,139.504615783691,139.504615783691,139.504615783691,139.504615783691,139.504615783691,141.00496673584,141.00496673584,141.00496673584,141.00496673584,141.00496673584,141.00496673584,141.00496673584,141.00496673584,141.00496673584,141.00496673584,141.00496673584,141.00496673584,141.00496673584,141.00496673584,108.467132568359,108.467132568359,108.467132568359,108.467132568359,108.467132568359,108.467132568359,108.467132568359,108.467132568359,108.467132568359,108.467132568359,108.467132568359,108.467132568359,112.381393432617,112.381393432617,112.381393432617,112.381393432617,112.381393432617,117.806022644043,117.806022644043,117.806022644043,117.806022644043,117.806022644043,117.806022644043,117.806022644043,117.806022644043,117.806022644043,117.806022644043,117.806022644043,117.806022644043,121.066276550293,121.066276550293,121.066276550293,121.066276550293,121.066276550293,124.029075622559,124.029075622559,124.029075622559,124.029075622559,124.029075622559,124.029075622559,124.029075622559,124.029075622559,124.029075622559,124.029075622559,124.029075622559,124.029075622559,124.029075622559,124.029075622559,127.388725280762,127.388725280762,127.388725280762,127.388725280762,127.388725280762,127.388725280762,127.388725280762,127.388725280762,127.388725280762,130.739967346191,130.739967346191,130.739967346191,130.739967346191,130.739967346191,130.739967346191,130.739967346191,133.246650695801,133.246650695801,133.246650695801,133.246650695801,133.246650695801,133.246650695801,133.246650695801,133.246650695801,133.246650695801,133.246650695801,133.246650695801,133.246650695801,133.246650695801,133.246650695801,136.575820922852,136.575820922852,136.575820922852,136.575820922852,136.575820922852,136.575820922852,140.933876037598,140.933876037598,140.933876037598,140.933876037598,140.933876037598,140.933876037598,140.933876037598,140.933876037598,140.933876037598,140.933876037598,140.933876037598,140.933876037598,140.933876037598,140.933876037598,140.933876037598,111.716659545898,111.716659545898,111.716659545898,111.716659545898,111.716659545898,111.716659545898,111.716659545898,111.842834472656,111.842834472656,111.842834472656,111.842834472656,111.842834472656,111.842834472656,111.842834472656,111.842834472656,111.842834472656,111.842834472656,111.842834472656,111.842834472656,111.842834472656,111.842834472656,112.033470153809,112.033470153809,112.033470153809,112.033470153809,112.033470153809,112.033470153809,112.033470153809,112.033470153809,112.033470153809,112.033470153809,112.033470153809,112.033470153809,112.033470153809,112.033470153809,112.176483154297,112.176483154297,112.176483154297,112.176483154297,112.176483154297,112.176483154297,112.176483154297,112.176483154297,112.176483154297,112.176483154297,112.176483154297,112.176483154297,112.176483154297,112.176483154297,112.32218170166,112.32218170166,112.32218170166,112.32218170166,112.32218170166,112.32218170166,112.32218170166,112.32218170166,112.32218170166,112.32218170166,112.32218170166,112.32218170166,112.423919677734,112.423919677734,112.423919677734,112.423919677734,112.423919677734,112.423919677734,112.423919677734,112.423919677734,112.423919677734,112.423919677734,112.423919677734,112.423919677734,112.423919677734,112.423919677734,112.423919677734,112.423919677734,112.613296508789,112.613296508789,112.613296508789,112.613296508789,112.613296508789,112.613296508789,112.613296508789,112.613296508789,112.613296508789,112.763984680176,112.763984680176,112.763984680176,112.763984680176,112.763984680176,112.763984680176,112.763984680176,112.763984680176,112.956443786621,112.956443786621,112.956443786621,112.956443786621,112.956443786621,112.956443786621,112.956443786621,112.956443786621,112.956443786621,112.956443786621,113.130310058594,113.130310058594,113.130310058594,113.130310058594,113.130310058594,113.130310058594,113.130310058594,109.807334899902,109.807334899902,109.807334899902,109.807334899902,109.807334899902,109.807334899902,109.807334899902,109.807334899902,109.807334899902,109.807334899902,109.807334899902,109.807334899902,109.807334899902,109.807334899902,109.807334899902,109.807334899902,109.949371337891,109.949371337891,109.949371337891,109.949371337891,109.949371337891,109.949371337891,109.949371337891,109.949371337891,109.949371337891,109.949371337891,109.949371337891,110.122863769531,110.122863769531,110.122863769531,110.122863769531,110.122863769531,110.122863769531,110.122863769531,110.122863769531,110.122863769531,110.122863769531,110.122863769531,110.122863769531,110.266799926758,110.266799926758,110.266799926758,110.266799926758,110.266799926758,110.266799926758,110.266799926758,110.37858581543,110.37858581543,110.37858581543,110.37858581543,110.37858581543,110.37858581543,110.37858581543,110.37858581543,110.37858581543,110.37858581543,110.37858581543,110.37858581543,110.37858581543,110.510673522949,110.510673522949,110.510673522949,110.510673522949,110.510673522949,110.510673522949,110.510673522949,110.726005554199,110.726005554199,110.726005554199,110.726005554199,110.726005554199,110.726005554199,110.726005554199,110.726005554199,110.88752746582,110.88752746582,110.88752746582,110.88752746582,110.88752746582,110.88752746582,110.88752746582,110.88752746582,110.88752746582,110.88752746582,110.88752746582,110.88752746582,110.88752746582,110.88752746582,110.88752746582,111.046691894531,111.046691894531,111.046691894531,111.046691894531,111.046691894531,111.046691894531,111.046691894531,111.046691894531,111.046691894531,111.046691894531,111.046691894531,111.046691894531,111.046691894531,111.046691894531,111.212646484375,111.212646484375,111.212646484375,111.212646484375,111.212646484375,111.212646484375,111.212646484375,111.212646484375,111.212646484375,111.212646484375,111.212646484375,111.212646484375,111.212646484375,111.212646484375,109.831642150879,109.831642150879,109.831642150879,109.831642150879,109.831642150879,109.831642150879,109.831642150879,109.831642150879,109.831642150879,109.831642150879,109.831642150879,109.831642150879,109.967681884766,109.967681884766,109.967681884766,109.967681884766,109.967681884766,109.967681884766,109.967681884766,109.967681884766,109.967681884766,109.967681884766,109.967681884766,110.118019104004,110.118019104004,110.118019104004,110.118019104004,110.118019104004,110.118019104004,110.118019104004,110.118019104004,110.118019104004,110.243469238281,110.243469238281,110.243469238281,110.243469238281,110.243469238281,110.243469238281,110.243469238281,110.243469238281,110.243469238281,110.243469238281,110.243469238281,110.243469238281,110.407508850098,110.407508850098,110.407508850098,110.407508850098,110.407508850098,110.407508850098,110.407508850098,110.593460083008,110.593460083008,110.593460083008,110.593460083008,110.593460083008,110.593460083008,110.593460083008,110.593460083008,110.593460083008,110.593460083008,110.768600463867,110.768600463867,110.768600463867,110.768600463867,110.768600463867,110.768600463867,110.768600463867,110.874855041504,110.874855041504,110.874855041504,110.874855041504,110.874855041504,110.874855041504,110.874855041504,110.874855041504,110.980911254883,110.980911254883,110.980911254883,110.980911254883,110.980911254883,110.980911254883,110.980911254883,110.980911254883,113.725898742676,113.725898742676,113.725898742676,113.725898742676,113.725898742676,113.725898742676,113.725898742676,113.725898742676,113.725898742676,113.725898742676,113.725898742676,113.725898742676,113.725898742676,113.725898742676,117.255783081055,117.255783081055,117.255783081055,117.255783081055,117.255783081055,117.255783081055,117.255783081055,117.255783081055,117.255783081055,117.255783081055,117.255783081055,117.255783081055,117.255783081055,117.255783081055,111.228569030762,111.228569030762,111.228569030762,111.228569030762,111.228569030762,111.228569030762,111.228569030762,111.228569030762,111.228569030762,111.228569030762,111.228569030762,111.228569030762,113.721069335938,113.721069335938,113.721069335938,113.721069335938,113.721069335938,113.721069335938,113.721069335938,113.721069335938,113.721069335938,113.721069335938,117.177345275879,117.177345275879,117.177345275879,117.177345275879,117.177345275879,117.177345275879,121.189903259277,121.189903259277,121.189903259277,121.189903259277,121.189903259277,121.189903259277,121.189903259277,121.189903259277,121.189903259277,121.189903259277,121.189903259277,121.189903259277,121.189903259277,121.189903259277,121.189903259277,124.43603515625,124.43603515625,124.43603515625,124.43603515625,124.43603515625,124.43603515625,127.789916992188,127.789916992188,127.789916992188,127.789916992188,127.789916992188,127.789916992188,127.789916992188,127.789916992188,127.789916992188,127.789916992188,130.580841064453,130.580841064453,130.580841064453,130.580841064453,130.580841064453,133.535614013672,133.535614013672,133.535614013672,133.535614013672,133.535614013672,133.535614013672,133.535614013672,133.535614013672,133.535614013672,133.535614013672,133.535614013672,133.535614013672,136.830474853516,136.830474853516,136.830474853516,136.830474853516,136.830474853516,136.830474853516,136.830474853516,136.830474853516,136.830474853516,136.830474853516,136.830474853516,136.830474853516,136.830474853516,141.005332946777,141.005332946777,141.005332946777,141.005332946777,141.005332946777,141.005332946777,141.005332946777,141.005332946777,141.005332946777,141.005332946777,141.005332946777,141.005332946777,141.005332946777,115.457870483398,115.457870483398,115.457870483398,115.457870483398,115.457870483398,115.457870483398,115.457870483398,115.457870483398,115.457870483398,115.457870483398,118.357315063477,118.357315063477,118.357315063477,118.357315063477,118.357315063477,118.357315063477,118.357315063477,118.357315063477,118.357315063477,118.357315063477,118.357315063477,118.357315063477,118.357315063477,118.357315063477,118.357315063477,118.357315063477,118.357315063477,118.357315063477,122.696723937988,122.696723937988,122.696723937988,122.696723937988,122.696723937988,122.696723937988,122.696723937988,122.696723937988,122.696723937988,122.696723937988,122.696723937988,122.696723937988,122.696723937988,125.618995666504,125.618995666504,125.618995666504,125.618995666504,125.618995666504,125.618995666504,125.618995666504,125.618995666504,125.618995666504,125.618995666504,125.618995666504,125.618995666504,125.618995666504,125.618995666504,125.618995666504,128.968765258789,128.968765258789,128.968765258789,128.968765258789,128.968765258789,128.968765258789,128.968765258789,128.968765258789,128.968765258789,128.968765258789,128.968765258789,128.968765258789,128.968765258789,128.968765258789,128.968765258789,128.968765258789,128.968765258789,132.276245117188,132.276245117188,132.276245117188,132.276245117188,132.276245117188,135.632766723633,135.632766723633,135.632766723633,135.632766723633,135.632766723633,135.632766723633,135.632766723633,135.632766723633,135.632766723633,135.632766723633,135.632766723633,135.632766723633,135.632766723633,135.632766723633,135.632766723633,139.702941894531,139.702941894531,139.702941894531,139.702941894531,139.702941894531,139.702941894531,139.702941894531,139.702941894531,139.702941894531,139.702941894531,139.702941894531,141.00269317627,141.00269317627,141.00269317627,141.00269317627,141.00269317627,141.00269317627,141.00269317627,141.00269317627,141.00269317627,141.00269317627,141.00269317627,141.00269317627,141.00269317627,109.660583496094,109.660583496094,109.660583496094,109.660583496094,109.660583496094,109.660583496094,109.660583496094,109.660583496094,109.660583496094,109.660583496094,109.660583496094,109.660583496094,109.660583496094,101.365882873535,101.365882873535,101.365882873535,101.365882873535,101.365882873535,101.365882873535,101.365882873535,101.365882873535,101.365882873535,101.365882873535,101.365882873535,101.365882873535,101.365882873535,101.365882873535,101.365882873535,104.600379943848,104.600379943848,104.600379943848,104.600379943848,104.600379943848,104.600379943848,104.600379943848,104.600379943848,104.600379943848,104.600379943848,104.600379943848,104.600379943848,104.600379943848,108.067207336426,108.067207336426,108.067207336426,108.067207336426,108.067207336426,110.30029296875,110.30029296875,110.30029296875,110.30029296875,110.30029296875,110.30029296875,110.30029296875,110.30029296875,110.30029296875,110.30029296875,110.30029296875,110.30029296875,110.30029296875,110.30029296875,113.654800415039,113.654800415039,113.654800415039,113.654800415039,113.654800415039,113.654800415039,113.654800415039,113.654800415039,113.654800415039,113.654800415039,113.654800415039,113.654800415039,117.085098266602,117.085098266602,117.085098266602,117.085098266602,117.085098266602,117.085098266602,117.085098266602,117.085098266602,117.085098266602,117.085098266602,117.085098266602,117.085098266602,120.336715698242,120.336715698242,120.336715698242,120.336715698242,120.336715698242,124.307914733887,124.307914733887,124.307914733887,124.307914733887,124.307914733887,124.307914733887,124.307914733887,124.307914733887,124.307914733887,124.307914733887,124.307914733887,124.307914733887,129.791687011719,129.791687011719,129.791687011719,129.791687011719,129.791687011719,129.791687011719,129.791687011719,129.791687011719,129.791687011719,133.302200317383,133.302200317383,133.302200317383,133.302200317383,133.302200317383,133.302200317383,133.302200317383,133.302200317383,133.302200317383,133.302200317383,133.302200317383,133.302200317383,136.33765411377,136.33765411377,136.33765411377,136.33765411377,136.33765411377,136.33765411377,136.33765411377,136.33765411377,136.33765411377,136.33765411377,136.33765411377,138.715087890625,138.715087890625,138.715087890625,138.715087890625,138.715087890625,138.715087890625,138.715087890625,138.715087890625,138.715087890625,138.715087890625,138.715087890625,141.007713317871,141.007713317871,141.007713317871,141.007713317871,141.007713317871,141.007713317871,106.033218383789,106.033218383789,106.033218383789,106.033218383789,106.033218383789,106.033218383789,106.033218383789,106.033218383789,106.033218383789,106.033218383789,106.033218383789,106.033218383789,109.403106689453,109.403106689453,109.403106689453,109.403106689453,109.403106689453,109.403106689453,109.403106689453,109.403106689453,109.403106689453,109.403106689453,109.403106689453,109.403106689453,109.403106689453,109.403106689453,111.483100891113,111.483100891113,111.483100891113,111.483100891113,111.483100891113,111.483100891113,111.483100891113,113.680442810059,113.680442810059,113.680442810059,113.680442810059,113.680442810059,113.680442810059,113.680442810059,113.680442810059,113.680442810059,113.680442810059,113.680442810059,113.680442810059,116.58943939209,116.58943939209,116.58943939209,116.58943939209,116.58943939209,116.58943939209,116.58943939209,116.58943939209,116.58943939209,116.58943939209,116.58943939209,120.953201293945,120.953201293945,120.953201293945,120.953201293945,120.953201293945,120.953201293945,120.953201293945,120.953201293945,120.953201293945,120.953201293945,120.953201293945,123.25309753418,123.25309753418,123.25309753418,123.25309753418,123.25309753418,123.25309753418,123.25309753418,123.25309753418,123.25309753418,123.25309753418,123.25309753418,123.25309753418,125.424858093262,125.424858093262,125.424858093262,125.424858093262,125.424858093262,125.424858093262,125.424858093262,125.424858093262,125.424858093262,125.424858093262,125.424858093262,128.656242370605,128.656242370605,128.656242370605,128.656242370605,128.656242370605,128.656242370605,128.656242370605,128.656242370605,128.656242370605,128.656242370605,131.631202697754,131.631202697754,134.983337402344,134.983337402344,134.983337402344,134.983337402344,134.983337402344,134.983337402344,134.983337402344,134.983337402344,137.772453308105,137.772453308105,137.772453308105,137.772453308105,137.772453308105,137.772453308105,137.772453308105,137.772453308105,137.772453308105,137.772453308105,137.772453308105,137.772453308105,137.772453308105,140.402435302734,140.402435302734,140.402435302734,140.402435302734,140.402435302734,140.402435302734,140.402435302734,140.402435302734,140.402435302734,140.402435302734,107.784057617188,107.784057617188,107.784057617188,107.784057617188,107.784057617188,107.784057617188,107.784057617188,107.784057617188,107.784057617188,107.784057617188,107.784057617188,107.784057617188,107.784057617188,110.90030670166,110.90030670166,110.90030670166,110.90030670166,110.90030670166,110.90030670166,110.90030670166,110.90030670166,110.90030670166,110.90030670166,110.90030670166,110.90030670166,110.90030670166,110.90030670166,110.90030670166,114.088111877441,114.088111877441,114.088111877441,114.088111877441,114.088111877441,114.088111877441,114.088111877441,114.088111877441,114.088111877441,114.088111877441,114.088111877441,114.088111877441,114.088111877441,116.423652648926,116.423652648926,116.423652648926,116.423652648926,116.423652648926,116.423652648926,119.19416809082,119.19416809082,119.19416809082,119.19416809082,119.19416809082,119.19416809082,119.19416809082,119.19416809082,119.19416809082,119.19416809082,119.19416809082,119.19416809082,119.19416809082,119.19416809082,122.570091247559,122.570091247559,122.570091247559,122.570091247559,122.570091247559,122.570091247559,122.570091247559,122.570091247559,122.570091247559,125.985290527344,125.985290527344,125.985290527344,125.985290527344,125.985290527344,125.985290527344,125.985290527344,125.985290527344,125.985290527344,128.204925537109,128.204925537109,128.204925537109,128.204925537109,128.204925537109,128.204925537109,128.204925537109,130.947685241699,130.947685241699,130.947685241699,130.947685241699,130.947685241699,130.947685241699,130.947685241699,133.766372680664,133.766372680664,133.766372680664,133.766372680664,133.766372680664,133.766372680664,133.766372680664,137.189094543457,137.189094543457,137.189094543457,137.189094543457,137.189094543457,137.189094543457,137.189094543457,137.189094543457,137.189094543457,137.189094543457,137.189094543457,137.189094543457,137.189094543457,137.189094543457,139.285522460938,139.285522460938,139.285522460938,139.285522460938,139.285522460938,139.285522460938,139.285522460938,139.285522460938,139.285522460938,139.285522460938,139.285522460938,139.285522460938,139.285522460938,141.007171630859,141.007171630859,141.007171630859,141.007171630859,141.007171630859,141.007171630859,141.007171630859,141.007171630859,112.041664123535,112.041664123535,112.041664123535,112.041664123535,112.041664123535,112.041664123535,112.041664123535,112.041664123535,112.041664123535,112.041664123535,112.041664123535,112.041664123535,112.041664123535,112.041664123535,112.041664123535,112.041664123535,115.275291442871,115.275291442871,115.275291442871,115.275291442871,115.275291442871,115.275291442871,115.275291442871,115.275291442871,118.078773498535,118.078773498535,118.078773498535,118.078773498535,118.078773498535,118.078773498535,120.295188903809,120.295188903809,120.295188903809,120.295188903809,120.295188903809,120.295188903809,120.295188903809,120.295188903809,120.295188903809,120.295188903809,120.295188903809,120.295188903809,120.295188903809,122.917823791504,122.917823791504,122.917823791504,122.917823791504,122.917823791504,122.917823791504,122.917823791504,122.917823791504,122.917823791504,122.917823791504,122.917823791504,125.992118835449,125.992118835449,125.992118835449,125.992118835449,125.992118835449,125.992118835449,125.992118835449,125.992118835449,125.992118835449,125.992118835449,125.992118835449,125.992118835449,125.992118835449,125.992118835449,129.860015869141,129.860015869141,129.860015869141,129.860015869141,129.860015869141,132.14884185791,132.14884185791,132.14884185791,132.14884185791,132.14884185791,132.14884185791,132.14884185791,132.14884185791,132.14884185791,132.14884185791,132.14884185791,134.278602600098,134.278602600098,134.278602600098,134.278602600098,134.278602600098,134.278602600098,134.278602600098,134.278602600098,134.278602600098,137.736305236816,137.736305236816,137.736305236816,137.736305236816,137.736305236816,137.736305236816,137.736305236816,137.736305236816,137.736305236816,137.736305236816,137.736305236816,137.736305236816,140.756378173828,140.756378173828,140.756378173828,140.756378173828,140.756378173828,140.756378173828,140.756378173828,140.756378173828,140.756378173828,140.756378173828,140.756378173828,140.756378173828,140.756378173828,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,141.007736206055,112.569885253906,112.569885253906,112.569885253906,112.569885253906,112.569885253906,112.569885253906,93.5246276855469,93.5246276855469,93.5246276855469,93.5246276855469,93.5246276855469,93.5246276855469,77.2169647216797,77.2169647216797,77.2169647216797,77.2169647216797,77.2169647216797,77.2169647216797,77.2169647216797,77.2169647216797,77.2169647216797,77.2169647216797,77.2169647216797,77.2169647216797,77.2169647216797,77.2169647216797,77.2169647216797,77.2169647216797,77.2169647216797,77.2169647216797,78.3107757568359,78.3107757568359,78.3107757568359,78.3107757568359,78.3107757568359,78.3107757568359,78.3107757568359,78.3107757568359,78.3107757568359,78.3107757568359,78.3107757568359,78.3107757568359,80.8397674560547,80.8397674560547,80.8397674560547,80.8397674560547,80.8397674560547,80.8397674560547,80.8397674560547,80.8397674560547,80.8397674560547,80.8397674560547,80.8397674560547,80.8397674560547,80.8397674560547,83.3124008178711,83.3124008178711,83.3124008178711,83.3124008178711,83.3124008178711,83.3124008178711,83.3124008178711,83.3124008178711,83.3124008178711,83.3124008178711,83.3124008178711,83.3124008178711,83.3124008178711,85.6495208740234,85.6495208740234,85.6495208740234,85.6495208740234,85.6495208740234,85.6495208740234,85.6495208740234,85.7522354125977,85.7522354125977,85.7522354125977,85.7522354125977,85.7522354125977,85.7522354125977,85.7522354125977,85.7522354125977,85.7522354125977,85.8355560302734,85.8355560302734,85.8355560302734,85.8355560302734,85.8355560302734,85.8355560302734,85.8355560302734,85.8355560302734,85.8355560302734,85.8355560302734,85.8355560302734,85.8355560302734,85.9841995239258,85.9841995239258,85.9841995239258,85.9841995239258,85.9841995239258,85.9841995239258,85.9841995239258,85.9841995239258,85.9841995239258,85.9841995239258,85.9841995239258,86.1942596435547,86.1942596435547,86.1942596435547,86.1942596435547,86.1942596435547,86.1942596435547,86.1942596435547,86.1942596435547,86.1942596435547,86.1942596435547,86.1942596435547,86.1942596435547,86.1942596435547,86.3098449707031,86.3098449707031,86.3098449707031,86.3098449707031,86.3098449707031,86.3098449707031,86.3098449707031,86.3098449707031,86.3098449707031,86.3098449707031,86.3098449707031,86.4024276733398,86.4024276733398,86.4024276733398,86.4024276733398,86.4024276733398,86.4024276733398,86.4024276733398,86.4024276733398,86.4024276733398,86.4024276733398,86.4806365966797,86.4806365966797,86.4806365966797,86.4806365966797,86.4806365966797,86.4806365966797,86.4806365966797,86.4806365966797,86.4806365966797,86.4806365966797,86.5520095825195,86.5520095825195,86.5520095825195,86.5520095825195,86.5520095825195,86.5520095825195,86.5520095825195,86.5520095825195,86.5520095825195,86.5520095825195,86.5520095825195,86.67138671875,86.67138671875,86.67138671875,86.67138671875,86.67138671875,86.67138671875,86.67138671875,86.67138671875,86.67138671875,86.67138671875,86.67138671875,86.7473297119141,86.7473297119141,86.7473297119141,86.7473297119141,86.7473297119141,86.7473297119141,86.7473297119141,86.7473297119141,86.7473297119141,86.7473297119141,86.7473297119141,86.8444290161133,86.8444290161133,86.8444290161133,86.8444290161133,86.8444290161133,86.8444290161133,86.8444290161133,86.8444290161133,86.8444290161133,86.8444290161133,86.9273681640625,86.9273681640625,86.9273681640625,86.9273681640625,86.9273681640625,86.9273681640625,86.9273681640625,86.9273681640625,86.9273681640625,86.9273681640625,86.9273681640625,87.011360168457,87.011360168457,87.011360168457,87.011360168457,87.011360168457,87.011360168457,87.011360168457,87.011360168457,87.011360168457,87.0874481201172,87.0874481201172,87.0874481201172,87.0874481201172,87.0874481201172,87.0874481201172,87.0874481201172,87.0874481201172,87.0874481201172,87.0874481201172,87.0874481201172,78.0848388671875,78.0848388671875,78.0848388671875,78.0848388671875,78.0848388671875,78.0848388671875,78.0848388671875,78.0848388671875,78.0848388671875,78.0848388671875,78.0848388671875,78.0848388671875,78.0848388671875,78.2230911254883,78.2230911254883,78.2230911254883,78.2230911254883,78.2230911254883,78.2230911254883,78.2230911254883,78.2230911254883,78.2230911254883,78.3191299438477,78.3191299438477,78.3191299438477,78.3191299438477,78.3191299438477,78.3191299438477,78.3191299438477,78.3191299438477,78.3191299438477,78.3191299438477,78.3191299438477,78.3191299438477,78.3191299438477,78.3191299438477,78.3191299438477,78.3191299438477,78.3928985595703,78.3928985595703,78.3928985595703,78.3928985595703,78.3928985595703,78.3928985595703,78.3928985595703,78.3928985595703,78.3928985595703,78.5014114379883,78.5014114379883,78.5014114379883,78.5014114379883,78.5014114379883,78.5014114379883,78.5014114379883,78.5014114379883,78.5014114379883,78.57958984375,78.57958984375,78.57958984375,78.57958984375,78.57958984375,78.57958984375,78.57958984375,78.57958984375,78.57958984375,78.57958984375,78.57958984375,78.57958984375,78.57958984375,78.57958984375,78.57958984375,78.6942138671875,78.6942138671875,78.6942138671875,78.6942138671875,78.6942138671875,78.6942138671875,78.6942138671875,78.6942138671875,78.7655181884766,78.7655181884766,78.7655181884766,78.7655181884766,78.7655181884766,78.7655181884766,78.7655181884766,78.7655181884766,78.7655181884766,78.7655181884766,78.7655181884766,78.8340530395508,78.8340530395508,78.8340530395508,78.8340530395508,78.8340530395508,78.8340530395508,78.8340530395508,78.8340530395508,78.8340530395508,78.8340530395508,78.8340530395508,78.8340530395508,78.9459762573242,78.9459762573242,78.9459762573242,78.9459762573242,78.9459762573242,78.9459762573242,78.9459762573242,78.9459762573242,78.9459762573242,79.0106887817383,79.0106887817383,79.0106887817383,79.0106887817383,79.0106887817383,79.0106887817383,79.0106887817383,79.0106887817383,79.0106887817383,79.096923828125,79.096923828125,79.096923828125,79.096923828125,79.096923828125,79.096923828125,79.096923828125,79.096923828125,79.096923828125,79.096923828125,79.096923828125,79.096923828125,79.1748504638672,79.1748504638672,79.1748504638672,79.1748504638672,79.1748504638672,79.1748504638672,79.1748504638672,79.1748504638672,79.1748504638672,79.1748504638672,79.1748504638672,79.257438659668,79.257438659668,79.257438659668,79.257438659668,79.257438659668,79.257438659668,79.257438659668,79.3959274291992,79.3959274291992,79.3959274291992,79.3959274291992,79.3959274291992,79.3959274291992,79.3959274291992,79.3959274291992,79.3959274291992,79.3959274291992,79.3959274291992,79.4652938842773,79.4652938842773,79.4652938842773,79.4652938842773,79.4652938842773,79.4652938842773,79.4652938842773,79.4652938842773,79.4652938842773,79.4652938842773,79.5392227172852,79.5392227172852,79.5392227172852,79.5392227172852,79.5392227172852,79.5392227172852,79.5392227172852,79.5392227172852,79.6236190795898,79.6236190795898,79.6236190795898,79.6236190795898,79.6236190795898,79.6236190795898,79.6236190795898,79.6236190795898,79.6236190795898,79.6236190795898,79.6236190795898,79.6948547363281,79.6948547363281,79.6948547363281,79.6948547363281,79.6948547363281,79.6948547363281,79.6948547363281,79.6948547363281,79.6948547363281,79.7704544067383,79.7704544067383,79.7704544067383,79.7704544067383,79.7704544067383,79.7704544067383,79.7704544067383,78.0826644897461,78.0826644897461,78.0826644897461,78.0826644897461,78.0826644897461,78.0826644897461,78.0826644897461,78.0826644897461,78.0826644897461,78.0826644897461,78.1813507080078,78.1813507080078,78.1813507080078,78.1813507080078,78.1813507080078,78.1813507080078,78.1813507080078,78.1813507080078,78.1813507080078,78.1813507080078,78.1813507080078,78.1813507080078,78.1813507080078,78.2607116699219,78.2607116699219,78.2607116699219,78.2607116699219,78.2607116699219,78.2607116699219,78.2607116699219,78.2607116699219,78.2607116699219,78.2607116699219,78.2607116699219,78.2607116699219,78.2607116699219,78.2607116699219,78.2607116699219,78.2607116699219,78.2607116699219,78.3357849121094,78.3357849121094,78.3357849121094,78.3357849121094,78.3357849121094,78.3357849121094,78.3357849121094,78.3357849121094,78.3357849121094,78.4174041748047,78.4174041748047,78.4174041748047,78.4174041748047,78.4174041748047,78.4174041748047,78.4174041748047,78.4174041748047,78.4174041748047,78.4174041748047,78.4174041748047,78.4174041748047,78.4174041748047,78.4174041748047,78.4174041748047,78.5178833007812,78.5178833007812,78.5178833007812,78.5178833007812,78.5178833007812,78.5178833007812,78.5178833007812,78.5178833007812,78.5178833007812,78.5178833007812,78.5178833007812,78.6305084228516,78.6305084228516,78.6305084228516,78.6305084228516,78.6305084228516,78.6305084228516,78.6305084228516,78.6305084228516,78.6305084228516,78.7471084594727,78.7471084594727,78.7471084594727,78.7471084594727,78.7471084594727,78.7471084594727,78.7471084594727,78.7471084594727,78.7471084594727,78.7471084594727,78.7471084594727,78.7471084594727,78.7471084594727,78.8179931640625,78.8179931640625,78.8179931640625,78.8179931640625,78.8179931640625,78.8179931640625,78.8179931640625,78.8179931640625,78.8179931640625,78.8179931640625,78.8179931640625,78.8179931640625,78.8179931640625,78.8179931640625,78.8179931640625,78.8924026489258,78.8924026489258,78.8924026489258,78.8924026489258,78.8924026489258,78.8924026489258,78.8924026489258,78.8924026489258,78.8924026489258,78.8924026489258,78.8924026489258,78.8924026489258,78.8924026489258,79.0035018920898,79.0035018920898,79.0035018920898,79.0035018920898,79.0035018920898,79.0035018920898,79.0035018920898,79.0035018920898,79.0035018920898,79.0035018920898,79.0035018920898,79.0035018920898,79.0035018920898],"meminc":[0,0,0,0,0,0,0,0,0,0,0,0,1.21694946289062,0,0,0,0,0,0,0,0,0,0,0.951820373535156,0,0,0,0,0,0,0,0,0,0,0,0,1.42919158935547,0,0,0,0,0,0,0,0,0,0,0,0,0,1.36549377441406,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1.80647277832031,0,0,0,0,0,0,0,0,0,0,1.07608795166016,0,0,0,0,0,0,0,0,0,0,0,0,1.74291229248047,0,0,0,0,1.80966186523438,0,0,0,0,1.87399291992188,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1.73048400878906,0,0,0,0,0,0,0,0,0,0,2.02996826171875,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1.68473815917969,0,0,0,0,0,0,0,0,0,0,0,2.156005859375,0,0,0,0,0,0,0,0,0,0,0,1.92147064208984,0,0,0,0,0,0,1.80805206298828,0,0,0,0,-21.0350875854492,0,0,0,0,0,0,0,0,0,0,0,1.97395324707031,0,0,0,0,0,0,2.05366516113281,0,0,0,0,0,0,0,0,0,0,0,2.06957244873047,0,0,0,0,0,0,0,0,0,0,2.14920043945312,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3.70170593261719,0,0,0,0,0,0,0,0,0,0,0,2.04983520507812,0,0,0,0,0,0,0,0,0,0,0,0,2.09814453125,0,0,0,0,0,0,0,0,0,0,2.70628356933594,0,0,0,0,0,0,0,2.49034118652344,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1.90233612060547,0,0,0,0,0,2.48531341552734,0,0,0,0,0,0,0,-22.4787826538086,0,0,0,0,0,0,0,0,0,0,0,0,2.23317718505859,0,0,0,0,0,0,0,0,2.07096099853516,0,0,0,0,0,0,0,2.36270141601562,0,0,0,0,0,0,3.07358551025391,0,0,0,0,0,0,2.30399322509766,0,0,0,0,0,0,0,0,0,0,0,2.15963745117188,0,0,0,0,0,0,0,0,0,0,0,0,3.47823333740234,0,0,0,0,0,0,0,2.29986572265625,0,0,0,0,0,0,0,0,0,0,0,2.23677825927734,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3.22409057617188,0,0,0,0,0,0,0,0,0,0,-21.0012512207031,0,0,0,0,0,0,0,0,2.50765228271484,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2.55284118652344,0,0,0,0,0,0,0,0,0,0,2.0147705078125,0,0,0,0,0,0,0,0,0,0,0,2.46332550048828,0,0,0,0,0,0,2.32634735107422,0,0,0,0,0,0,2.09278106689453,0,0,0,0,0,0,0,2.711669921875,0,0,0,0,0,0,0,0,0,0,0,0,2.24123382568359,0,0,0,0,0,0,0,0,0,0,1.56708526611328,0,0,0,0,0,0,0,0,0,0,0,0.1458740234375,0,0,0,0,0,0,-19.9328002929688,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.163589477539062,0,0,0,0,0,0,0,0,0.153579711914062,0,0,0,0,0,0,0,0,0,0,0.190879821777344,0,0,0,0,0,0,0,0,0,0,0,0,0.170677185058594,0,0,0,0,0,0,0,0,0,0,0,0.164199829101562,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.173019409179688,0,0,0,0,0,0,0,0,0,0,0.161689758300781,0,0,0,0,0,0,0,0,0,0,0,0,0.159866333007812,0,0,0,0,0,0,0,0,0,0,0,0,-1.44234466552734,0,0,0,0,0,0,0,0.163192749023438,0,0,0,0,0,0,0,0,0.169319152832031,0,0,0,0,0,0.161544799804688,0,0,0,0,0,0,0,0.19451904296875,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.159576416015625,0,0,0,0,0.209320068359375,0,0,0,0,0,0,0.203392028808594,0,0,0,0,0,0,0,0,0,0,0.187339782714844,0,0,0,0,0,0,-1.44340515136719,0,0,0,0,0,0,0.15924072265625,0,0,0,0,0,0,0,0,0,0.160385131835938,0,0,0,0,0,0,0,0,0,0,2.97373962402344,0,0,0,0,0,0,0,0,0,0,0,0,2.65562438964844,0,0,0,0,0,0,0,0,0,2.22898101806641,0,0,0,0,0,0,0,0,0,0,0,2.28907775878906,0,0,0,0,0,0,0,0,0,0,0,3.49828338623047,0,0,0,0,0,0,0,0,0,0,0,2.98877716064453,0,0,0,0,0,0,0,0,0,0,2.6365966796875,0,0,0,0,0,0,0,0,0,0,0,0,3.00897216796875,0,0,0,0,0,0,0,0,0,0,0,0,2.59535980224609,0,0,0,0,0,0,0,0,0,0,0,0,-20.0254211425781,0,0,0,0,0,0,0,0,0,2.76718902587891,0,0,0,0,0,0,0,0,0,0,0,0,2.28091430664062,0,0,0,0,2.04193878173828,0,0,0,0,0,0,0,0,0,0,0,0,1.87960815429688,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2.052734375,0,0,0,0,0,0,1.31914520263672,0,0,0,0,0,0,0,0,0,0,0,0,1.65441131591797,0,0,0,0,2.05898284912109,0,0,0,0,0,0,0,0,0,0,0,2.16146850585938,0,0,0,0,0,0,0,0,0,0,0,1.84047698974609,0,0,0,0,0,0,0,0,0,0,0,2.62107086181641,0,0,0,0,0,0,0,0,0,0,0,0,2.33358764648438,0,0,0,0,0,1.44680786132812,0,0,0,0,0,0,0,0,0,0,0,1.57192993164062,0,0,0,0,0,0,1.92308807373047,0,0,0,0,0,0,0,0,0,0,0,0,0,-26.7926330566406,0,0,0,0,0,0,0,0,0,0,0,0,1.84156799316406,0,0,0,0,0,0,0,0,0,0,2.24954223632812,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2.67997741699219,0,0,0,0,0,0,2.40736389160156,0,0,0,0,0,0,0,0,2.2645263671875,0,0,0,0,2.36392211914062,0,3.62499237060547,0,0,0,0,0,0,0,2.27346038818359,0,0,0,0,0,0,0,0,0,0,2.77283477783203,0,0,0,0,0,0,0,0,2.09371948242188,0,0,0,0,0,0,0,0,0,0,0,0,0,1.52712249755859,0,0,0,0,0,1.71482086181641,0,0,0,0,0,0,0,1.30391693115234,0,0,0,0,0,0,-27.3209533691406,0,0,0,0,0,0,0,0,0,0,0,1.51621246337891,0,0,0,0,0,0,0,0,0,0,0,2.29994201660156,0,0,0,0,0,0,0,0,0,0,0,2.59790802001953,0,0,0,0,0,0,2.69789123535156,0,0,0,0,2.88887023925781,0,0,0,0,0,0,0,0,0,0,0,0,2.72260284423828,0,0,0,0,4.39151000976562,0,0,0,0,0,0,0,0,2.84860992431641,0,0,0,0,0,0,0,0,0,0,2.48871612548828,0,0,0,2.62066650390625,0,0,0,0,0,2.65721893310547,0,0,0,0,0,0,0,0,0,0,-25.8750076293945,0,0,0,0,0,2.68463134765625,0,0,0,0,0,0,2.65424346923828,0,0,0,0,0,2.66799163818359,0,0,0,0,0,0,1.75497436523438,0,0,0,0,0,0,0,0,0.188400268554688,0,0,0,0,0,0,0,0,0,0,0,0.154655456542969,0,0,0,0,0,0,0,0.168342590332031,0,0,0,0,0,0.207984924316406,0,0,0,0,0,0,0,0,0.153526306152344,0,0,0,0,0,0,0,0.0943527221679688,0,0,0,0,0,-22.4584274291992,0,0,0,0,0,0.0594558715820312,0,0,0,0,0,0,0,0,0,0,0.168121337890625,0,0,0,0,0,0,0,0,0,0.192024230957031,0,0,0,0,0,0,0,0,0,0,0,0,0.144050598144531,0,0,0,0,0,0.154228210449219,0,0,0,0,0,0,0,0.157676696777344,0,0,0,0,0,0,0,0,0,0,0,0.240036010742188,0,0,0,0,0,0,0,0,0,0,0,0.136138916015625,0,0,0,0,0,0,0,0,0,0.170455932617188,0,0,0,0,0,0,0,0,0,0.151687622070312,0,0,0,0,0,0,0,0,-1.51576232910156,0,0,0,0,0,0,0,0.199005126953125,0,0,0,0,0,0,0,0,0.185859680175781,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.186264038085938,0,0,0,0,0,0,0,0,0,0,0,0,0,0.191658020019531,0,0,0,0,0,0.179550170898438,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.172317504882812,0,0,0,0,0,0,0,0,0,0,0,0,0,2.15422821044922,0,0,0,0,0,0,0,0,0,0,0,0,2.65682983398438,0,0,0,0,0,0,0,0,0,0,0,2.56003570556641,0,0,0,0,0,0,0,0,0,0,0,-7.48562622070312,0,0,0,0,0,0,0,0,0,0,0,2.83332824707031,0,0,0,0,0,0,0,0,0,0,0,3.04695129394531,0,0,0,0,0,0,0,0,0,0,0,0,2.85498046875,0,0,0,0,0,0,0,0,0,0,0,2.90306854248047,0,0,0,0,0,0,0,0,3.63573455810547,0,0,0,0,0,2.85960388183594,0,0,0,0,0,3.71605682373047,0,0,0,0,0,0,0,0,0,0,3.58615112304688,0,0,0,0,0,0,0,0,0,3.13009643554688,0,0,0,0,0,0,0,0,0,0,0,2.95888519287109,0,0,0,0,0,0,0,0,0,0,0,0,2.94217681884766,0,0,0,0,0,3.08486175537109,0,0,0,0,0,0,0,0,0,0,2.27876281738281,0,0,0,0,0,0,0,0,0,0,0,0,-33.5386581420898,0,0,0,0,0,0,0,0,0,0,0,3.06875610351562,0,0,0,0,0,0,0,0,0,0,0,0,0,3.25334930419922,0,0,0,0,0,0,0,0,0,2.52988433837891,0,0,0,0,0,0,0,0,0,0,2.51303863525391,0,0,0,0,0,0,2.90338134765625,0,0,0,0,0,0,0,0,0,0,3.72753143310547,0,0,0,0,0,0,0,0,0,0,0,0,2.84716796875,0,0,0,0,0,0,0,0,0,0,0,3.12142944335938,0,0,0,0,0,0,0,4.18947601318359,0,0,0,0,0,0,0,0,0,0,0,0,2.86129760742188,0,0,0,0,0,0,0,0,0,0,0,3.56945037841797,0,0,0,0,0,0,2.51302337646484,0,0,0,0,0,0,0,0,-33.5999450683594,0,0,0,0,0,0,0,0,0,0,0,2.85917663574219,0,0,0,0,0,0,0,0,0,0,0,3.54237365722656,0,0,0,0,0,0,0,0,0,0,0,0,2.13467407226562,0,0,0,0,0,0,0,0,0,0,0,0,0,3.19398498535156,0,0,0,0,0,3.24852752685547,0,0,0,0,0,0,0,0,0,0,0,3.42624664306641,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3.15660858154297,0,0,0,0,3.90151977539062,0,0,0,0,0,0,0,0,0,0,3.12869262695312,0,0,0,0,0,0,0,0,0,0,0,0,0,3.01015472412109,0,0,0,0,0,0,0,0,0,0,3.00167083740234,0,0,0,0,0,0,2.52466583251953,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-31.7326354980469,0,0,0,0,0,0,0,0,0,0,0,0,3.71576690673828,0,0,0,0,0,0,0,0,0,0,0,0,0,2.99125671386719,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3.038818359375,0,0,0,0,0,0,0,0,0,0,3.29351806640625,0,0,0,0,0,0,0,0,0,0,0,0,3.37592315673828,0,0,0,0,0,2.84862518310547,0,0,0,0,0,0,0,0,3.28145599365234,0,0,0,0,0,0,0,0,0,0,0,3.35960388183594,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3.02595520019531,0,0,0,0,0,0,0,0,0,0,0,1.11100769042969,0,0,0,0,0,0.130020141601562,0,0,0,0,0,0,0,0,-29.260124206543,0,0,0,0,0,0,0,0,0,0,0.180877685546875,0,0,0,0.157798767089844,0,0,0,0,0,0,0,0,0,0,0,0.146934509277344,0,0,0,0,0,0,0,0,0,0.187156677246094,0,0,0,0,0,0,0,0,0,0.216163635253906,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.169082641601562,0,0,0,0,0,0.140174865722656,0,0,0,0,0,0,0,0,0,0,-1.33719635009766,0,0,0,0,0,0,0,0,0,0.154586791992188,0,0,0,0,0,0,0,0,0,0,0,0,0.168998718261719,0,0,0,0,0,0,0,0.165634155273438,0,0,0,0,0,0,0.1697998046875,0,0,0,0,0,0,0,0,0,0,0.198501586914062,0,0,0,0,0,0,0,0,0,0,0,0,0.173698425292969,0,0,0,0,0,0,0,0,0,0,0,0,0.191551208496094,0,0,0,0,0,0,0,0.149650573730469,0,0,0,0,0,0,0,0,0,0,0,0,0.144081115722656,0,0,0,0,0,0,0,0,0,-1.37277221679688,0,0,0,0,0,0,0,0.197746276855469,0,0,0,0,0,0,0.160736083984375,0,0,0,0,0,0,0,0,1.41539764404297,0,0,0,0,0,0,0,0,0,0,2.996337890625,0,0,0,0,0,0,0,0,0,0,0,3.23535919189453,0,0,0,0,0,0,0,0,0,0,4.42684173583984,0,0,0,0,0,0,0,0,0,0,0,0,0,3.47408294677734,0,0,0,0,0,0,0,0,0,0,3.223876953125,0,0,0,0,0,0,0,0,0,0,3.12077331542969,0,0,0,0,0,0,0,0,0,3.7955322265625,0,0,0,0,0,0,0,0,0,0,0,0,-21.6173706054688,0,0,0,0,0,0,0,0,0,0,0,3.4912109375,0,0,0,0,0,0,0,0,0,0,0,0,0,3.46073913574219,0,0,0,0,0,0,0,0,0,0,0,0,4.08464050292969,0,0,0,0,2.86795043945312,0,0,0,0,0,0,0,0,4.20279693603516,0,0,0,0,0,0,0,0,0,0,3.99015045166016,0,0,0,0,0,0,0,0,0,0,0,0,3.42631530761719,0,0,0,0,0,3.78199768066406,0,0,0,0,0,0,0,0,0,0,0,0,3.91807556152344,0,0,0,0,0,0,0,0,0,0,0,0,2.51907348632812,0,0,0,0,0,0,0,0,0,0,0,0,0,3.58621978759766,0,0,0,0,0,0,0,0,0,0,0,0,-27.7034225463867,0,0,0,0,0,0,0,0,0,-5.74484252929688,0,0,0,0,3.80030059814453,0,0,0,0,0,0,0,0,0,3.77523803710938,0,0,0,0,0,0,0,0,3.63987731933594,0,0,0,0,0,0,0,0,0,0,0,3.70968627929688,0,0,0,0,0,0,0,0,2.9129638671875,0,0,0,0,3.87081146240234,0,0,0,0,0,0,0,0,0,3.04988098144531,0,0,0,0,0,0,0,0,0,0,0,0,4.19348907470703,0,0,0,0,0,0,0,0,3.3856201171875,0,0,0,0,0,0,0,0,0,3.20492553710938,0,0,0,0,0,0,0,0,0,0,0,0,3.13867950439453,0,0,0,0,-36.7527160644531,0,0,0,0,0,0,0,0,3.73775482177734,0,0,0,0,0,0,0,0,0,0,3.03746032714844,0,0,0,0,0,0,0,0,0,0,0,3.38158416748047,0,0,0,0,0,0,0,0,0,0,3.38819885253906,0,0,0,0,2.94343566894531,0,0,0,0,0,0,0,0,0,0,3.12535095214844,0,0,0,0,0,0,0,0,0,0,0,4.32257843017578,0,0,0,0,0,0,0,0,0,0,0,4.06160736083984,0,0,0,0,0,0,0,0,0,0,0,3.92891693115234,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3.37693786621094,0,0,0,0,0,1.49984741210938,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1.50035095214844,0,0,0,0,0,0,0,0,0,0,0,0,0,-32.5378341674805,0,0,0,0,0,0,0,0,0,0,0,3.91426086425781,0,0,0,0,5.42462921142578,0,0,0,0,0,0,0,0,0,0,0,3.26025390625,0,0,0,0,2.96279907226562,0,0,0,0,0,0,0,0,0,0,0,0,0,3.35964965820312,0,0,0,0,0,0,0,0,3.35124206542969,0,0,0,0,0,0,2.50668334960938,0,0,0,0,0,0,0,0,0,0,0,0,0,3.32917022705078,0,0,0,0,0,4.35805511474609,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-29.2172164916992,0,0,0,0,0,0,0.126174926757812,0,0,0,0,0,0,0,0,0,0,0,0,0,0.190635681152344,0,0,0,0,0,0,0,0,0,0,0,0,0,0.143013000488281,0,0,0,0,0,0,0,0,0,0,0,0,0,0.145698547363281,0,0,0,0,0,0,0,0,0,0,0,0.101737976074219,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.189376831054688,0,0,0,0,0,0,0,0,0.150688171386719,0,0,0,0,0,0,0,0.192459106445312,0,0,0,0,0,0,0,0,0,0.173866271972656,0,0,0,0,0,0,-3.32297515869141,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.142036437988281,0,0,0,0,0,0,0,0,0,0,0.173492431640625,0,0,0,0,0,0,0,0,0,0,0,0.143936157226562,0,0,0,0,0,0,0.111785888671875,0,0,0,0,0,0,0,0,0,0,0,0,0.132087707519531,0,0,0,0,0,0,0.21533203125,0,0,0,0,0,0,0,0.161521911621094,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.159164428710938,0,0,0,0,0,0,0,0,0,0,0,0,0,0.16595458984375,0,0,0,0,0,0,0,0,0,0,0,0,0,-1.38100433349609,0,0,0,0,0,0,0,0,0,0,0,0.136039733886719,0,0,0,0,0,0,0,0,0,0,0.150337219238281,0,0,0,0,0,0,0,0,0.125450134277344,0,0,0,0,0,0,0,0,0,0,0,0.164039611816406,0,0,0,0,0,0,0.185951232910156,0,0,0,0,0,0,0,0,0,0.175140380859375,0,0,0,0,0,0,0.106254577636719,0,0,0,0,0,0,0,0.106056213378906,0,0,0,0,0,0,0,2.74498748779297,0,0,0,0,0,0,0,0,0,0,0,0,0,3.52988433837891,0,0,0,0,0,0,0,0,0,0,0,0,0,-6.02721405029297,0,0,0,0,0,0,0,0,0,0,0,2.49250030517578,0,0,0,0,0,0,0,0,0,3.45627593994141,0,0,0,0,0,4.01255798339844,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3.24613189697266,0,0,0,0,0,3.3538818359375,0,0,0,0,0,0,0,0,0,2.79092407226562,0,0,0,0,2.95477294921875,0,0,0,0,0,0,0,0,0,0,0,3.29486083984375,0,0,0,0,0,0,0,0,0,0,0,0,4.17485809326172,0,0,0,0,0,0,0,0,0,0,0,0,-25.5474624633789,0,0,0,0,0,0,0,0,0,2.89944458007812,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4.33940887451172,0,0,0,0,0,0,0,0,0,0,0,0,2.92227172851562,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3.34976959228516,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3.30747985839844,0,0,0,0,3.35652160644531,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4.07017517089844,0,0,0,0,0,0,0,0,0,0,1.29975128173828,0,0,0,0,0,0,0,0,0,0,0,0,-31.3421096801758,0,0,0,0,0,0,0,0,0,0,0,0,-8.29470062255859,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3.2344970703125,0,0,0,0,0,0,0,0,0,0,0,0,3.46682739257812,0,0,0,0,2.23308563232422,0,0,0,0,0,0,0,0,0,0,0,0,0,3.35450744628906,0,0,0,0,0,0,0,0,0,0,0,3.4302978515625,0,0,0,0,0,0,0,0,0,0,0,3.25161743164062,0,0,0,0,3.97119903564453,0,0,0,0,0,0,0,0,0,0,0,5.48377227783203,0,0,0,0,0,0,0,0,3.51051330566406,0,0,0,0,0,0,0,0,0,0,0,3.03545379638672,0,0,0,0,0,0,0,0,0,0,2.37743377685547,0,0,0,0,0,0,0,0,0,0,2.29262542724609,0,0,0,0,0,-34.974494934082,0,0,0,0,0,0,0,0,0,0,0,3.36988830566406,0,0,0,0,0,0,0,0,0,0,0,0,0,2.07999420166016,0,0,0,0,0,0,2.19734191894531,0,0,0,0,0,0,0,0,0,0,0,2.90899658203125,0,0,0,0,0,0,0,0,0,0,4.36376190185547,0,0,0,0,0,0,0,0,0,0,2.29989624023438,0,0,0,0,0,0,0,0,0,0,0,2.17176055908203,0,0,0,0,0,0,0,0,0,0,3.23138427734375,0,0,0,0,0,0,0,0,0,2.97496032714844,0,3.35213470458984,0,0,0,0,0,0,0,2.78911590576172,0,0,0,0,0,0,0,0,0,0,0,0,2.62998199462891,0,0,0,0,0,0,0,0,0,-32.6183776855469,0,0,0,0,0,0,0,0,0,0,0,0,3.11624908447266,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3.18780517578125,0,0,0,0,0,0,0,0,0,0,0,0,2.33554077148438,0,0,0,0,0,2.77051544189453,0,0,0,0,0,0,0,0,0,0,0,0,0,3.37592315673828,0,0,0,0,0,0,0,0,3.41519927978516,0,0,0,0,0,0,0,0,2.21963500976562,0,0,0,0,0,0,2.74275970458984,0,0,0,0,0,0,2.81868743896484,0,0,0,0,0,0,3.42272186279297,0,0,0,0,0,0,0,0,0,0,0,0,0,2.09642791748047,0,0,0,0,0,0,0,0,0,0,0,0,1.72164916992188,0,0,0,0,0,0,0,-28.9655075073242,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3.23362731933594,0,0,0,0,0,0,0,2.80348205566406,0,0,0,0,0,2.21641540527344,0,0,0,0,0,0,0,0,0,0,0,0,2.62263488769531,0,0,0,0,0,0,0,0,0,0,3.07429504394531,0,0,0,0,0,0,0,0,0,0,0,0,0,3.86789703369141,0,0,0,0,2.28882598876953,0,0,0,0,0,0,0,0,0,0,2.1297607421875,0,0,0,0,0,0,0,0,3.45770263671875,0,0,0,0,0,0,0,0,0,0,0,3.02007293701172,0,0,0,0,0,0,0,0,0,0,0,0,0.251358032226562,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-28.4378509521484,0,0,0,0,0,-19.0452575683594,0,0,0,0,0,-16.3076629638672,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1.09381103515625,0,0,0,0,0,0,0,0,0,0,0,2.52899169921875,0,0,0,0,0,0,0,0,0,0,0,0,2.47263336181641,0,0,0,0,0,0,0,0,0,0,0,0,2.33712005615234,0,0,0,0,0,0,0.102714538574219,0,0,0,0,0,0,0,0,0.0833206176757812,0,0,0,0,0,0,0,0,0,0,0,0.148643493652344,0,0,0,0,0,0,0,0,0,0,0.210060119628906,0,0,0,0,0,0,0,0,0,0,0,0,0.115585327148438,0,0,0,0,0,0,0,0,0,0,0.0925827026367188,0,0,0,0,0,0,0,0,0,0.0782089233398438,0,0,0,0,0,0,0,0,0,0.0713729858398438,0,0,0,0,0,0,0,0,0,0,0.119377136230469,0,0,0,0,0,0,0,0,0,0,0.0759429931640625,0,0,0,0,0,0,0,0,0,0,0.0970993041992188,0,0,0,0,0,0,0,0,0,0.0829391479492188,0,0,0,0,0,0,0,0,0,0,0.0839920043945312,0,0,0,0,0,0,0,0,0.0760879516601562,0,0,0,0,0,0,0,0,0,0,-9.00260925292969,0,0,0,0,0,0,0,0,0,0,0,0,0.138252258300781,0,0,0,0,0,0,0,0,0.096038818359375,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.0737686157226562,0,0,0,0,0,0,0,0,0.108512878417969,0,0,0,0,0,0,0,0,0.0781784057617188,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.1146240234375,0,0,0,0,0,0,0,0.0713043212890625,0,0,0,0,0,0,0,0,0,0,0.0685348510742188,0,0,0,0,0,0,0,0,0,0,0,0.111923217773438,0,0,0,0,0,0,0,0,0.0647125244140625,0,0,0,0,0,0,0,0,0.0862350463867188,0,0,0,0,0,0,0,0,0,0,0,0.0779266357421875,0,0,0,0,0,0,0,0,0,0,0.0825881958007812,0,0,0,0,0,0,0.13848876953125,0,0,0,0,0,0,0,0,0,0,0.069366455078125,0,0,0,0,0,0,0,0,0,0.0739288330078125,0,0,0,0,0,0,0,0.0843963623046875,0,0,0,0,0,0,0,0,0,0,0.0712356567382812,0,0,0,0,0,0,0,0,0.0755996704101562,0,0,0,0,0,0,-1.68778991699219,0,0,0,0,0,0,0,0,0,0.0986862182617188,0,0,0,0,0,0,0,0,0,0,0,0,0.0793609619140625,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.0750732421875,0,0,0,0,0,0,0,0,0.0816192626953125,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.100479125976562,0,0,0,0,0,0,0,0,0,0,0.112625122070312,0,0,0,0,0,0,0,0,0.116600036621094,0,0,0,0,0,0,0,0,0,0,0,0,0.0708847045898438,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.0744094848632812,0,0,0,0,0,0,0,0,0,0,0,0,0.111099243164062,0,0,0,0,0,0,0,0,0,0,0,0],"filename":[null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,"modelr/R/resample.R","modelr/R/resample.R",null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,"modelr/R/resample.R","modelr/R/resample.R",null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,"<expr>",null,null,null,null,"<expr>",null,null,null,null,null,"modelr/R/resample.R","modelr/R/resample.R",null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,"<expr>",null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,"modelr/R/resample.R","modelr/R/resample.R",null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,"modelr/R/response.R","modelr/R/response.R",null,"modelr/R/response.R","modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,"modelr/R/resample.R","modelr/R/resample.R",null,null,"modelr/R/response.R","modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,"modelr/R/response.R","modelr/R/response.R",null,"modelr/R/response.R","modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,"modelr/R/resample.R","modelr/R/resample.R",null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>","modelr/R/residuals.R",null,null,null,"<expr>",null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,"<expr>",null,"modelr/R/resample.R","modelr/R/resample.R",null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,"<expr>","modelr/R/resample.R","modelr/R/resample.R",null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>","modelr/R/resample.R","modelr/R/resample.R",null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,"<expr>",null,"<expr>",null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,"<expr>",null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,null,"<expr>",null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>","modelr/R/resample.R","modelr/R/resample.R",null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,"modelr/R/response.R","modelr/R/response.R",null,"modelr/R/response.R","modelr/R/residuals.R",null,null,null,"<expr>","modelr/R/response.R","modelr/R/response.R","modelr/R/response.R",null,"modelr/R/response.R","modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,"modelr/R/resample.R","modelr/R/resample.R",null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,"modelr/R/resample.R","modelr/R/resample.R",null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,"modelr/R/resample.R","modelr/R/resample.R",null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,"modelr/R/residuals.R",null,null,null,"<expr>",null,"modelr/R/response.R",null,"modelr/R/response.R","modelr/R/residuals.R",null,null,null,"<expr>",null,"modelr/R/resample.R","modelr/R/resample.R",null,null,"modelr/R/response.R","modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,"<expr>",null,null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>","modelr/R/response.R","modelr/R/residuals.R",null,null,null,"<expr>",null,null,"modelr/R/response.R","modelr/R/response.R",null,"modelr/R/response.R","modelr/R/residuals.R",null,null,null,"<expr>","modelr/R/resample.R","modelr/R/resample.R",null,null,"modelr/R/response.R","modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,"modelr/R/resample.R","modelr/R/resample.R",null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>","modelr/R/response.R",null,"modelr/R/response.R","modelr/R/residuals.R",null,null,null,"<expr>",null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,"modelr/R/resample.R","modelr/R/resample.R",null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>","modelr/R/resample.R","modelr/R/resample.R",null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,"modelr/R/resample.R","modelr/R/resample.R",null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,"<expr>",null,null,"modelr/R/resample.R","modelr/R/resample.R",null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,"modelr/R/resample.R","modelr/R/resample.R",null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,"<expr>",null,null,"modelr/R/resample.R","modelr/R/resample.R",null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,"modelr/R/resample.R","modelr/R/resample.R",null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,"modelr/R/resample.R","modelr/R/resample.R",null,null,"modelr/R/response.R","modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,"modelr/R/resample.R","modelr/R/resample.R",null,null,"modelr/R/response.R","modelr/R/residuals.R",null,null,null,"<expr>",null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,"modelr/R/resample.R","modelr/R/resample.R",null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,"modelr/R/resample.R","modelr/R/resample.R",null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,"modelr/R/resample.R","modelr/R/resample.R",null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,"modelr/R/resample.R","modelr/R/resample.R",null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,"<expr>",null,null,null,"modelr/R/resample.R","modelr/R/resample.R",null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,"modelr/R/resample.R","modelr/R/resample.R",null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>","modelr/R/resample.R","modelr/R/resample.R",null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>","modelr/R/resample.R","modelr/R/resample.R",null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,"<expr>",null,"<expr>",null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,"<expr>",null,null,"modelr/R/resample.R","modelr/R/resample.R",null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,"modelr/R/resample.R","modelr/R/resample.R",null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,"modelr/R/response.R","modelr/R/response.R",null,"modelr/R/response.R","modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,"modelr/R/resample.R","modelr/R/resample.R",null,null,"modelr/R/response.R","modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,"modelr/R/resample.R","modelr/R/resample.R",null,null,"modelr/R/response.R","modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,"modelr/R/resample.R","modelr/R/resample.R",null,null,"modelr/R/response.R","modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,"modelr/R/resample.R","modelr/R/resample.R",null,null,"modelr/R/response.R","modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,"modelr/R/response.R","modelr/R/response.R",null,"modelr/R/response.R","modelr/R/residuals.R",null,null,null,"<expr>",null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>","modelr/R/response.R","modelr/R/response.R",null,"modelr/R/response.R","modelr/R/residuals.R",null,null,null,"<expr>",null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,"modelr/R/resample.R","modelr/R/resample.R",null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,"modelr/R/resample.R","modelr/R/resample.R",null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,"modelr/R/resample.R","modelr/R/resample.R",null,null,"modelr/R/response.R","modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>"]},"interval":10,"files":[{"filename":"<expr>","content":"library(profvis)\n\nprofvis({\n  cv_error <- vector(\"numeric\", 5)\n  terms <- seq(from = 1, to = 5)\n  \n  for(i in terms){\n    loocv_models <- map(loocv_data$train, ~ lm(mpg ~ poly(horsepower, i), data = .))\n    loocv_mse <- map2_dbl(loocv_models, loocv_data$test, mse)\n    cv_error[[i]] <- mean(loocv_mse)\n  }\n})","normpath":"<expr>"},{"filename":"modelr/R/resample.R","content":"#' A \"lazy\" resample.\n#'\n#' Often you will resample a dataset hundreds or thousands of times. Storing\n#' the complete resample each time would be very inefficient so this class\n#' instead stores a \"pointer\" to the original dataset, and a vector of row\n#' indexes. To turn this into a regular data frame, call \\code{as.data.frame},\n#' to extract the indices, use \\code{as.integer}.\n#'\n#' @param data The data frame\n#' @param idx A vector of integer indexes indicating which rows have\n#'   been selected. These values should lie between 1 and \\code{nrow(data)}\n#'   but they are not checked by this function in the interests of performance.\n#' @inheritParams resampling techniques\n#' @export\n#' @examples\n#' resample(mtcars, 1:10)\n#'\n#' b <- resample_bootstrap(mtcars)\n#' b\n#' as.integer(b)\n#' as.data.frame(b)\n#'\n#' # Many modelling functions will do the coercion for you, so you can\n#' # use a resample object directly in the data argument\n#' lm(mpg ~ wt, data = b)\nresample <- function(data, idx) {\n  if (!is.data.frame(data)) {\n    stop(\"`data` must be a data frame.\", call. = FALSE)\n  }\n  if (!is.integer(idx)) {\n    stop(\"`idx` must be an integer vector.\", call. = FALSE)\n  }\n\n  structure(\n    list(\n      data = data,\n      idx = idx\n    ),\n    class = \"resample\"\n  )\n}\n\n#' @export\nprint.resample <- function(x, ...) {\n  n <- length(x$idx)\n  if (n > 10) {\n    id10 <- c(x$idx[1:10], \"...\")\n  } else {\n    id10 <- x$idx\n  }\n\n  cat(\"<\", obj_sum.resample(x), \"> \", paste(id10, collapse = \", \"), \"\\n\",\n    sep = \"\"\n  )\n}\n\n#' @export\nas.integer.resample <- function(x, ...) {\n  x$idx\n}\n\n#' @export\nas.data.frame.resample <- function(x, ...) {\n  x$data[x$idx, , drop = FALSE]\n}\n\n#' @export\ndim.resample <- function(x, ...) {\n  c(length(x$idx), ncol(x$data))\n}\n\n#' @importFrom tibble obj_sum\n#' @method obj_sum resample\n#' @export\nobj_sum.resample <- function(x, ...) {\n  paste0(\"resample [\", big_mark(nrow(x)), \" x \", big_mark(ncol(x)), \"]\")\n}","normpath":"/Users/soltoffbc/Projects/Computing for Social Sciences/temp/modelr/R/resample.R"},{"filename":"modelr/R/residuals.R","content":"#' Add residuals to a data frame\n#'\n#' @param data A data frame used to generate the residuals\n#' @param model,var \\code{add_residuals} takes a single \\code{model}; the\n#'   output column will be called \\code{pred}\n#' @param ... \\code{gather_residuals} and \\code{spread_residuals} take\n#'   multiple models. The name will be taken from either the argument\n#'   name of the name of the model.\n#' @param .resid,.model The variable names used by \\code{gather_residuals}.\n#' @return A data frame. \\code{add_prediction} adds a single new column,\n#'   \\code{.pred}, to the input \\code{data}. \\code{spread_residuals} adds\n#'   one column for each model. \\code{gather_prections} adds two columns\n#'   \\code{.model} and \\code{.pred}, and repeats the input rows for\n#'   each model.\n#' @export\n#' @examples\n#' df <- tibble::data_frame(\n#'   x = sort(runif(100)),\n#'   y = 5 * x + 0.5 * x ^ 2 + 3 + rnorm(length(x))\n#' )\n#' plot(df)\n#'\n#' m1 <- lm(y ~ x, data = df)\n#' df %>% add_residuals(m1)\n#'\n#' m2 <- lm(y ~ poly(x, 2), data = df)\n#' df %>% spread_residuals(m1, m2)\n#' df %>% gather_residuals(m1, m2)\nadd_residuals <- function(data, model, var = \"resid\") {\n  data[[var]] <- residuals(model, data)\n  data\n}\n\n#' @rdname add_residuals\n#' @export\nspread_residuals <- function(data, ...) {\n  models <- tibble::lst(...)\n  for (nm in names(models)) {\n    data[[nm]] <- residuals(models[[nm]], data)\n  }\n  data\n}\n\n#' @rdname add_residuals\n#' @export\ngather_residuals <- function(data, ..., .resid = \"resid\", .model = \"model\") {\n  models <- tibble::lst(...)\n\n  df <- purrr::map2(models, .resid, add_residuals, data = data)\n  names(df) <- names(models)\n\n  dplyr::bind_rows(df, .id = .model)\n}\n\nresiduals <- function(model, data) {\n  response(model, data) - stats::predict(model, data)\n}","normpath":"/Users/soltoffbc/Projects/Computing for Social Sciences/temp/modelr/R/residuals.R"},{"filename":"modelr/R/response.R","content":"response_var <- function(model) {\n  UseMethod(\"response_var\")\n}\n\n#' @export\nresponse_var.default <- function(model, data) {\n  stats::formula(model)[[2L]]\n}\n\npredictor_vars <- function(model) {\n  UseMethod(\"predictor_vars\")\n}\n\n#' @export\npredictor_vars.default <- function(model, data) {\n  all.vars(stats::formula(model)[[3L]])\n}\n\nresponse <- function(model, data) {\n  eval(response_var(model), as.data.frame(data))\n}","normpath":"/Users/soltoffbc/Projects/Computing for Social Sciences/temp/modelr/R/response.R"}],"prof_output":"/var/folders/vw/l7k7vwhn3qqd990ww0dd101c0000gn/T//RtmpHOtm4D/file133a7149d3e48.prof","highlight":{"output":["^output\\$"],"gc":["^<GC>$"],"stacktrace":["^\\.\\.stacktraceo(n|ff)\\.\\.$"]},"split":"h"}},"evals":[],"jsHooks":[]}</script>
</div>
<div id="fold-cv" class="section level3">
<h3>10-fold CV</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">profvis</span>({
  cv_error_fold10 &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="st">&quot;numeric&quot;</span>, <span class="dv">5</span>)
  terms &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">1</span>, <span class="dt">to =</span> <span class="dv">5</span>)
  
  <span class="cf">for</span>(i <span class="cf">in</span> terms){
    cv10_models &lt;-<span class="st"> </span><span class="kw">map</span>(cv10_data<span class="op">$</span>train, <span class="op">~</span><span class="st"> </span><span class="kw">lm</span>(mpg <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(horsepower, i), <span class="dt">data =</span> .))
    cv10_mse &lt;-<span class="st"> </span><span class="kw">map2_dbl</span>(cv10_models, cv10_data<span class="op">$</span>test, mse)
    cv_error_fold10[[i]] &lt;-<span class="st"> </span><span class="kw">mean</span>(cv10_mse)
  }
})</code></pre></div>
<div id="htmlwidget-e4b7407ede296e9f5aaa" style="width:100%;height:600px;" class="profvis html-widget"></div>
<script type="application/json" data-for="htmlwidget-e4b7407ede296e9f5aaa">{"x":{"message":{"prof":{"time":[1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,11,11,12,12],"depth":[12,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,2,1],"label":["outer","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","map","[.tbl_df","[","as.data.frame.resample","as.data.frame","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","$","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","deparse","paste","FUN","lapply","sapply","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map","c","eval","eval","match.arg","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl","deparse","mode","%in%","deparse","paste","FUN","vapply","model.matrix.default","model.matrix","lm",".f",".Call","map","predict.lm","stats::predict","modelr:::residuals",".f",".Call","map2_dbl",".Fortran","qr.qy","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map",".External2","model.matrix.default","model.matrix","lm",".f",".Call","map","outer","poly","eval","eval","model.frame.default","stats::model.frame","eval","eval","lm",".f",".Call","map",".Call","map"],"filenum":[null,null,null,null,null,null,null,null,null,null,null,1,null,2,2,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,3,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,3,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,null,null,null,1,null,1],"linenum":[null,null,null,null,null,null,null,null,null,null,null,6,null,64,64,null,null,null,null,null,null,null,null,null,6,null,null,null,null,null,null,null,null,null,null,null,6,null,null,null,null,null,null,null,null,null,null,null,null,6,null,null,null,null,null,null,null,null,null,null,6,null,null,null,null,null,56,null,null,null,7,null,null,null,null,null,null,null,null,null,null,null,null,6,null,56,null,null,null,7,null,null,null,null,null,null,null,null,null,null,null,null,6,null,null,null,null,null,null,6,null,null,null,null,null,null,null,null,null,null,null,6,null,6],"memalloc":[59.7426910400391,59.7426910400391,59.7426910400391,59.7426910400391,59.7426910400391,59.7426910400391,59.7426910400391,59.7426910400391,59.7426910400391,59.7426910400391,59.7426910400391,59.7426910400391,60.6387023925781,60.6387023925781,60.6387023925781,60.6387023925781,60.6387023925781,60.6387023925781,60.6387023925781,60.6387023925781,60.6387023925781,60.6387023925781,60.6387023925781,60.6387023925781,60.6387023925781,61.6550750732422,61.6550750732422,61.6550750732422,61.6550750732422,61.6550750732422,61.6550750732422,61.6550750732422,61.6550750732422,61.6550750732422,61.6550750732422,61.6550750732422,61.6550750732422,62.1096649169922,62.1096649169922,62.1096649169922,62.1096649169922,62.1096649169922,62.1096649169922,62.1096649169922,62.1096649169922,62.1096649169922,62.1096649169922,62.1096649169922,62.1096649169922,62.1096649169922,64.3517837524414,64.3517837524414,64.3517837524414,64.3517837524414,64.3517837524414,64.3517837524414,64.3517837524414,64.3517837524414,64.3517837524414,64.3517837524414,64.3517837524414,65.4000473022461,65.4000473022461,65.4000473022461,65.4000473022461,65.4000473022461,65.4000473022461,65.4000473022461,65.4000473022461,65.4000473022461,65.4000473022461,67.5832901000977,67.5832901000977,67.5832901000977,67.5832901000977,67.5832901000977,67.5832901000977,67.5832901000977,67.5832901000977,67.5832901000977,67.5832901000977,67.5832901000977,67.5832901000977,67.5832901000977,69.2725677490234,69.2725677490234,69.2725677490234,69.2725677490234,69.2725677490234,69.2725677490234,71.4016342163086,71.4016342163086,71.4016342163086,71.4016342163086,71.4016342163086,71.4016342163086,71.4016342163086,71.4016342163086,71.4016342163086,71.4016342163086,71.4016342163086,71.4016342163086,71.4016342163086,73.8077163696289,73.8077163696289,73.8077163696289,73.8077163696289,73.8077163696289,73.8077163696289,73.8077163696289,75.3150863647461,75.3150863647461,75.3150863647461,75.3150863647461,75.3150863647461,75.3150863647461,75.3150863647461,75.3150863647461,75.3150863647461,75.3150863647461,75.3150863647461,75.3150863647461,78.7761001586914,78.7761001586914],"meminc":[0,0,0,0,0,0,0,0,0,0,0,0,0.896011352539062,0,0,0,0,0,0,0,0,0,0,0,0,1.01637268066406,0,0,0,0,0,0,0,0,0,0,0,0.45458984375,0,0,0,0,0,0,0,0,0,0,0,0,2.24211883544922,0,0,0,0,0,0,0,0,0,0,1.04826354980469,0,0,0,0,0,0,0,0,0,2.18324279785156,0,0,0,0,0,0,0,0,0,0,0,0,1.68927764892578,0,0,0,0,0,2.12906646728516,0,0,0,0,0,0,0,0,0,0,0,0,2.40608215332031,0,0,0,0,0,0,1.50736999511719,0,0,0,0,0,0,0,0,0,0,0,3.46101379394531,0],"filename":[null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,"modelr/R/resample.R","modelr/R/resample.R",null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,"modelr/R/residuals.R",null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,"<expr>",null,null,null,null,null,null,null,null,null,null,null,"<expr>",null,"<expr>"]},"interval":10,"files":[{"filename":"<expr>","content":"profvis({\n  cv_error_fold10 <- vector(\"numeric\", 5)\n  terms <- seq(from = 1, to = 5)\n  \n  for(i in terms){\n    cv10_models <- map(cv10_data$train, ~ lm(mpg ~ poly(horsepower, i), data = .))\n    cv10_mse <- map2_dbl(cv10_models, cv10_data$test, mse)\n    cv_error_fold10[[i]] <- mean(cv10_mse)\n  }\n})","normpath":"<expr>"},{"filename":"modelr/R/resample.R","content":"#' A \"lazy\" resample.\n#'\n#' Often you will resample a dataset hundreds or thousands of times. Storing\n#' the complete resample each time would be very inefficient so this class\n#' instead stores a \"pointer\" to the original dataset, and a vector of row\n#' indexes. To turn this into a regular data frame, call \\code{as.data.frame},\n#' to extract the indices, use \\code{as.integer}.\n#'\n#' @param data The data frame\n#' @param idx A vector of integer indexes indicating which rows have\n#'   been selected. These values should lie between 1 and \\code{nrow(data)}\n#'   but they are not checked by this function in the interests of performance.\n#' @inheritParams resampling techniques\n#' @export\n#' @examples\n#' resample(mtcars, 1:10)\n#'\n#' b <- resample_bootstrap(mtcars)\n#' b\n#' as.integer(b)\n#' as.data.frame(b)\n#'\n#' # Many modelling functions will do the coercion for you, so you can\n#' # use a resample object directly in the data argument\n#' lm(mpg ~ wt, data = b)\nresample <- function(data, idx) {\n  if (!is.data.frame(data)) {\n    stop(\"`data` must be a data frame.\", call. = FALSE)\n  }\n  if (!is.integer(idx)) {\n    stop(\"`idx` must be an integer vector.\", call. = FALSE)\n  }\n\n  structure(\n    list(\n      data = data,\n      idx = idx\n    ),\n    class = \"resample\"\n  )\n}\n\n#' @export\nprint.resample <- function(x, ...) {\n  n <- length(x$idx)\n  if (n > 10) {\n    id10 <- c(x$idx[1:10], \"...\")\n  } else {\n    id10 <- x$idx\n  }\n\n  cat(\"<\", obj_sum.resample(x), \"> \", paste(id10, collapse = \", \"), \"\\n\",\n    sep = \"\"\n  )\n}\n\n#' @export\nas.integer.resample <- function(x, ...) {\n  x$idx\n}\n\n#' @export\nas.data.frame.resample <- function(x, ...) {\n  x$data[x$idx, , drop = FALSE]\n}\n\n#' @export\ndim.resample <- function(x, ...) {\n  c(length(x$idx), ncol(x$data))\n}\n\n#' @importFrom tibble obj_sum\n#' @method obj_sum resample\n#' @export\nobj_sum.resample <- function(x, ...) {\n  paste0(\"resample [\", big_mark(nrow(x)), \" x \", big_mark(ncol(x)), \"]\")\n}","normpath":"/Users/soltoffbc/Projects/Computing for Social Sciences/temp/modelr/R/resample.R"},{"filename":"modelr/R/residuals.R","content":"#' Add residuals to a data frame\n#'\n#' @param data A data frame used to generate the residuals\n#' @param model,var \\code{add_residuals} takes a single \\code{model}; the\n#'   output column will be called \\code{pred}\n#' @param ... \\code{gather_residuals} and \\code{spread_residuals} take\n#'   multiple models. The name will be taken from either the argument\n#'   name of the name of the model.\n#' @param .resid,.model The variable names used by \\code{gather_residuals}.\n#' @return A data frame. \\code{add_prediction} adds a single new column,\n#'   \\code{.pred}, to the input \\code{data}. \\code{spread_residuals} adds\n#'   one column for each model. \\code{gather_prections} adds two columns\n#'   \\code{.model} and \\code{.pred}, and repeats the input rows for\n#'   each model.\n#' @export\n#' @examples\n#' df <- tibble::data_frame(\n#'   x = sort(runif(100)),\n#'   y = 5 * x + 0.5 * x ^ 2 + 3 + rnorm(length(x))\n#' )\n#' plot(df)\n#'\n#' m1 <- lm(y ~ x, data = df)\n#' df %>% add_residuals(m1)\n#'\n#' m2 <- lm(y ~ poly(x, 2), data = df)\n#' df %>% spread_residuals(m1, m2)\n#' df %>% gather_residuals(m1, m2)\nadd_residuals <- function(data, model, var = \"resid\") {\n  data[[var]] <- residuals(model, data)\n  data\n}\n\n#' @rdname add_residuals\n#' @export\nspread_residuals <- function(data, ...) {\n  models <- tibble::lst(...)\n  for (nm in names(models)) {\n    data[[nm]] <- residuals(models[[nm]], data)\n  }\n  data\n}\n\n#' @rdname add_residuals\n#' @export\ngather_residuals <- function(data, ..., .resid = \"resid\", .model = \"model\") {\n  models <- tibble::lst(...)\n\n  df <- purrr::map2(models, .resid, add_residuals, data = data)\n  names(df) <- names(models)\n\n  dplyr::bind_rows(df, .id = .model)\n}\n\nresiduals <- function(model, data) {\n  response(model, data) - stats::predict(model, data)\n}","normpath":"/Users/soltoffbc/Projects/Computing for Social Sciences/temp/modelr/R/residuals.R"}],"prof_output":"/var/folders/vw/l7k7vwhn3qqd990ww0dd101c0000gn/T//RtmpHOtm4D/file133a77622a365.prof","highlight":{"output":["^output\\$"],"gc":["^<GC>$"],"stacktrace":["^\\.\\.stacktraceo(n|ff)\\.\\.$"]},"split":"h"}},"evals":[],"jsHooks":[]}</script>
<p>On my machine, 10-fold CV was about 40 times faster than LOOCV. Again, estimating <span class="math inline">\(k=10\)</span> models is going to be much easier than estimating <span class="math inline">\(k=392\)</span> models.</p>
</div>
</div>
<div id="k-fold-cv-in-logistic-regression" class="section level2">
<h2>k-fold CV in logistic regression</h2>
<p>You’ve gotten the idea by now, but let’s do it one more time on our interactive Titanic model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">titanic_kfold &lt;-<span class="st"> </span><span class="kw">crossv_kfold</span>(titanic, <span class="dt">k =</span> <span class="dv">10</span>)
titanic_models &lt;-<span class="st"> </span><span class="kw">map</span>(titanic_kfold<span class="op">$</span>train, <span class="op">~</span><span class="st"> </span><span class="kw">glm</span>(Survived <span class="op">~</span><span class="st"> </span>Age <span class="op">*</span><span class="st"> </span>Sex,
                                                 <span class="dt">data =</span> .,
                                                 <span class="dt">family =</span> binomial))
titanic_mse &lt;-<span class="st"> </span><span class="kw">map2_dbl</span>(titanic_models, titanic_kfold<span class="op">$</span>test, mse.glm)
<span class="kw">mean</span>(titanic_mse, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## [1] 0.1693387</code></pre>
<p>Not a large difference from the LOOCV approach, but it take much less time to compute.</p>
</div>
<div id="exercise-k-fold-cv" class="section level2">
<h2>Exercise: k-fold CV</h2>
<ol style="list-style-type: decimal">
<li><p>Estimate the 10-fold CV MSE of a linear regression of the relationship between admission rate and cost in the <a href="stat002_linear_models.html#exercise:_linear_regression_with_scorecard"><code>scorecard</code> dataset</a>.</p>
<details> <summary>Click for the solution</summary>
<p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">scorecard_cv10 &lt;-<span class="st"> </span><span class="kw">crossv_kfold</span>(scorecard, <span class="dt">k =</span> <span class="dv">10</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">model =</span> <span class="kw">map</span>(train, <span class="op">~</span><span class="st"> </span><span class="kw">lm</span>(cost <span class="op">~</span><span class="st"> </span>admrate, <span class="dt">data =</span> .)),
         <span class="dt">mse =</span> <span class="kw">map2_dbl</span>(model, test, mse))
<span class="kw">mean</span>(scorecard_cv10<span class="op">$</span>mse, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## [1] 147794005</code></pre>
</p>
<p></details></p></li>
<li><p>Estimate the 10-fold CV MSE of a <a href="stat003_logistic_regression.html#exercise:_logistic_regression_with_mental_health">logistic regression model of voter turnout</a> using only <code>mhealth</code> as the predictor. Compare this to the LOOCV MSE of a logistic regression model using all available predictors. Which is the better model?</p>
<details> <summary>Click for the solution</summary>
<p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># basic model</span>
mh_cv10_lite &lt;-<span class="st"> </span><span class="kw">crossv_kfold</span>(mental_health, <span class="dt">k =</span> <span class="dv">10</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">model =</span> <span class="kw">map</span>(train, <span class="op">~</span><span class="st"> </span><span class="kw">glm</span>(vote96 <span class="op">~</span><span class="st"> </span>mhealth, <span class="dt">data =</span> .,
                                  <span class="dt">family =</span> binomial)),
         <span class="dt">mse =</span> <span class="kw">map2_dbl</span>(model, test, mse.glm))
<span class="kw">mean</span>(mh_cv10_lite<span class="op">$</span>mse, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## [1] 0.2093087</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># full model</span>
mh_cv10_full &lt;-<span class="st"> </span><span class="kw">crossv_kfold</span>(mental_health, <span class="dt">k =</span> <span class="dv">10</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">model =</span> <span class="kw">map</span>(train, <span class="op">~</span><span class="st"> </span><span class="kw">glm</span>(vote96 <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> .,
                                  <span class="dt">family =</span> binomial)),
         <span class="dt">mse =</span> <span class="kw">map2_dbl</span>(model, test, mse.glm))
<span class="kw">mean</span>(mh_cv10_full<span class="op">$</span>mse, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## [1] 0.1819416</code></pre>
</p>
<p></details></p></li>
</ol>
</div>
</div>
<div id="session-info" class="section level1 toc-ignore">
<h1>Session Info</h1>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">devtools<span class="op">::</span><span class="kw">session_info</span>()</code></pre></div>
<pre><code>##  setting  value                       
##  version  R version 3.4.3 (2017-11-30)
##  system   x86_64, darwin15.6.0        
##  ui       X11                         
##  language (EN)                        
##  collate  en_US.UTF-8                 
##  tz       America/Chicago             
##  date     2018-05-23                  
## 
##  package    * version    date       source                             
##  assertthat   0.2.0      2017-04-11 CRAN (R 3.4.0)                     
##  backports    1.1.2      2017-12-13 CRAN (R 3.4.3)                     
##  base       * 3.4.3      2017-12-07 local                              
##  bindr        0.1.1      2018-03-13 CRAN (R 3.4.3)                     
##  bindrcpp     0.2.2      2018-03-29 CRAN (R 3.4.4)                     
##  broom      * 0.4.4      2018-03-29 CRAN (R 3.4.3)                     
##  cellranger   1.1.0      2016-07-27 CRAN (R 3.4.0)                     
##  cli          1.0.0      2017-11-05 CRAN (R 3.4.2)                     
##  colorspace   1.3-2      2016-12-14 CRAN (R 3.4.0)                     
##  compiler     3.4.3      2017-12-07 local                              
##  crayon       1.3.4      2017-10-03 Github (gaborcsardi/crayon@b5221ab)
##  datasets   * 3.4.3      2017-12-07 local                              
##  devtools     1.13.5     2018-02-18 CRAN (R 3.4.3)                     
##  digest       0.6.15     2018-01-28 CRAN (R 3.4.3)                     
##  dplyr      * 0.7.4      2017-09-28 CRAN (R 3.4.2)                     
##  evaluate     0.10.1     2017-06-24 CRAN (R 3.4.1)                     
##  forcats    * 0.3.0      2018-02-19 CRAN (R 3.4.3)                     
##  foreign      0.8-69     2017-06-22 CRAN (R 3.4.3)                     
##  ggplot2    * 2.2.1.9000 2018-05-18 Github (tidyverse/ggplot2@54de616) 
##  glue         1.2.0      2017-10-29 CRAN (R 3.4.2)                     
##  graphics   * 3.4.3      2017-12-07 local                              
##  grDevices  * 3.4.3      2017-12-07 local                              
##  grid         3.4.3      2017-12-07 local                              
##  gtable       0.2.0      2016-02-26 CRAN (R 3.4.0)                     
##  haven        1.1.1      2018-01-18 CRAN (R 3.4.3)                     
##  hms          0.4.2      2018-03-10 CRAN (R 3.4.3)                     
##  htmltools    0.3.6      2017-04-28 CRAN (R 3.4.0)                     
##  httr         1.3.1      2017-08-20 CRAN (R 3.4.1)                     
##  jsonlite     1.5        2017-06-01 CRAN (R 3.4.0)                     
##  knitr        1.20       2018-02-20 CRAN (R 3.4.3)                     
##  lattice      0.20-35    2017-03-25 CRAN (R 3.4.3)                     
##  lazyeval     0.2.1      2017-10-29 CRAN (R 3.4.2)                     
##  lubridate    1.7.4      2018-04-11 CRAN (R 3.4.3)                     
##  magrittr     1.5        2014-11-22 CRAN (R 3.4.0)                     
##  memoise      1.1.0      2017-04-21 CRAN (R 3.4.0)                     
##  methods    * 3.4.3      2017-12-07 local                              
##  mnormt       1.5-5      2016-10-15 CRAN (R 3.4.0)                     
##  modelr     * 0.1.1      2017-08-10 local                              
##  munsell      0.4.3      2016-02-13 CRAN (R 3.4.0)                     
##  nlme         3.1-137    2018-04-07 CRAN (R 3.4.4)                     
##  parallel     3.4.3      2017-12-07 local                              
##  pillar       1.2.1      2018-02-27 CRAN (R 3.4.3)                     
##  pkgconfig    2.0.1      2017-03-21 CRAN (R 3.4.0)                     
##  plyr         1.8.4      2016-06-08 CRAN (R 3.4.0)                     
##  psych        1.8.3.3    2018-03-30 CRAN (R 3.4.4)                     
##  purrr      * 0.2.4      2017-10-18 CRAN (R 3.4.2)                     
##  R6           2.2.2      2017-06-17 CRAN (R 3.4.0)                     
##  Rcpp         0.12.16    2018-03-13 CRAN (R 3.4.4)                     
##  readr      * 1.1.1      2017-05-16 CRAN (R 3.4.0)                     
##  readxl       1.0.0      2017-04-18 CRAN (R 3.4.0)                     
##  reshape2     1.4.3      2017-12-11 CRAN (R 3.4.3)                     
##  rlang        0.2.0.9001 2018-05-18 Github (r-lib/rlang@854174a)       
##  rmarkdown    1.9        2018-03-01 CRAN (R 3.4.3)                     
##  rprojroot    1.3-2      2018-01-03 CRAN (R 3.4.3)                     
##  rstudioapi   0.7        2017-09-07 CRAN (R 3.4.1)                     
##  rvest        0.3.2      2016-06-17 CRAN (R 3.4.0)                     
##  scales       0.5.0.9000 2018-05-18 Github (hadley/scales@d767915)     
##  stats      * 3.4.3      2017-12-07 local                              
##  stringi      1.1.7      2018-03-12 CRAN (R 3.4.3)                     
##  stringr    * 1.3.0      2018-02-19 CRAN (R 3.4.3)                     
##  tibble     * 1.4.2      2018-01-22 CRAN (R 3.4.3)                     
##  tidyr      * 0.8.0      2018-01-29 CRAN (R 3.4.3)                     
##  tidyverse  * 1.2.1      2017-11-14 CRAN (R 3.4.2)                     
##  tools        3.4.3      2017-12-07 local                              
##  utils      * 3.4.3      2017-12-07 local                              
##  withr        2.1.2      2018-05-18 Github (jimhester/withr@79d7b0d)   
##  xml2         1.2.0      2018-01-24 CRAN (R 3.4.3)                     
##  yaml         2.1.18     2018-03-08 CRAN (R 3.4.4)</code></pre>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>The actual value you use is irrelevant. Just be sure to set it in the script, otherwise R will randomly pick one each time you start a new session.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>The default <code>family</code> for <code>glm()</code> is <code>gaussian()</code>, or the <strong>Gaussian</strong> distribution. You probably know it by its other name, the <a href="https://en.wikipedia.org/wiki/Normal_distribution"><strong>Normal</strong> distribution</a>.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>This function can also be loaded via the <a href="https://github.com/uc-cfss/rcfss"><code>rcfss</code></a> library. Be sure to update your package to the latest version to make sure the function is available.<a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>This function can also be loaded via the <a href="https://github.com/uc-cfss/rcfss"><code>rcfss</code></a> library.<a href="#fnref4">↩</a></p></li>
</ol>
</div>

<p>This work is licensed under the  <a href="http://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0 Creative Commons License</a>.</p>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
