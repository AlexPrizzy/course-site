---
title: "Statistical learning: classification and cross-validation"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache=TRUE)
```

# cm012 - May 2, 2018

## Overview

* Define a decision tree
* Demonstrate how to estimate a decision tree
* Define and estimate a random forest
* Introduce the `caret` package for statistical learning in R
* Define resampling method
* Compare and contrast the validation set approach with leave-one-out and $k$-fold cross-validation
* Demonstrate how to conduct cross-validation using `rsample`

## Before class

This is not a math/stats class. In class we will **briefly** summarize how these methods work and spend the bulk of our time on estimating and interpreting these models. That said, you should have some understanding of the mathematical underpinnings of statistical learning methods prior to implementing them yourselves. See below for some recommended readings:

##### For those with little/no statistics training

* Chapters 1-2, 4 in [Machine Learning with Tree-Based Models in R](https://www.datacamp.com/courses/correlation-and-regression) - a DataCamp course

##### For those with prior statistics training

* Chapters 8.1, 8.2.2, and 5.1 in [*An Introduction to Statistical Learning*](http://link.springer.com.proxy.uchicago.edu/book/10.1007%2F978-1-4614-7138-7)

## Slides and links

* [Slides](extras/cm012_slides.html)
* [Decision trees and random forests](stat004_decision_trees.html)
* [Resampling methods](stat005_resampling.html)

* [The `caret` Package](https://topepo.github.io/caret/) - introductory book for the `caret` package. Tells you what models you can implement and all the nitty-gritty details to customize `train` for different cross-validation methods.
* [Working with `rset`s](https://tidymodels.github.io/rsample/articles/Working_with_rsets.html) - documentation for `rsample` and demonstration implementing it for resampling and model assessment

## What you need to do

* [Start homework 6](hw06-stat-learn.html)
