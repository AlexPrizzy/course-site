---
title: "Statistical learning: classification and cross-validation"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache=TRUE)
```

# cm012 - May 2, 2018

## Overview

* Define a decision tree
* Demonstrate how to estimate a decision tree
* Define and estimate a random forest
* Introduce the `caret` package for statistical learning in R
* Define resampling method
* Compare and contrast the validation set approach with leave-one-out and $k$-fold cross-validation
* Demonstrate how to conduct cross-validation using `rsample`

## Before class

* Read chapters , 8.1, 8.2.2, and 5.1 in [*An Introduction to Statistical Learning*](http://link.springer.com.proxy.uchicago.edu/book/10.1007%2F978-1-4614-7138-7) if you want a rigorous introduction to the mathematics behind logistic regression, decision trees, and random forests. In class we will **briefly** summarize how these methods work and spend the bulk of our time on estimating and interpreting these models

## Slides and links

* [Slides](extras/cm012_slides.html)
* [Decision trees and random forests](stat004_decision_trees.html)
* [Resampling methods](stat005_resampling.html)

* [The `caret` Package](https://topepo.github.io/caret/) - introductory book for the `caret` package. Tells you what models you can implement and all the nitty-gritty details to customize `train` for different cross-validation methods.
* [Working with `rset`s](https://tidymodels.github.io/rsample/articles/Working_with_rsets.html) - documentation for `rsample` and demonstration implementing it for resampling and model assessment

## What you need to do

* [Start homework 6](hw06-stat-learn.html)
