<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Spark and sparklyr</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/readable.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-45631879-2', 'auto');
  ga('send', 'pageview');

</script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 66px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 71px;
  margin-top: -71px;
}

.section h2 {
  padding-top: 71px;
  margin-top: -71px;
}
.section h3 {
  padding-top: 71px;
  margin-top: -71px;
}
.section h4 {
  padding-top: 71px;
  margin-top: -71px;
}
.section h5 {
  padding-top: 71px;
  margin-top: -71px;
}
.section h6 {
  padding-top: 71px;
  margin-top: -71px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Computing for the Social Sciences</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="faq.html">FAQ</a>
</li>
<li>
  <a href="syllabus.html">Syllabus</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Spark and <code>sparklyr</code></h1>

</div>


<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rsparkling)
<span class="kw">library</span>(sparklyr)
<span class="kw">library</span>(h2o)
<span class="kw">library</span>(tidyverse)

<span class="kw">set.seed</span>(<span class="dv">1234</span>)
<span class="kw">theme_set</span>(<span class="kw">theme_minimal</span>())</code></pre></div>
<div id="hadoop-and-spark" class="section level1">
<h1>Hadoop and Spark</h1>
<p><a href="http://hadoop.apache.org/">Apache Hadoop</a> is an open-source software library that enables distributed processing of large data sets across clusters of computers. It is highly <strong>scalable</strong>, in that can be loaded on a single server or spread across thousands of separate machines. It includes several modules including the Hadoop Distributed File System (HDFS) for distributed file storage, Hadoop MapReduce for parallel processing of large data sets, and <a href="http://spark.apache.org/">Spark</a>, a general engine for large-scale data processing, including statistical learning.</p>
</div>
<div id="sparklyr" class="section level1">
<h1><code>sparklyr</code></h1>
<p>Learning to use Hadoop and Spark can be very complicated. They use their own programming language to specify functions and perform operations. In this class, we will interact with Spark through <a href="http://spark.rstudio.com/"><code>sparklyr</code></a>, a package in R from the same authors of RStudio and the <code>tidyverse</code>. This allows us to:</p>
<ul>
<li>Connect to Spark from R using the <code>dplyr</code> interface</li>
<li>Interact with SQL databases stored on a Spark cluster</li>
<li>Implement distributed <a href="cm011.html">statistical</a> <a href="cm012.html">learning</a> algorithms</li>
</ul>
<p>See <a href="http://spark.rstudio.com/">here</a> for more detailed instructions for setting up and using <code>sparklyr</code>.</p>
<div id="installation" class="section level2">
<h2>Installation</h2>
<p>First you need to install <code>sparklyr</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">&quot;sparklyr&quot;</span>)</code></pre></div>
<p>You also need to install a local version of Spark to run it on your computer:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(sparklyr)
<span class="kw">spark_install</span>(<span class="dt">version =</span> <span class="st">&quot;2.1.0&quot;</span>)</code></pre></div>
</div>
<div id="connecting-to-spark" class="section level2">
<h2>Connecting to Spark</h2>
<p>You can connect to both local instances of Spark as well as remote Spark clusters. Let’s use the <code>spark_connect()</code> function to connect to a local cluster built on our computer:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(sparklyr)
sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">&quot;local&quot;</span>)</code></pre></div>
</div>
<div id="reading-data" class="section level2">
<h2>Reading data</h2>
<p>You can copy R data frames into Spark using the <code>dplyr::copy_to()</code> function. Let’s prepare the Spark cluster by loading two data frames from the <code>babynames</code> package:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">&quot;babynames&quot;</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(babynames)
babynames_tbl &lt;-<span class="st"> </span><span class="kw">copy_to</span>(sc, babynames, <span class="st">&quot;babynames&quot;</span>, <span class="dt">overwrite =</span> <span class="ot">TRUE</span>)
applicants_tbl &lt;-<span class="st"> </span><span class="kw">copy_to</span>(sc, applicants, <span class="st">&quot;applicants&quot;</span>, <span class="dt">overwrite =</span> <span class="ot">TRUE</span>)

babynames_tbl</code></pre></div>
<pre><code>## # Source:   table&lt;babynames&gt; [?? x 5]
## # Database: spark_connection
##     year sex   name          n   prop
##    &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;     &lt;int&gt;  &lt;dbl&gt;
##  1 1880. F     Mary       7065 0.0724
##  2 1880. F     Anna       2604 0.0267
##  3 1880. F     Emma       2003 0.0205
##  4 1880. F     Elizabeth  1939 0.0199
##  5 1880. F     Minnie     1746 0.0179
##  6 1880. F     Margaret   1578 0.0162
##  7 1880. F     Ida        1472 0.0151
##  8 1880. F     Alice      1414 0.0145
##  9 1880. F     Bertha     1320 0.0135
## 10 1880. F     Sarah      1288 0.0132
## # ... with more rows</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">applicants_tbl</code></pre></div>
<pre><code>## # Source:   table&lt;applicants&gt; [?? x 3]
## # Database: spark_connection
##     year sex    n_all
##    &lt;int&gt; &lt;chr&gt;  &lt;int&gt;
##  1  1880 F      97604
##  2  1880 M     118399
##  3  1881 F      98855
##  4  1881 M     108282
##  5  1882 F     115696
##  6  1882 M     122031
##  7  1883 F     120059
##  8  1883 M     112478
##  9  1884 F     137586
## 10  1884 M     122739
## # ... with more rows</code></pre>
</div>
<div id="using-dplyr" class="section level2">
<h2>Using <code>dplyr</code></h2>
<p>Interacting with a Spark database uses the same <code>dplyr</code> functions as you would with a data frame or SQL database. For example, let’s plot the total US births recorded from the Social Security Administration, by gender:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">birthsYearly &lt;-<span class="st"> </span>applicants_tbl <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">sex =</span> <span class="kw">if_else</span>(sex <span class="op">==</span><span class="st"> &quot;M&quot;</span>, <span class="st">&quot;male&quot;</span>, <span class="st">&quot;female&quot;</span>),
         <span class="dt">n_all =</span> n_all <span class="op">/</span><span class="st"> </span><span class="dv">1000000</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">collect</span>()

<span class="kw">ggplot</span>(birthsYearly, <span class="kw">aes</span>(year, n_all, <span class="dt">fill =</span> sex)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_area</span>(<span class="dt">position =</span> <span class="st">&quot;stack&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_fill_brewer</span>(<span class="dt">type =</span> <span class="st">&quot;qual&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Total US Births&quot;</span>,
       <span class="dt">y =</span> <span class="st">&quot;Millions&quot;</span>,
       <span class="dt">fill =</span> <span class="ot">NULL</span>,
       <span class="dt">caption =</span> <span class="st">&quot;Source: SSA&quot;</span>)</code></pre></div>
<p><img src="distrib003_spark_files/figure-html/total-us-birth-spark-1.png" width="672" /></p>
<p>Note that this code is extremely similar to if we ran it with a traditional data frame. The only difference is that we do not have to <code>collect()</code> the final table:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">birthsYearly &lt;-<span class="st"> </span>applicants <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">sex =</span> <span class="kw">if_else</span>(sex <span class="op">==</span><span class="st"> &quot;M&quot;</span>, <span class="st">&quot;male&quot;</span>, <span class="st">&quot;female&quot;</span>),
         <span class="dt">n_all =</span> n_all <span class="op">/</span><span class="st"> </span><span class="dv">1000000</span>)

<span class="kw">ggplot</span>(birthsYearly, <span class="kw">aes</span>(year, n_all, <span class="dt">fill =</span> sex)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_area</span>(<span class="dt">position =</span> <span class="st">&quot;stack&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_fill_brewer</span>(<span class="dt">type =</span> <span class="st">&quot;qual&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Total US Births&quot;</span>,
       <span class="dt">y =</span> <span class="st">&quot;Millions&quot;</span>,
       <span class="dt">fill =</span> <span class="ot">NULL</span>,
       <span class="dt">caption =</span> <span class="st">&quot;Source: SSA&quot;</span>)</code></pre></div>
<p><img src="distrib003_spark_files/figure-html/total-us-birth-df-1.png" width="672" /></p>
<p>We can also use Spark and <code>dplyr</code> to create a <a href="https://www.red-gate.com/simple-talk/sql/t-sql-programming/look-up-tables-in-sql/"><strong>lookup table</strong></a>. A lookup table summarizes some entity or relationship in a database; while it is not required to exist in the database schema, it can be useful to store these summary tables for easy access later. Here let’s create a lookup table that stores information on the top 1000 baby names since 1986:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(topNames_tbl &lt;-<span class="st"> </span>babynames_tbl <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(year <span class="op">&gt;=</span><span class="st"> </span><span class="dv">1986</span>) <span class="op">%&gt;%</span><span class="st">  </span>
<span class="st">  </span><span class="kw">group_by</span>(name, sex) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">count =</span> <span class="kw">as.numeric</span>(<span class="kw">sum</span>(n))) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(count <span class="op">&gt;</span><span class="st"> </span><span class="dv">1000</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(name, sex))</code></pre></div>
<pre><code>## # Source:   lazy query [?? x 2]
## # Database: spark_connection
## # Groups:   name
##         name   sex
##        &lt;chr&gt; &lt;chr&gt;
##  1   Jessica     F
##  2    Ashley     F
##  3  Jennifer     F
##  4    Nicole     F
##  5   Heather     F
##  6 Elizabeth     F
##  7     Megan     F
##  8   Melissa     F
##  9  Danielle     F
## 10       Amy     F
## # ... with more rows</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(filteredNames_tbl &lt;-<span class="st"> </span>babynames_tbl <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(year <span class="op">&gt;=</span><span class="st"> </span><span class="dv">1986</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">inner_join</span>(topNames_tbl))</code></pre></div>
<pre><code>## # Source:   lazy query [?? x 5]
## # Database: spark_connection
##     year   sex  name     n         prop
##    &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt;        &lt;dbl&gt;
##  1  1998     F Aanya     5 2.580377e-06
##  2  1999     F Aanya     5 2.569595e-06
##  3  2000     F Aanya     7 3.509720e-06
##  4  2001     F Aanya    20 1.010320e-05
##  5  2002     F Aanya    20 1.013399e-05
##  6  2003     F Aanya    24 1.197048e-05
##  7  2004     F Aanya    39 1.934463e-05
##  8  2005     F Aanya    39 1.923544e-05
##  9  2006     F Aanya    92 4.405580e-05
## 10  2007     F Aanya   125 5.913224e-05
## # ... with more rows</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(yearlyNames_tbl &lt;-<span class="st"> </span>filteredNames_tbl <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(year, name, sex) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">count =</span> <span class="kw">as.numeric</span>(<span class="kw">sum</span>(n))))</code></pre></div>
<pre><code>## # Source:   lazy query [?? x 4]
## # Database: spark_connection
## # Groups:   year, name
##     year     name   sex count
##    &lt;dbl&gt;    &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;
##  1  1986  Abagail     F    23
##  2  1986     Abbi     F    37
##  3  1987     Abbi     F    40
##  4  1986 Abbygail     F     7
##  5  2002  Addelyn     F    12
##  6  1987    Addie     F   101
##  7  1987  Addison     F    43
##  8  1995  Addisyn     F     5
##  9  1996  Addisyn     F     6
## 10  1990  Addyson     F     5
## # ... with more rows</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sdf_register</span>(yearlyNames_tbl, <span class="st">&quot;yearlyNames&quot;</span>)</code></pre></div>
<pre><code>## # Source:   table&lt;yearlyNames&gt; [?? x 4]
## # Database: spark_connection
##     year     name   sex count
##    &lt;dbl&gt;    &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;
##  1  1986  Abagail     F    23
##  2  1986     Abbi     F    37
##  3  1987     Abbi     F    40
##  4  1986 Abbygail     F     7
##  5  2002  Addelyn     F    12
##  6  1987    Addie     F   101
##  7  1987  Addison     F    43
##  8  1995  Addisyn     F     5
##  9  1996  Addisyn     F     6
## 10  1990  Addyson     F     5
## # ... with more rows</code></pre>
<blockquote>
<p>Notice the use of <code>inner_join()</code> to create <code>filteredNames_tbl</code>. This is a great use of a <a href="datawrangle_relational_data.html">filtering join operation</a>.</p>
</blockquote>
<p><code>sdf_register()</code> is necessary to add <code>yearlyNames_tbl</code> to the Spark cluster. Otherwise it only exists internally within the R session.</p>
<p>Now that we have our lookup table, we can use it to visualize the most popular baby names from specific years. For instance, here are the top 5 male and female names from 1986 and their popularity trend over time:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">topNames1986_tbl &lt;-<span class="st"> </span>yearlyNames_tbl <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(year <span class="op">==</span><span class="st"> </span><span class="dv">1986</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(name, sex) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">count =</span> <span class="kw">sum</span>(count)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(sex) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">rank =</span> <span class="kw">min_rank</span>(<span class="kw">desc</span>(count))) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(rank <span class="op">&lt;</span><span class="st"> </span><span class="dv">5</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">arrange</span>(sex, rank) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(name, sex, rank) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">sdf_register</span>(<span class="st">&quot;topNames1986&quot;</span>)

topNames1986Yearly &lt;-<span class="st"> </span>yearlyNames_tbl <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">inner_join</span>(<span class="kw">select</span>(topNames1986_tbl, sex, name)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">sex =</span> <span class="kw">if_else</span>(sex <span class="op">==</span><span class="st"> &quot;M&quot;</span>, <span class="st">&quot;Male&quot;</span>, <span class="st">&quot;Female&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">collect</span>()

<span class="kw">ggplot</span>(topNames1986Yearly, <span class="kw">aes</span>(year, count, <span class="dt">color =</span> name)) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_grid</span>(<span class="op">~</span><span class="st"> </span>sex) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_color_brewer</span>(<span class="dt">type =</span> <span class="st">&quot;qual&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Most Popular Names of 1986&quot;</span>,
       <span class="dt">x =</span> <span class="st">&quot;Year&quot;</span>,
       <span class="dt">y =</span> <span class="st">&quot;Number of children born&quot;</span>,
       <span class="dt">caption =</span> <span class="st">&quot;Source: SSA&quot;</span>)</code></pre></div>
<p><img src="distrib003_spark_files/figure-html/names-1986-1.png" width="672" /></p>
<p>Now what about the most popular names from 2014? Because we already generated the lookup table, we can reuse the same code with just a couple of modifications:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">topNames2014_tbl &lt;-<span class="st"> </span>yearlyNames_tbl <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(year <span class="op">==</span><span class="st"> </span><span class="dv">2014</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(name, sex) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">count =</span> <span class="kw">sum</span>(count)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(sex) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">rank =</span> <span class="kw">min_rank</span>(<span class="kw">desc</span>(count))) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(rank <span class="op">&lt;</span><span class="st"> </span><span class="dv">5</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">arrange</span>(sex, rank) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(name, sex, rank) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">sdf_register</span>(<span class="st">&quot;topNames2014&quot;</span>)

topNames2014Yearly &lt;-<span class="st"> </span>yearlyNames_tbl <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">inner_join</span>(<span class="kw">select</span>(topNames2014_tbl, sex, name)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">sex =</span> <span class="kw">if_else</span>(sex <span class="op">==</span><span class="st"> &quot;M&quot;</span>, <span class="st">&quot;Male&quot;</span>, <span class="st">&quot;Female&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">collect</span>()

<span class="kw">ggplot</span>(topNames2014Yearly, <span class="kw">aes</span>(year, count, <span class="dt">color =</span> name)) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_grid</span>(<span class="op">~</span><span class="st"> </span>sex) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_color_brewer</span>(<span class="dt">type =</span> <span class="st">&quot;qual&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Most Popular Names of 2014&quot;</span>,
       <span class="dt">x =</span> <span class="st">&quot;Year&quot;</span>,
       <span class="dt">y =</span> <span class="st">&quot;Number of children born&quot;</span>,
       <span class="dt">caption =</span> <span class="st">&quot;Source: SSA&quot;</span>)</code></pre></div>
<p><img src="distrib003_spark_files/figure-html/names-2014-1.png" width="672" /></p>
<p>There really isn’t much new here, so I’m not going to hammer this point home any further. Read <a href="http://spark.rstudio.com/dplyr.html"><em>Manipulating Data with dplyr</em></a> for more information on Spark-specific examples of <code>dplyr</code> code.</p>
</div>
</div>
<div id="machine-learning-with-spark" class="section level1">
<h1>Machine learning with Spark</h1>
<p>You can use <code>sparklyr</code> to fit a wide range of machine learning algorithms in Apache Spark. Rather than using <code>caret::train()</code>, you use a set of <code>ml_</code> functions depending on which algorithm you want to employ.</p>
<div id="load-the-data" class="section level2">
<h2>Load the data</h2>
<p>Let’s continue using the Titanic dataset. First, load the <code>titanic</code> package, which contains the data files we have been using for past statistical learning exercises, into the local Spark cluster:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(titanic)
(titanic_tbl &lt;-<span class="st"> </span><span class="kw">copy_to</span>(sc, titanic<span class="op">::</span>titanic_train, <span class="st">&quot;titanic&quot;</span>, <span class="dt">overwrite =</span> <span class="ot">TRUE</span>))</code></pre></div>
<pre><code>## # Source:   table&lt;titanic&gt; [?? x 12]
## # Database: spark_connection
##    PassengerId Survived Pclass Name   Sex     Age SibSp Parch Ticket  Fare
##          &lt;int&gt;    &lt;int&gt;  &lt;int&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;  &lt;dbl&gt;
##  1           1        0      3 Braun… male    22.     1     0 A/5 2…  7.25
##  2           2        1      1 Cumin… fema…   38.     1     0 PC 17… 71.3 
##  3           3        1      3 Heikk… fema…   26.     0     0 STON/…  7.92
##  4           4        1      1 Futre… fema…   35.     1     0 113803 53.1 
##  5           5        0      3 Allen… male    35.     0     0 373450  8.05
##  6           6        0      3 Moran… male   NaN      0     0 330877  8.46
##  7           7        0      1 McCar… male    54.     0     0 17463  51.9 
##  8           8        0      3 Palss… male     2.     3     1 349909 21.1 
##  9           9        1      3 Johns… fema…   27.     0     2 347742 11.1 
## 10          10        1      2 Nasse… fema…   14.     1     0 237736 30.1 
## # ... with more rows, and 2 more variables: Cabin &lt;chr&gt;, Embarked &lt;chr&gt;</code></pre>
</div>
<div id="tidy-the-data" class="section level2">
<h2>Tidy the data</h2>
<p>You can use <code>dplyr</code> syntax to tidy and reshape data in Spark, as well as specialized functions from the <a href="http://spark.apache.org/docs/latest/ml-features.html">Spark machine learning library</a>.</p>
<div id="spark-sql-transforms" class="section level3">
<h3>Spark SQL transforms</h3>
<p>These are <strong>feature transforms</strong> (aka mutating or filtering the columns/rows) using Spark SQL. This allows you to create new columns and modify existing columns while still employing the <code>dplyr</code> syntax. Here let’s modify 4 columns:</p>
<ol style="list-style-type: decimal">
<li><code>Family_Size</code> - create number of siblings and parents</li>
<li><code>Pclass</code> - format passenger class as character not numeric</li>
<li><code>Embarked</code> - remove a small number of missing records</li>
<li><code>Age</code> - impute missing age with average age</li>
</ol>
<p>We use <code>sdf_register()</code> at the end of the operation to store the table in the Spark cluster.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">titanic2_tbl &lt;-<span class="st"> </span>titanic_tbl <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Family_Size =</span> SibSp <span class="op">+</span><span class="st"> </span>Parch <span class="op">+</span><span class="st"> </span>1L) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Pclass =</span> <span class="kw">as.character</span>(Pclass)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(<span class="op">!</span><span class="kw">is.na</span>(Embarked)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Age =</span> <span class="kw">if_else</span>(<span class="kw">is.na</span>(Age), <span class="kw">mean</span>(Age), Age)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">sdf_register</span>(<span class="st">&quot;titanic2&quot;</span>)</code></pre></div>
</div>
<div id="spark-ml-transforms" class="section level3">
<h3>Spark ML transforms</h3>
<p>Spark also includes several functions to transform features. We can access several of them <a href="http://spark.rstudio.com/reference/sparklyr/latest/index.html">directly through <code>sparklyr</code></a>. For instance, to transform <code>Family_Sizes</code> into bins, use <code>ft_bucketizer()</code>. Because this function comes from Spark, it is used within <code>sdf_mutate()</code>, not <code>mutate()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">titanic_final_tbl &lt;-<span class="st"> </span>titanic2_tbl <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Family_Size =</span> <span class="kw">as.numeric</span>(Family_size)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">sdf_mutate</span>(
    <span class="dt">Family_Sizes =</span> <span class="kw">ft_bucketizer</span>(Family_Size, <span class="dt">splits =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">5</span>,<span class="dv">12</span>))
    ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Family_Sizes =</span> <span class="kw">as.character</span>(<span class="kw">as.integer</span>(Family_Sizes))) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">sdf_register</span>(<span class="st">&quot;titanic_final&quot;</span>)</code></pre></div>
<blockquote>
<p><code>ft_bucketizer()</code> is equivalent to <code>cut()</code> in R.</p>
</blockquote>
</div>
<div id="train-validation-split" class="section level3">
<h3>Train-validation split</h3>
<p>Randomly partition the data into training/test sets.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Partition the data</span>
partition &lt;-<span class="st"> </span>titanic_final_tbl <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Survived =</span> <span class="kw">as.numeric</span>(Survived),
         <span class="dt">SibSp =</span> <span class="kw">as.numeric</span>(SibSp),
         <span class="dt">Parch =</span> <span class="kw">as.numeric</span>(Parch)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(Survived, Pclass, Sex, Age, SibSp, Parch, Fare, Embarked, Family_Sizes) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">sdf_partition</span>(<span class="dt">train =</span> <span class="fl">0.75</span>, <span class="dt">test =</span> <span class="fl">0.25</span>, <span class="dt">seed =</span> <span class="dv">1234</span>)

<span class="co"># Create table references</span>
train_tbl &lt;-<span class="st"> </span>partition<span class="op">$</span>train
test_tbl &lt;-<span class="st"> </span>partition<span class="op">$</span>test</code></pre></div>
</div>
</div>
<div id="train-the-models" class="section level2">
<h2>Train the models</h2>
<p>Spark ML includes several types of machine learning algorithms. We can use these algorithms to fit models using the training data, then evaluate model performance using the test data.</p>
<div id="logistic-regression" class="section level3">
<h3>Logistic regression</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Model survival as a function of several predictors</span>
ml_formula &lt;-<span class="st"> </span><span class="kw">formula</span>(Survived <span class="op">~</span><span class="st"> </span>Pclass <span class="op">+</span><span class="st"> </span>Sex <span class="op">+</span><span class="st"> </span>Age <span class="op">+</span><span class="st"> </span>SibSp <span class="op">+</span>
<span class="st">                        </span>Parch <span class="op">+</span><span class="st"> </span>Fare <span class="op">+</span><span class="st"> </span>Embarked <span class="op">+</span><span class="st"> </span>Family_Sizes)

<span class="co"># Train a logistic regression model</span>
(ml_log &lt;-<span class="st"> </span><span class="kw">ml_logistic_regression</span>(train_tbl, ml_formula))</code></pre></div>
<pre><code>## Call: Survived ~ Pclass_2 + Pclass_3 + Sex_male + Age + SibSp + Parch + Fare + Embarked_Q + Embarked_S + Family_Sizes_1 + Family_Sizes_2
## 
## Coefficients:
##    (Intercept)       Pclass_2       Pclass_3       Sex_male            Age 
##    3.696483969   -1.102340720   -2.053772367   -2.786065613   -0.035430315 
##          SibSp          Parch           Fare     Embarked_Q     Embarked_S 
##    0.158164571    0.457385475    0.002038998    0.214551594   -0.159123177 
## Family_Sizes_1 Family_Sizes_2 
##   -0.306388170   -3.749909900</code></pre>
</div>
<div id="other-machine-learning-algorithms" class="section level3">
<h3>Other machine learning algorithms</h3>
<p>Run the same formula using the other machine learning algorithms. Notice that training times vary greatly between methods.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Decision Tree</span>
ml_dt &lt;-<span class="st"> </span><span class="kw">ml_decision_tree</span>(train_tbl, ml_formula)

<span class="co"># Random Forest</span>
ml_rf &lt;-<span class="st"> </span><span class="kw">ml_random_forest</span>(train_tbl, ml_formula)

<span class="co"># Gradient Boosted Tree</span>
ml_gbt &lt;-<span class="st"> </span><span class="kw">ml_gradient_boosted_trees</span>(train_tbl, ml_formula)

<span class="co"># Naive Bayes</span>
ml_nb &lt;-<span class="st"> </span><span class="kw">ml_naive_bayes</span>(train_tbl, ml_formula)

<span class="co"># Neural Network</span>
ml_nn &lt;-<span class="st"> </span><span class="kw">ml_multilayer_perceptron</span>(train_tbl, ml_formula, <span class="dt">layers =</span> <span class="kw">c</span>(<span class="dv">11</span>, <span class="dv">15</span>, <span class="dv">2</span>))</code></pre></div>
</div>
<div id="validation-data" class="section level3">
<h3>Validation data</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Bundle the models into a single list object</span>
ml_models &lt;-<span class="st"> </span><span class="kw">list</span>(
  <span class="st">&quot;Logistic&quot;</span> =<span class="st"> </span>ml_log,
  <span class="st">&quot;Decision Tree&quot;</span> =<span class="st"> </span>ml_dt,
  <span class="st">&quot;Random Forest&quot;</span> =<span class="st"> </span>ml_rf,
  <span class="st">&quot;Gradient Boosted Trees&quot;</span> =<span class="st"> </span>ml_gbt,
  <span class="st">&quot;Naive Bayes&quot;</span> =<span class="st"> </span>ml_nb,
  <span class="st">&quot;Neural Net&quot;</span> =<span class="st"> </span>ml_nn
)

<span class="co"># Create a function for scoring</span>
score_test_data &lt;-<span class="st"> </span><span class="cf">function</span>(model, <span class="dt">data =</span> test_tbl){
  pred &lt;-<span class="st"> </span><span class="kw">sdf_predict</span>(model, data)
  <span class="kw">select</span>(pred, Survived, prediction)
}

<span class="co"># Score all the models</span>
ml_score &lt;-<span class="st"> </span><span class="kw">map</span>(ml_models, score_test_data)</code></pre></div>
</div>
</div>
<div id="compare-results" class="section level2">
<h2>Compare results</h2>
<p>To pick the best model, compare the test set results by examining performance metrics: lift, accuracy, and <a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic">area under the curve (AUC)</a>.</p>
<div id="model-lift" class="section level3">
<h3>Model lift</h3>
<p><strong>Lift</strong> compares how well the model predicts survival compared to random guessing. The function below calculates the model lift for each scored decile in the test data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Lift function</span>
calculate_lift &lt;-<span class="st"> </span><span class="cf">function</span>(scored_data) {
  scored_data <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">bin =</span> <span class="kw">ntile</span>(<span class="kw">desc</span>(prediction), <span class="dv">10</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">group_by</span>(bin) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">summarize</span>(<span class="dt">count =</span> <span class="kw">sum</span>(Survived)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">prop =</span> count <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(count)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">arrange</span>(bin) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">prop =</span> <span class="kw">cumsum</span>(prop)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">select</span>(<span class="op">-</span>count) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">collect</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">as.data.frame</span>()
}

<span class="co"># Initialize results</span>
ml_gains &lt;-<span class="st"> </span><span class="kw">data_frame</span>(
  <span class="dt">bin =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">10</span>,
  <span class="dt">prop =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">len =</span> <span class="dv">10</span>),
  <span class="dt">model =</span> <span class="st">&quot;Base&quot;</span>
)

<span class="co"># Calculate lift</span>
<span class="cf">for</span>(i <span class="cf">in</span> <span class="kw">names</span>(ml_score)){
  ml_gains &lt;-<span class="st"> </span>ml_score[[i]] <span class="op">%&gt;%</span>
<span class="st">    </span>calculate_lift <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">model =</span> i) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">bind_rows</span>(ml_gains, .)
}

<span class="co"># Plot results</span>
<span class="kw">ggplot</span>(ml_gains, <span class="kw">aes</span>(<span class="dt">x =</span> bin, <span class="dt">y =</span> prop, <span class="dt">color =</span> model)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_color_brewer</span>(<span class="dt">type =</span> <span class="st">&quot;qual&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Lift Chart for Predicting Survival&quot;</span>,
       <span class="dt">subtitle =</span> <span class="st">&quot;Test Data Set&quot;</span>,
       <span class="dt">x =</span> <span class="ot">NULL</span>,
       <span class="dt">y =</span> <span class="ot">NULL</span>)</code></pre></div>
<p><img src="distrib003_spark_files/figure-html/model-lift-1.png" width="672" /></p>
<p>The lift chart suggests the tree-based models (random forest, gradient boosted trees, and decision tree) provide the best prediction.</p>
</div>
<div id="accuracy-and-auc" class="section level3">
<h3>Accuracy and AUC</h3>
<p><strong>Receiver operating characteristic (ROC) curves</strong> are graphical plots that illustrate the performance of a binary classifier. They visualize the relationship between the true positive rate (TPR) against the false positive rate (FPR).</p>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/3/36/ROC_space-2.png" alt="From Receiver operating characteristic" />
<p class="caption">From <a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic">Receiver operating characteristic</a></p>
</div>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/6/6b/Roccurves.png" alt="From Receiver operating characteristic" />
<p class="caption">From <a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic">Receiver operating characteristic</a></p>
</div>
<p>The ideal model perfectly classifies all positive outcomes as true and all negative outcomes as false (i.e. TPR = 1 and FPR = 0). The line on the second graph is made by calculating predicted outcomes at different cutpoint thresholds (i.e. <span class="math inline">\(.1, .2, .5, .8\)</span>) and connecting the dots. The diagonal line indicates expected true/false positive rates if you guessed at random. The area under the curve (AUC) summarizes how good the model is across these threshold points simultaneously. An area of 1 indicates that for any threshold value, the model always makes perfect preditions. <strong>This will almost never occur in real life.</strong> Good AUC values are between <span class="math inline">\(.6\)</span> and <span class="math inline">\(.8\)</span>. While we cannot draw the ROC graph using Spark, we can extract the AUC values based on the predictions.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Function for calculating accuracy</span>
calc_accuracy &lt;-<span class="st"> </span><span class="cf">function</span>(data, <span class="dt">cutpoint =</span> <span class="fl">0.5</span>){
  data <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">prediction =</span> <span class="kw">if_else</span>(prediction <span class="op">&gt;</span><span class="st"> </span>cutpoint, <span class="fl">1.0</span>, <span class="fl">0.0</span>)) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">ml_classification_eval</span>(<span class="st">&quot;prediction&quot;</span>, <span class="st">&quot;Survived&quot;</span>, <span class="st">&quot;accuracy&quot;</span>)
}

<span class="co"># Calculate AUC and accuracy</span>
perf_metrics &lt;-<span class="st"> </span><span class="kw">data_frame</span>(
  <span class="dt">model =</span> <span class="kw">names</span>(ml_score),
  <span class="dt">AUC =</span> <span class="dv">100</span> <span class="op">*</span><span class="st"> </span><span class="kw">map_dbl</span>(ml_score, ml_binary_classification_eval, <span class="st">&quot;Survived&quot;</span>, <span class="st">&quot;prediction&quot;</span>),
  <span class="dt">Accuracy =</span> <span class="dv">100</span> <span class="op">*</span><span class="st"> </span><span class="kw">map_dbl</span>(ml_score, calc_accuracy)
  )
perf_metrics</code></pre></div>
<pre><code>## # A tibble: 6 x 3
##                    model      AUC Accuracy
##                    &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;
## 1               Logistic 81.00928 82.43902
## 2          Decision Tree 87.78392 79.51220
## 3          Random Forest 86.90500 82.43902
## 4 Gradient Boosted Trees 85.89769 79.51220
## 5            Naive Bayes 66.47738 69.26829
## 6             Neural Net 77.32076 78.04878</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Plot results</span>
<span class="kw">gather</span>(perf_metrics, metric, value, AUC, Accuracy) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="kw">reorder</span>(model, value), value, <span class="dt">fill =</span> metric)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_bar</span>(<span class="dt">stat =</span> <span class="st">&quot;identity&quot;</span>, <span class="dt">position =</span> <span class="st">&quot;dodge&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">coord_flip</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Performance metrics&quot;</span>,
       <span class="dt">x =</span> <span class="ot">NULL</span>,
       <span class="dt">y =</span> <span class="st">&quot;Percent&quot;</span>)</code></pre></div>
<p><img src="distrib003_spark_files/figure-html/titanic_eval-1.png" width="672" /></p>
<p>Overall it appears the tree-based models performed the best - they had the highest accuracy rates and AUC values.</p>
</div>
<div id="feature-importance" class="section level3">
<h3>Feature importance</h3>
<p>It is also interesting to compare the features that were identified by each model as being important predictors for survival. The tree models implement feature importance metrics (a la <code>randomForest::varImpPlot()</code>. Sex, fare, and age are some of the most important features.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Initialize results</span>
feature_importance &lt;-<span class="st"> </span><span class="kw">data_frame</span>()

<span class="co"># Calculate feature importance</span>
<span class="cf">for</span>(i <span class="cf">in</span> <span class="kw">c</span>(<span class="st">&quot;Decision Tree&quot;</span>, <span class="st">&quot;Random Forest&quot;</span>, <span class="st">&quot;Gradient Boosted Trees&quot;</span>)){
  feature_importance &lt;-<span class="st"> </span><span class="kw">ml_tree_feature_importance</span>(sc, ml_models[[i]]) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">Model =</span> i) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">importance =</span> <span class="kw">as.numeric</span>(<span class="kw">levels</span>(importance))[importance]) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">feature =</span> <span class="kw">as.character</span>(feature)) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">rbind</span>(feature_importance, .)
}

<span class="co"># Plot results</span>
feature_importance <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="kw">reorder</span>(feature, importance), importance, <span class="dt">fill =</span> Model)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>Model) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_bar</span>(<span class="dt">stat =</span> <span class="st">&quot;identity&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">coord_flip</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Feature importance&quot;</span>,
       <span class="dt">x =</span> <span class="ot">NULL</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>)</code></pre></div>
<p><img src="distrib003_spark_files/figure-html/titanic_feature-1.png" width="672" /></p>
</div>
</div>
<div id="compare-run-times" class="section level2">
<h2>Compare run times</h2>
<p>The time to train a model is important. Some algorithms are more complex than others, so sometimes you need to balance the trade-off between accuracy and efficiency. The following code evaluates each model <code>n</code> times and plots the results. Notice that gradient boosted trees and neural nets take considerably longer to train than the other methods.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Number of reps per model</span>
n &lt;-<span class="st"> </span><span class="dv">10</span>

<span class="co"># Format model formula as character</span>
format_as_character &lt;-<span class="st"> </span><span class="cf">function</span>(x){
  x &lt;-<span class="st"> </span><span class="kw">paste</span>(<span class="kw">deparse</span>(x), <span class="dt">collapse =</span> <span class="st">&quot;&quot;</span>)
  x &lt;-<span class="st"> </span><span class="kw">gsub</span>(<span class="st">&quot;</span><span class="ch">\\</span><span class="st">s+&quot;</span>, <span class="st">&quot; &quot;</span>, <span class="kw">paste</span>(x, <span class="dt">collapse =</span> <span class="st">&quot;&quot;</span>))
  x
}

<span class="co"># Create model statements with timers</span>
format_statements &lt;-<span class="st"> </span><span class="cf">function</span>(y){
  y &lt;-<span class="st"> </span><span class="kw">format_as_character</span>(y[[<span class="st">&quot;.call&quot;</span>]])
  y &lt;-<span class="st"> </span><span class="kw">gsub</span>(<span class="st">&#39;ml_formula&#39;</span>, ml_formula_char, y)
  y &lt;-<span class="st"> </span><span class="kw">paste0</span>(<span class="st">&quot;system.time(&quot;</span>, y, <span class="st">&quot;)&quot;</span>)
  y
}

<span class="co"># Convert model formula to character</span>
ml_formula_char &lt;-<span class="st"> </span><span class="kw">format_as_character</span>(ml_formula)

<span class="co"># Create n replicates of each model statements with timers</span>
all_statements &lt;-<span class="st"> </span><span class="kw">map_chr</span>(ml_models, format_statements) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">rep</span>(., n) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">parse</span>(<span class="dt">text =</span> .)

<span class="co"># Evaluate all model statements</span>
res &lt;-<span class="st"> </span><span class="kw">map</span>(all_statements, eval)

<span class="co"># Compile results</span>
result &lt;-<span class="st"> </span><span class="kw">data_frame</span>(<span class="dt">model =</span> <span class="kw">rep</span>(<span class="kw">names</span>(ml_models), n),
                     <span class="dt">time =</span> <span class="kw">map_dbl</span>(res, <span class="cf">function</span>(x){<span class="kw">as.numeric</span>(x[<span class="st">&quot;elapsed&quot;</span>])})) 

<span class="co"># Plot</span>
result <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(time, <span class="kw">reorder</span>(model, time))) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_boxplot</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_jitter</span>(<span class="dt">width =</span> <span class="fl">0.4</span>, <span class="kw">aes</span>(<span class="dt">color =</span> model)) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_color_discrete</span>(<span class="dt">guide =</span> <span class="ot">FALSE</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Model training times&quot;</span>,
       <span class="dt">x =</span> <span class="st">&quot;Seconds&quot;</span>,
       <span class="dt">y =</span> <span class="ot">NULL</span>)</code></pre></div>
<p><img src="distrib003_spark_files/figure-html/titanic_compare_runtime-1.png" width="672" /></p>
</div>
<div id="sparkling-water-h2o-and-machine-learning" class="section level2">
<h2>Sparkling Water (H2O) and machine learning</h2>
<p>Where’s the LOOCV? Where’s the <span class="math inline">\(k\)</span>-fold cross validation? Well, <code>sparklyr</code> is still under development. It doesn’t allow you to do every single thing Spark can do. The functions we used above to estimate the models are part of <strong>Spark’s distributed <a href="https://spark.apache.org/docs/latest/mllib-guide.html">machine learning library</a></strong> (MLlib). MLlib contains <a href="http://spark.apache.org/docs/latest/ml-tuning.html#cross-validation">cross-validation functions</a> - there just isn’t an interface to them in <code>sparklyr</code> <a href="https://github.com/rstudio/sparklyr/issues/196">yet</a>.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> A real drag.</p>
<p>If you are serious about utilizing Spark and need cross-validation and other more robust machine learning tools, another option is <a href="https://www.h2o.ai/h2o/"><strong>H2O</strong></a>, an alternative open-source cross-platform machine learning software package. The <code>rsparkling</code> package provides functions to access H2O’s distributed <a href="https://www.h2o.ai/h2o/machine-learning/">machine learning functions</a> via <code>sparklyr</code>. H2O has many of the same features as MLlib (if not more so through <code>sparklyr</code>), however implementing it is a bit more complicated. Hence we focused most our code above on MLlib algorithms.</p>
<div id="h2o-and-logistic-regression" class="section level3">
<h3>H2O and logistic regression</h3>
<p>As a quick demonstration, let’s estimate a logistic regression model with 10-fold CV using H2O. First we need to load some additional packages:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rsparkling)
<span class="kw">library</span>(h2o)</code></pre></div>
<p>We will reuse the previously modified Titanic table <code>titanic_final_tbl</code>. However to use it with H2O functions, we need to convert it to an H2O data frame:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">titanic_h2o &lt;-<span class="st"> </span>titanic_final_tbl <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Survived =</span> <span class="kw">as.numeric</span>(Survived),
         <span class="dt">SibSp =</span> <span class="kw">as.numeric</span>(SibSp),
         <span class="dt">Parch =</span> <span class="kw">as.numeric</span>(Parch)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(Survived, Pclass, Sex, Age, SibSp, Parch, Fare, Embarked, Family_Sizes) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as_h2o_frame</span>(sc, ., <span class="dt">strict_version_check =</span> <span class="ot">FALSE</span>)</code></pre></div>
<p>Next we can estimate the logistic regression model using <code>h2o.glm()</code>.</p>
<ul>
<li>This function does not use a formula to pass in the indepenent and dependent variables; instead they are passed as character vector arguments to <code>x</code> and <code>y</code></li>
<li><code>family = &quot;binomial&quot;</code> - ensure we run logistic regression, not linear regression for continuous dependent variables</li>
<li><code>training_frame</code> - data frame containing the training set (here we use the entire data frame because we also use cross-validation)</li>
<li><code>lambda_search = TRUE</code> - argument for the optimizer function to calculate the parameter values</li>
<li><code>nfolds = 10</code> - estimate the model using 10-fold cross-validation</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">glm_model &lt;-<span class="st"> </span><span class="kw">h2o.glm</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="st">&quot;Pclass&quot;</span>, <span class="st">&quot;Sex&quot;</span>, <span class="st">&quot;Age&quot;</span>, <span class="st">&quot;SibSp&quot;</span>, <span class="st">&quot;Parch&quot;</span>,
                           <span class="st">&quot;Fare&quot;</span>, <span class="st">&quot;Embarked&quot;</span>, <span class="st">&quot;Family_Sizes&quot;</span>), 
                     <span class="dt">y =</span> <span class="st">&quot;Survived&quot;</span>,
                     <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>,
                     <span class="dt">training_frame =</span> titanic_h2o,
                     <span class="dt">lambda_search =</span> <span class="ot">TRUE</span>,
                     <span class="dt">nfolds =</span> <span class="dv">10</span>)</code></pre></div>
<pre><code>## 
  |                                                                       
  |                                                                 |   0%
  |                                                                       
  |=                                                                |   1%
  |                                                                       
  |========================                                         |  37%
  |                                                                       
  |=================================================================| 100%</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">glm_model</code></pre></div>
<pre><code>## Model Details:
## ==============
## 
## H2OBinomialModel: glm
## Model ID:  GLM_model_R_1503421695031_1 
## GLM Model: summary
##     family  link                                regularization
## 1 binomial logit Elastic Net (alpha = 0.5, lambda = 0.003129 )
##                                                                    lambda_search
## 1 nlambda = 100, lambda.max = 0.248, lambda.min = 0.003129, lambda.1se = 0.03515
##   number_of_predictors_total number_of_active_predictors
## 1                          4                           4
##   number_of_iterations                                   training_frame
## 1                   68 frame_rdd_13566_a40ade0b999e58d83ef2c902891449bb
## 
## Coefficients: glm coefficients
##       names coefficients standardized_coefficients
## 1 Intercept    -0.236119                 -0.454621
## 2       Age    -0.022417                 -0.290716
## 3     SibSp    -0.289895                 -0.319958
## 4     Parch     0.101851                  0.082169
## 5      Fare     0.017416                  0.865539
## 
## H2OBinomialMetrics: glm
## ** Reported on training data. **
## 
## MSE:  0.2084469
## RMSE:  0.4565598
## LogLoss:  0.6122621
## Mean Per-Class Error:  0.3641755
## AUC:  0.7074815
## Gini:  0.414963
## R^2:  0.117433
## Residual Deviance:  1088.602
## AIC:  1098.602
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##          0   1    Error      Rate
## 0      288 261 0.475410  =261/549
## 1       86 254 0.252941   =86/340
## Totals 374 515 0.390326  =347/889
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold    value idx
## 1                       max f1  0.322308 0.594152 268
## 2                       max f2  0.172284 0.759268 395
## 3                 max f0point5  0.400116 0.645032 173
## 4                 max accuracy  0.400116 0.724409 173
## 5                max precision  0.999640 1.000000   0
## 6                   max recall  0.172284 1.000000 395
## 7              max specificity  0.999640 1.000000   0
## 8             max absolute_mcc  0.399184 0.393883 174
## 9   max min_per_class_accuracy  0.346658 0.632353 236
## 10 max mean_per_class_accuracy  0.399184 0.677215 174
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`
## 
## H2OBinomialMetrics: glm
## ** Reported on cross-validation data. **
## ** 10-fold cross-validation on training data (Metrics computed for combined holdout predictions) **
## 
## MSE:  0.2108965
## RMSE:  0.4592347
## LogLoss:  0.6189053
## Mean Per-Class Error:  0.4220026
## AUC:  0.6925587
## Gini:  0.3851173
## R^2:  0.1070613
## Residual Deviance:  1100.414
## AIC:  1110.414
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##          0   1    Error      Rate
## 0      147 402 0.732240  =402/549
## 1       38 302 0.111765   =38/340
## Totals 185 704 0.494938  =440/889
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold    value idx
## 1                       max f1  0.297723 0.578544 304
## 2                       max f2  0.152770 0.757238 395
## 3                 max f0point5  0.413114 0.625000 151
## 4                 max accuracy  0.413114 0.713161 151
## 5                max precision  0.999707 1.000000   0
## 6                   max recall  0.152770 1.000000 395
## 7              max specificity  0.999707 1.000000   0
## 8             max absolute_mcc  0.399255 0.368296 167
## 9   max min_per_class_accuracy  0.346688 0.623529 228
## 10 max mean_per_class_accuracy  0.392200 0.670556 173
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`
## Cross-Validation Metrics Summary: 
##                 mean          sd cv_1_valid cv_2_valid cv_3_valid
## accuracy   0.6500479 0.041881736  0.6363636  0.6091954 0.71428573
## auc       0.71170306 0.032053903 0.74575895  0.6638825 0.70077866
## err        0.3499521 0.041881736 0.36363637  0.3908046  0.2857143
## err_count       31.0   3.7549968       36.0       34.0       26.0
## f0point5   0.5726497 0.045476418 0.53505534  0.5106383 0.56213015
##           cv_4_valid cv_5_valid cv_6_valid cv_7_valid cv_8_valid
## accuracy  0.55172414  0.6835443   0.682243  0.5833333  0.7582418
## auc       0.70297295  0.7615283  0.7119403  0.6064706 0.74852073
## err       0.44827586  0.3164557   0.317757 0.41666666 0.24175824
## err_count       39.0       25.0       34.0       35.0       22.0
## f0point5    0.542522 0.62211984 0.58189654  0.5252101 0.72192514
##           cv_9_valid cv_10_valid
## accuracy  0.61904764      0.6625
## auc         0.719496   0.7556818
## err        0.3809524      0.3375
## err_count       32.0        27.0
## f0point5         0.5       0.625
## 
## ---
##                         mean          sd cv_1_valid cv_2_valid  cv_3_valid
## precision          0.5381394 0.055250388  0.4915254 0.47058824  0.54285717
## r2                 0.0975009 0.031127375  0.1564119 0.10831892 0.086596675
## recall             0.8112482 0.086222775 0.82857144  0.7741935   0.6551724
## residual_deviance  109.25886   5.4304786   114.6542  104.17874   106.71968
## rmse              0.45955113 0.008883104  0.4390905 0.45223105  0.44533285
## specificity        0.5446867  0.11514253    0.53125 0.51785713   0.7419355
##                   cv_4_valid cv_5_valid cv_6_valid  cv_7_valid  cv_8_valid
## precision          0.4868421  0.5869565     0.5625  0.49019608   0.7297297
## r2                 0.1278114 0.09742886 0.13443607 0.027979773 0.121132664
## recall                   1.0  0.8181818      0.675   0.7352941   0.6923077
## residual_deviance  108.03258  101.55076  128.32715  111.066345   112.77616
## rmse               0.4617127 0.46854305 0.45012507  0.48393032  0.46393192
## specificity             0.22  0.5869565  0.6865672        0.48   0.8076923
##                    cv_9_valid cv_10_valid
## precision          0.44642857  0.57377046
## r2                0.008515219  0.10637745
## recall             0.96153843   0.9722222
## residual_deviance   103.23352  102.049416
## rmse               0.46032485   0.4702888
## specificity        0.46551725   0.4090909</code></pre>
<p>We get lots of information back about the model. Many of these statistics can be extracted and stored as tidy data frames or used to create visualizations.</p>
</div>
</div>
</div>
<div id="acknowledgments" class="section level1 toc-ignore">
<h1>Acknowledgments</h1>
<ul>
<li>Baby names and <code>dplyr</code> example drawn from <a href="https://beta.rstudioconnect.com/content/1813/babynames-dplyr.nb.html">Analysis of babynames with <code>dplyr</code></a></li>
<li>Titanic machine learning example drawn from <a href="https://beta.rstudioconnect.com/content/1518/notebook-classification.html">Comparison of ML Classifiers Using Sparklyr</a></li>
</ul>
</div>
<div id="session-info" class="section level1 toc-ignore">
<h1>Session Info</h1>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">devtools<span class="op">::</span><span class="kw">session_info</span>()</code></pre></div>
<pre><code>##  setting  value                       
##  version  R version 3.4.3 (2017-11-30)
##  system   x86_64, darwin15.6.0        
##  ui       X11                         
##  language (EN)                        
##  collate  en_US.UTF-8                 
##  tz       America/Chicago             
##  date     2018-04-24                  
## 
##  package    * version    date       source                             
##  assertthat   0.2.0      2017-04-11 CRAN (R 3.4.0)                     
##  babynames  * 0.3.0      2017-04-14 CRAN (R 3.4.0)                     
##  backports    1.1.2      2017-12-13 CRAN (R 3.4.3)                     
##  base       * 3.4.3      2017-12-07 local                              
##  base64enc    0.1-3      2015-07-28 CRAN (R 3.4.0)                     
##  bindr        0.1.1      2018-03-13 CRAN (R 3.4.3)                     
##  bindrcpp     0.2.2.9000 2018-04-08 Github (krlmlr/bindrcpp@bd5ae73)   
##  bitops       1.0-6      2013-08-17 CRAN (R 3.4.0)                     
##  broom        0.4.4      2018-03-29 CRAN (R 3.4.3)                     
##  cellranger   1.1.0      2016-07-27 CRAN (R 3.4.0)                     
##  cli          1.0.0      2017-11-05 CRAN (R 3.4.2)                     
##  colorspace   1.3-2      2016-12-14 CRAN (R 3.4.0)                     
##  compiler     3.4.3      2017-12-07 local                              
##  config       0.3        2018-03-27 CRAN (R 3.4.4)                     
##  crayon       1.3.4      2017-10-03 Github (gaborcsardi/crayon@b5221ab)
##  datasets   * 3.4.3      2017-12-07 local                              
##  DBI          0.8        2018-03-02 CRAN (R 3.4.3)                     
##  dbplyr       1.2.1      2018-02-19 CRAN (R 3.4.3)                     
##  devtools     1.13.5     2018-02-18 CRAN (R 3.4.3)                     
##  digest       0.6.15     2018-01-28 CRAN (R 3.4.3)                     
##  dplyr      * 0.7.4.9003 2018-04-08 Github (tidyverse/dplyr@b7aaa95)   
##  evaluate     0.10.1     2017-06-24 CRAN (R 3.4.1)                     
##  forcats    * 0.3.0      2018-02-19 CRAN (R 3.4.3)                     
##  foreign      0.8-69     2017-06-22 CRAN (R 3.4.3)                     
##  ggplot2    * 2.2.1.9000 2018-04-24 Github (tidyverse/ggplot2@3c9c504) 
##  glue         1.2.0      2017-10-29 CRAN (R 3.4.2)                     
##  graphics   * 3.4.3      2017-12-07 local                              
##  grDevices  * 3.4.3      2017-12-07 local                              
##  grid         3.4.3      2017-12-07 local                              
##  gtable       0.2.0      2016-02-26 CRAN (R 3.4.0)                     
##  h2o        * 3.16.0.2   2017-12-01 CRAN (R 3.4.3)                     
##  haven        1.1.1      2018-01-18 CRAN (R 3.4.3)                     
##  hms          0.4.2      2018-03-10 CRAN (R 3.4.3)                     
##  htmltools    0.3.6      2017-04-28 CRAN (R 3.4.0)                     
##  httpuv       1.3.6.2    2018-03-02 CRAN (R 3.4.3)                     
##  httr         1.3.1      2017-08-20 CRAN (R 3.4.1)                     
##  jsonlite     1.5        2017-06-01 CRAN (R 3.4.0)                     
##  knitr        1.20       2018-02-20 CRAN (R 3.4.3)                     
##  lattice      0.20-35    2017-03-25 CRAN (R 3.4.3)                     
##  lazyeval     0.2.1      2017-10-29 CRAN (R 3.4.2)                     
##  lubridate    1.7.4      2018-04-11 CRAN (R 3.4.3)                     
##  magrittr     1.5        2014-11-22 CRAN (R 3.4.0)                     
##  memoise      1.1.0      2017-04-21 CRAN (R 3.4.0)                     
##  methods    * 3.4.3      2017-12-07 local                              
##  mime         0.5        2016-07-07 CRAN (R 3.4.0)                     
##  mnormt       1.5-5      2016-10-15 CRAN (R 3.4.0)                     
##  modelr       0.1.1      2017-08-10 local                              
##  munsell      0.4.3      2016-02-13 CRAN (R 3.4.0)                     
##  nlme         3.1-137    2018-04-07 CRAN (R 3.4.4)                     
##  openssl      1.0.1      2018-03-03 CRAN (R 3.4.3)                     
##  parallel     3.4.3      2017-12-07 local                              
##  pillar       1.2.1      2018-02-27 CRAN (R 3.4.3)                     
##  pkgconfig    2.0.1      2017-03-21 CRAN (R 3.4.0)                     
##  plyr         1.8.4      2016-06-08 CRAN (R 3.4.0)                     
##  psych        1.8.3.3    2018-03-30 CRAN (R 3.4.4)                     
##  purrr      * 0.2.4      2017-10-18 CRAN (R 3.4.2)                     
##  R6           2.2.2      2017-06-17 CRAN (R 3.4.0)                     
##  rappdirs     0.3.1      2016-03-28 CRAN (R 3.4.0)                     
##  Rcpp         0.12.16    2018-03-13 CRAN (R 3.4.4)                     
##  RCurl        1.95-4.10  2018-01-04 CRAN (R 3.4.3)                     
##  readr      * 1.1.1      2017-05-16 CRAN (R 3.4.0)                     
##  readxl       1.0.0      2017-04-18 CRAN (R 3.4.0)                     
##  reshape2     1.4.3      2017-12-11 CRAN (R 3.4.3)                     
##  rlang        0.2.0.9001 2018-04-24 Github (r-lib/rlang@82b2727)       
##  rmarkdown    1.9        2018-03-01 CRAN (R 3.4.3)                     
##  rprojroot    1.3-2      2018-01-03 CRAN (R 3.4.3)                     
##  rsparkling * 0.2.3      2018-03-08 CRAN (R 3.4.4)                     
##  rstudioapi   0.7        2017-09-07 CRAN (R 3.4.1)                     
##  rvest        0.3.2      2016-06-17 CRAN (R 3.4.0)                     
##  scales       0.5.0.9000 2018-04-24 Github (hadley/scales@d767915)     
##  shiny        1.0.5      2017-08-23 cran (@1.0.5)                      
##  sparklyr   * 0.7.0      2018-01-23 CRAN (R 3.4.3)                     
##  stats      * 3.4.3      2017-12-07 local                              
##  stringi      1.1.7      2018-03-12 CRAN (R 3.4.3)                     
##  stringr    * 1.3.0      2018-02-19 CRAN (R 3.4.3)                     
##  tibble     * 1.4.2      2018-01-22 CRAN (R 3.4.3)                     
##  tidyr      * 0.8.0      2018-01-29 CRAN (R 3.4.3)                     
##  tidyselect   0.2.4      2018-02-26 CRAN (R 3.4.3)                     
##  tidyverse  * 1.2.1      2017-11-14 CRAN (R 3.4.2)                     
##  titanic    * 0.1.0      2015-08-31 CRAN (R 3.4.0)                     
##  tools        3.4.3      2017-12-07 local                              
##  utf8         1.1.3      2018-01-03 CRAN (R 3.4.3)                     
##  utils      * 3.4.3      2017-12-07 local                              
##  withr        2.1.2      2018-04-24 Github (jimhester/withr@79d7b0d)   
##  xml2         1.2.0      2018-01-24 CRAN (R 3.4.3)                     
##  xtable       1.8-2      2016-02-05 CRAN (R 3.4.0)                     
##  yaml         2.1.18     2018-03-08 CRAN (R 3.4.4)</code></pre>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>In refresing my notes for the term, I saw CV was just incorporated into the development version of <code>sparklyr</code> but it is not yet deployed on CRAN.<a href="#fnref1">↩</a></p></li>
</ol>
</div>

<p>This work is licensed under the  <a href="http://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0 Creative Commons License</a>.</p>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
